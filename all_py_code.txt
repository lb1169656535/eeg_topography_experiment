# 项目结构 (tree /f 或 tree -af)
# ===============================
.
├── ./.datalad
│   ├── ./.datalad/.gitattributes
│   └── ./.datalad/config
├── ./.git
│   ├── ./.git/COMMIT_EDITMSG
│   ├── ./.git/FETCH_HEAD
│   ├── ./.git/HEAD
│   ├── ./.git/annex
│   │   ├── ./.git/annex/fsck
│   │   │   ├── ./.git/annex/fsck/fsck.lck
│   │   │   └── ./.git/annex/fsck/fsckdb
│   │   │       └── ./.git/annex/fsck/fsckdb/db
│   │   ├── ./.git/annex/index
│   │   ├── ./.git/annex/index.lck
│   │   ├── ./.git/annex/journal
│   │   ├── ./.git/annex/journal.lck
│   │   ├── ./.git/annex/keysdb
│   │   │   └── ./.git/annex/keysdb/db
│   │   ├── ./.git/annex/keysdb.cache
│   │   ├── ./.git/annex/keysdb.lck
│   │   ├── ./.git/annex/mergedrefs
│   │   ├── ./.git/annex/othertmp
│   │   ├── ./.git/annex/othertmp.lck
│   │   ├── ./.git/annex/sentinal
│   │   ├── ./.git/annex/sentinal.cache
│   │   ├── ./.git/annex/smudge.lck
│   │   └── ./.git/annex/smudge.log
│   ├── ./.git/branches
│   ├── ./.git/config
│   ├── ./.git/config.dataladlock
│   ├── ./.git/description
│   ├── ./.git/hooks
│   │   ├── ./.git/hooks/applypatch-msg.sample
│   │   ├── ./.git/hooks/commit-msg.sample
│   │   ├── ./.git/hooks/fsmonitor-watchman.sample
│   │   ├── ./.git/hooks/post-checkout
│   │   ├── ./.git/hooks/post-merge
│   │   ├── ./.git/hooks/post-receive
│   │   ├── ./.git/hooks/post-update.sample
│   │   ├── ./.git/hooks/pre-applypatch.sample
│   │   ├── ./.git/hooks/pre-commit
│   │   ├── ./.git/hooks/pre-commit.sample
│   │   ├── ./.git/hooks/pre-merge-commit.sample
│   │   ├── ./.git/hooks/pre-push.sample
│   │   ├── ./.git/hooks/pre-rebase.sample
│   │   ├── ./.git/hooks/pre-receive.sample
│   │   ├── ./.git/hooks/prepare-commit-msg.sample
│   │   ├── ./.git/hooks/push-to-checkout.sample
│   │   ├── ./.git/hooks/sendemail-validate.sample
│   │   └── ./.git/hooks/update.sample
│   ├── ./.git/index
│   ├── ./.git/info
│   │   ├── ./.git/info/attributes
│   │   └── ./.git/info/exclude
│   ├── ./.git/logs
│   │   ├── ./.git/logs/HEAD
│   │   └── ./.git/logs/refs
│   │       ├── ./.git/logs/refs/heads
│   │       │   ├── ./.git/logs/refs/heads/git-annex
│   │       │   └── ./.git/logs/refs/heads/main
│   │       └── ./.git/logs/refs/remotes
│   │           └── ./.git/logs/refs/remotes/origin
│   │               ├── ./.git/logs/refs/remotes/origin/HEAD
│   │               └── ./.git/logs/refs/remotes/origin/main
│   ├── ./.git/objects
│   │   ├── ./.git/objects/0b
│   │   │   └── ./.git/objects/0b/0076e57c553ea9056c17ace9f16363e9900d65
│   │   ├── ./.git/objects/0c
│   │   │   └── ./.git/objects/0c/f8e75b6fb6db990e90248106d6b8770a027e7b
│   │   ├── ./.git/objects/0f
│   │   │   └── ./.git/objects/0f/1f79e38845e57f347552ea93d1f92e977a11c2
│   │   ├── ./.git/objects/1f
│   │   │   └── ./.git/objects/1f/0bd672157052c9887dcc3fb761b1159e2e9e58
│   │   ├── ./.git/objects/24
│   │   │   └── ./.git/objects/24/bed0bdb41d2220f129a401af09cb65c7ee5de6
│   │   ├── ./.git/objects/41
│   │   │   └── ./.git/objects/41/07637f7768c9a09d2297b6b9c708602ec3cbd0
│   │   ├── ./.git/objects/42
│   │   │   └── ./.git/objects/42/d26db99b9b8d5f7e4d1079985ab31037cb3945
│   │   ├── ./.git/objects/45
│   │   │   └── ./.git/objects/45/af84fcbea02e00d3659d37e5e420da39e46494
│   │   ├── ./.git/objects/46
│   │   │   └── ./.git/objects/46/3ac0fad1d88cbf59f38cd6884c824ade4ca5a8
│   │   ├── ./.git/objects/49
│   │   │   └── ./.git/objects/49/4612250187fc87654237b55540499cce09a9c9
│   │   ├── ./.git/objects/4b
│   │   │   └── ./.git/objects/4b/825dc642cb6eb9a060e54bf8d69288fbee4904
│   │   ├── ./.git/objects/4d
│   │   │   └── ./.git/objects/4d/58d446cfaf130a730751ff21ba1e517a0552a0
│   │   ├── ./.git/objects/4e
│   │   │   └── ./.git/objects/4e/d05926487eb2bd84a73eac648e6b8678ddeee2
│   │   ├── ./.git/objects/59
│   │   │   └── ./.git/objects/59/28185081410e652fcb8b4446fae9caf43288e5
│   │   ├── ./.git/objects/5a
│   │   │   └── ./.git/objects/5a/aba8aabfb55002fb1e3b56b40c1ec77aa91d59
│   │   ├── ./.git/objects/5f
│   │   │   └── ./.git/objects/5f/84c346beb09d2eed54a14446d1b175c1857af0
│   │   ├── ./.git/objects/6b
│   │   │   └── ./.git/objects/6b/38ca9dfe215971a9e329782ea0c3fdbf8a31b6
│   │   ├── ./.git/objects/6c
│   │   │   └── ./.git/objects/6c/0b1c14df216291dae3cb585617d288d4bf48a2
│   │   ├── ./.git/objects/70
│   │   │   └── ./.git/objects/70/49eff93c7d4ed219919bce4b74370c152bd6d3
│   │   ├── ./.git/objects/77
│   │   │   └── ./.git/objects/77/4154243c5ee80449641d9dfa77d8318c9943be
│   │   ├── ./.git/objects/80
│   │   │   └── ./.git/objects/80/5770d083b03913ddcc30815b012d4a4fe91fd6
│   │   ├── ./.git/objects/81
│   │   │   └── ./.git/objects/81/9ff3af34b2d388e3f76dda5d1ff53289897dda
│   │   ├── ./.git/objects/82
│   │   │   └── ./.git/objects/82/ccb5d829f624f42c5994df967cec904ff2469c
│   │   ├── ./.git/objects/86
│   │   │   └── ./.git/objects/86/726e91bc765cd628401aed13f1bc139134d156
│   │   ├── ./.git/objects/9c
│   │   │   └── ./.git/objects/9c/e00ea2ccb3c6997a8d3004bd41ebfa96168c73
│   │   ├── ./.git/objects/af
│   │   │   └── ./.git/objects/af/926ef0c359556ac1d36d71f7e173d97b893ff2
│   │   ├── ./.git/objects/b6
│   │   │   └── ./.git/objects/b6/334bd9af8e300fd7f33f42869172e6a2cbe2d8
│   │   ├── ./.git/objects/c2
│   │   │   └── ./.git/objects/c2/c0ea6f3921fd03337a9592657eaa200a780e7b
│   │   ├── ./.git/objects/c5
│   │   │   └── ./.git/objects/c5/30856915c260cbfdf71c72974db3004aebd759
│   │   ├── ./.git/objects/c8
│   │   │   └── ./.git/objects/c8/368359f3e7633965252fbd3b8047b37a45a325
│   │   ├── ./.git/objects/d4
│   │   │   └── ./.git/objects/d4/9f3251d735c3e3775dd1c930e0c3fa5e867869
│   │   ├── ./.git/objects/d5
│   │   │   └── ./.git/objects/d5/9574abe8fbaa810502881ab4ccfb738c1d705a
│   │   ├── ./.git/objects/d9
│   │   │   └── ./.git/objects/d9/9cd4afa8955f94d4fde4a3846e121d77a7c87d
│   │   ├── ./.git/objects/da
│   │   │   └── ./.git/objects/da/ad4c4a0fb4474a8408c7c763b1395a6e039d40
│   │   ├── ./.git/objects/dc
│   │   │   └── ./.git/objects/dc/dfe8aaa7536290e92da3461a610c1917445078
│   │   ├── ./.git/objects/e0
│   │   │   └── ./.git/objects/e0/ae8d49527e460a86a9e640b24cef3ca1d41ac0
│   │   ├── ./.git/objects/e3
│   │   │   └── ./.git/objects/e3/9584b67a3ef09500ac880be852816b8e821d7d
│   │   ├── ./.git/objects/e6
│   │   │   └── ./.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391
│   │   ├── ./.git/objects/f2
│   │   │   └── ./.git/objects/f2/08d7457372a48b3e5e89ec9e4576b6145f98af
│   │   ├── ./.git/objects/f8
│   │   │   ├── ./.git/objects/f8/5b791bee41050ad7b29374397788189cb002f8
│   │   │   └── ./.git/objects/f8/f95e78c08d4309190cf8300a139062e32c9c6f
│   │   ├── ./.git/objects/fd
│   │   │   └── ./.git/objects/fd/0aadefc75e3ad402b9a161f68980d4d940f9fa
│   │   ├── ./.git/objects/ff
│   │   │   └── ./.git/objects/ff/818832bd2164da8f6f3de864d88535ed08928e
│   │   ├── ./.git/objects/info
│   │   └── ./.git/objects/pack
│   │       ├── ./.git/objects/pack/pack-44261f52b16e2554a4dac2d17f6c4669e26c8bc1.idx
│   │       ├── ./.git/objects/pack/pack-44261f52b16e2554a4dac2d17f6c4669e26c8bc1.pack
│   │       └── ./.git/objects/pack/pack-44261f52b16e2554a4dac2d17f6c4669e26c8bc1.rev
│   ├── ./.git/packed-refs
│   └── ./.git/refs
│       ├── ./.git/refs/annex
│       │   └── ./.git/refs/annex/last-index
│       ├── ./.git/refs/heads
│       │   ├── ./.git/refs/heads/git-annex
│       │   └── ./.git/refs/heads/main
│       ├── ./.git/refs/remotes
│       │   └── ./.git/refs/remotes/origin
│       │       ├── ./.git/refs/remotes/origin/HEAD
│       │       └── ./.git/refs/remotes/origin/main
│       └── ./.git/refs/tags
├── ./.gitattributes
├── ./.gitignore
├── ./README.md
├── ./__pycache__
│   ├── ./__pycache__/algorithm_comparison.cpython-311.pyc
│   └── ./__pycache__/config.cpython-311.pyc
├── ./algorithm_comparison.py
├── ./config.py
├── ./gather_all_py_to_txt.py
├── ./logs
│   └── ./logs/enhanced_experiment_20250802_061714.log
├── ./main.py
├── ./quick_test.py
├── ./requirements.txt
├── ./src
│   ├── ./src/__init__.py
│   ├── ./src/__pycache__
│   │   ├── ./src/__pycache__/__init__.cpython-311.pyc
│   │   ├── ./src/__pycache__/data_loader.cpython-311.pyc
│   │   ├── ./src/__pycache__/topography.cpython-311.pyc
│   │   ├── ./src/__pycache__/tracker.cpython-311.pyc
│   │   ├── ./src/__pycache__/trajectory_analysis.cpython-311.pyc
│   │   └── ./src/__pycache__/visualization.cpython-311.pyc
│   ├── ./src/data_loader.py
│   ├── ./src/topography.py
│   ├── ./src/trajectory_analysis.py
│   └── ./src/visualization.py
├── ./test_results
│   ├── ./test_results/algorithm_comparison_test.png
│   ├── ./test_results/comparison_charts_test.png
│   ├── ./test_results/enhanced_visualization_test.png
│   └── ./test_results/font_test.png
├── ./trackers
│   ├── ./trackers/__init__.py
│   ├── ./trackers/__pycache__
│   │   ├── ./trackers/__pycache__/__init__.cpython-311.pyc
│   │   ├── ./trackers/__pycache__/base_tracker.cpython-311.pyc
│   │   ├── ./trackers/__pycache__/greedy_tracker.cpython-311.pyc
│   │   ├── ./trackers/__pycache__/hungarian_tracker.cpython-311.pyc
│   │   ├── ./trackers/__pycache__/hybrid_tracker.cpython-311.pyc
│   │   ├── ./trackers/__pycache__/kalman_tracker.cpython-311.pyc
│   │   ├── ./trackers/__pycache__/overlap_tracker.cpython-311.pyc
│   │   └── ./trackers/__pycache__/tracker_factory.cpython-311.pyc
│   ├── ./trackers/base_tracker.py
│   ├── ./trackers/greedy_tracker.py
│   ├── ./trackers/hungarian_tracker.py
│   ├── ./trackers/hybrid_tracker.py
│   ├── ./trackers/kalman_tracker.py
│   ├── ./trackers/overlap_tracker.py
│   └── ./trackers/tracker_factory.py
└── ./usage_guide.md

75 directories, 144 files

# ===============================

# ========== algorithm_comparison.py ==========
# 相对路径: algorithm_comparison.py
# 在项目中的相对位置: ./algorithm_comparison.py

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced EEG Trajectory Tracking Algorithm Comparison Module
Comprehensive evaluation and comparison of different tracking algorithms
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.spatial.distance import cdist
from scipy.optimize import linear_sum_assignment
from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score, adjusted_rand_score
import time
import pandas as pd
from typing import Dict, List, Tuple, Optional
import logging
import os

# Set matplotlib to use English fonts only
plt.rcParams['font.family'] = 'DejaVu Sans'

class EnhancedAlgorithmComparison:
    """Enhanced algorithm comparison with better visualization and analysis"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def calculate_comprehensive_metrics(self, algorithm_results: Dict) -> Dict:
        """Calculate comprehensive performance metrics for each algorithm"""
        comprehensive_metrics = {}
        
        for algorithm_name, results in algorithm_results.items():
            metrics = {
                'trajectory_count': [],
                'computation_times': [],
                'trajectory_lengths': [],
                'quality_scores': [],
                'frames_processed': [],
                'efficiency_scores': [],
                'stability_scores': []
            }
            
            # Collect raw data
            for session_data in results.values():
                if isinstance(session_data, dict) and 'trajectories' in session_data:
                    metrics['trajectory_count'].append(len(session_data['trajectories']))
                    metrics['computation_times'].append(session_data.get('total_computation_time', 0))
                    metrics['frames_processed'].append(session_data.get('total_frames_processed', 0))
                    
                    # Extract trajectory-level metrics
                    for traj_data in session_data['trajectories'].values():
                        metrics['trajectory_lengths'].append(traj_data.get('length', 0))
                        metrics['quality_scores'].append(traj_data.get('quality_score', 0))
                    
                    # Calculate efficiency: trajectories per second
                    time_taken = session_data.get('total_computation_time', 1e-6)
                    traj_count = len(session_data['trajectories'])
                    efficiency = traj_count / max(time_taken, 1e-6)
                    metrics['efficiency_scores'].append(efficiency)
            
            # Calculate summary statistics
            summary = {}
            for metric_name, values in metrics.items():
                if values:
                    summary[f'avg_{metric_name}'] = np.mean(values)
                    summary[f'std_{metric_name}'] = np.std(values)
                    summary[f'min_{metric_name}'] = np.min(values)
                    summary[f'max_{metric_name}'] = np.max(values)
                    summary[f'median_{metric_name}'] = np.median(values)
                else:
                    summary[f'avg_{metric_name}'] = 0
                    summary[f'std_{metric_name}'] = 0
                    summary[f'min_{metric_name}'] = 0
                    summary[f'max_{metric_name}'] = 0
                    summary[f'median_{metric_name}'] = 0
            
            # Calculate composite performance score
            traj_score = min(1.0, summary['avg_trajectory_count'] / 5.0)
            quality_score = summary['avg_quality_scores']
            efficiency_score = min(1.0, summary['avg_efficiency_scores'] / 10.0)
            stability_score = 1.0 / (1.0 + summary['std_computation_times'] / max(summary['avg_computation_times'], 1e-6))
            
            composite_score = (traj_score * 0.3 + quality_score * 0.3 + 
                             efficiency_score * 0.25 + stability_score * 0.15)
            
            summary['composite_performance_score'] = composite_score
            summary['raw_data'] = metrics
            
            comprehensive_metrics[algorithm_name] = summary
        
        return comprehensive_metrics
    
    def generate_detailed_report(self, comprehensive_metrics: Dict) -> str:
        """Generate detailed comparison report with actionable insights"""
        report = []
        report.append("=" * 80)
        report.append("ENHANCED EEG TRAJECTORY TRACKING ALGORITHM COMPARISON REPORT")
        report.append("=" * 80)
        report.append(f"Analysis Date: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"Algorithms Analyzed: {len(comprehensive_metrics)}")
        report.append("")
        
        # Executive Summary
        report.append("EXECUTIVE SUMMARY")
        report.append("-" * 40)
        
        # Find best performers in each category
        best_overall = max(comprehensive_metrics.items(), 
                          key=lambda x: x[1]['composite_performance_score'])
        best_speed = min(comprehensive_metrics.items(), 
                        key=lambda x: x[1]['avg_computation_times'])
        best_quality = max(comprehensive_metrics.items(), 
                          key=lambda x: x[1]['avg_quality_scores'])
        best_efficiency = max(comprehensive_metrics.items(), 
                             key=lambda x: x[1]['avg_efficiency_scores'])
        
        report.append(f"• Best Overall Performance: {best_overall[0].upper()} "
                     f"(Score: {best_overall[1]['composite_performance_score']:.3f})")
        report.append(f"• Fastest Algorithm: {best_speed[0].upper()} "
                     f"({best_speed[1]['avg_computation_times']:.4f}s avg)")
        report.append(f"• Highest Quality: {best_quality[0].upper()} "
                     f"(Score: {best_quality[1]['avg_quality_scores']:.3f})")
        report.append(f"• Most Efficient: {best_efficiency[0].upper()} "
                     f"({best_efficiency[1]['avg_efficiency_scores']:.1f} traj/s)")
        report.append("")
        
        # Detailed Algorithm Analysis
        report.append("DETAILED ALGORITHM ANALYSIS")
        report.append("-" * 50)
        
        for algorithm_name, metrics in comprehensive_metrics.items():
            report.append(f"\n{algorithm_name.upper()} ALGORITHM:")
            report.append("=" * (len(algorithm_name) + 11))
            
            # Performance Metrics
            report.append("Performance Metrics:")
            report.append(f"  • Average Trajectories Detected: {metrics['avg_trajectory_count']:.2f} ± {metrics['std_trajectory_count']:.2f}")
            report.append(f"  • Average Computation Time: {metrics['avg_computation_times']:.4f}s ± {metrics['std_computation_times']:.4f}s")
            report.append(f"  • Average Trajectory Quality: {metrics['avg_quality_scores']:.3f} ± {metrics['std_quality_scores']:.3f}")
            report.append(f"  • Average Trajectory Length: {metrics['avg_trajectory_lengths']:.1f} ± {metrics['std_trajectory_lengths']:.1f} frames")
            report.append(f"  • Processing Efficiency: {metrics['avg_efficiency_scores']:.1f} trajectories/second")
            report.append(f"  • Composite Performance Score: {metrics['composite_performance_score']:.3f}")
            
            # Reliability Metrics
            report.append("\nReliability Analysis:")
            cv_time = metrics['std_computation_times'] / max(metrics['avg_computation_times'], 1e-6)
            cv_quality = metrics['std_quality_scores'] / max(metrics['avg_quality_scores'], 1e-6)
            
            report.append(f"  • Time Consistency (CV): {cv_time:.3f} {'(Excellent)' if cv_time < 0.1 else '(Good)' if cv_time < 0.3 else '(Poor)'}")
            report.append(f"  • Quality Consistency (CV): {cv_quality:.3f} {'(Excellent)' if cv_quality < 0.1 else '(Good)' if cv_quality < 0.3 else '(Poor)'}")
            
            # Performance Range
            report.append("\nPerformance Range:")
            report.append(f"  • Trajectory Count Range: {metrics['min_trajectory_count']:.0f} - {metrics['max_trajectory_count']:.0f}")
            report.append(f"  • Time Range: {metrics['min_computation_times']:.4f}s - {metrics['max_computation_times']:.4f}s")
            report.append(f"  • Quality Range: {metrics['min_quality_scores']:.3f} - {metrics['max_quality_scores']:.3f}")
        
        # Comparative Analysis
        report.append("\n\nCOMPARATIVE ANALYSIS")
        report.append("-" * 50)
        
        # Statistical significance (simplified)
        report.append("Performance Ranking by Category:")
        
        categories = [
            ('Overall Performance', 'composite_performance_score'),
            ('Speed', 'avg_computation_times', True),  # Lower is better
            ('Quality', 'avg_quality_scores'),
            ('Efficiency', 'avg_efficiency_scores'),
            ('Trajectory Count', 'avg_trajectory_count')
        ]
        
        for category_name, metric_key, *reverse in categories:
            is_reverse = len(reverse) > 0 and reverse[0]
            sorted_algorithms = sorted(comprehensive_metrics.items(), 
                                     key=lambda x: x[1][metric_key], 
                                     reverse=not is_reverse)
            
            report.append(f"\n{category_name}:")
            for i, (alg_name, metrics) in enumerate(sorted_algorithms, 1):
                value = metrics[metric_key]
                if 'time' in metric_key:
                    report.append(f"  {i}. {alg_name.upper()}: {value:.4f}s")
                elif 'score' in metric_key:
                    report.append(f"  {i}. {alg_name.upper()}: {value:.3f}")
                else:
                    report.append(f"  {i}. {alg_name.upper()}: {value:.2f}")
        
        # Recommendations
        report.append("\n\nRECOMMENDATIONS")
        report.append("-" * 40)
        
        report.append("Use Case Recommendations:")
        report.append("• Real-time Processing: Choose the fastest algorithm with acceptable quality")
        report.append("• High-precision Analysis: Choose the highest quality algorithm")
        report.append("• Resource-constrained Environments: Choose the most efficient algorithm")
        report.append("• Batch Processing: Choose the best overall performance algorithm")
        
        report.append("\nSpecific Recommendations:")
        for alg_name, metrics in comprehensive_metrics.items():
            score = metrics['composite_performance_score']
            speed = metrics['avg_computation_times']
            quality = metrics['avg_quality_scores']
            
            if score > 0.7:
                recommendation = "Excellent for most applications"
            elif speed < 0.1 and quality > 0.6:
                recommendation = "Good for real-time applications"
            elif quality > 0.8:
                recommendation = "Ideal for high-precision tasks"
            elif metrics['avg_efficiency_scores'] > 15:
                recommendation = "Best for high-throughput scenarios"
            else:
                recommendation = "Suitable for basic applications"
            
            report.append(f"• {alg_name.upper()}: {recommendation}")
        
        # Technical Notes
        report.append("\n\nTECHNICAL NOTES")
        report.append("-" * 40)
        report.append("• Performance scores are normalized to 0-1 scale")
        report.append("• Composite score weights: Trajectories(30%), Quality(30%), Efficiency(25%), Stability(15%)")
        report.append("• Coefficient of Variation (CV) indicates consistency: <0.1=Excellent, 0.1-0.3=Good, >0.3=Poor")
        report.append("• Results may vary with different data characteristics and parameters")
        
        return "\n".join(report)
    
    def create_comprehensive_visualizations(self, comprehensive_metrics: Dict, 
                                          save_dir: str, visualizer):
        """Create comprehensive visualization suite"""
        os.makedirs(save_dir, exist_ok=True)
        
        # 1. Main comparison chart
        main_comparison_path = os.path.join(save_dir, "main_algorithm_comparison.png")
        visualizer.create_algorithm_comparison_plot(comprehensive_metrics, main_comparison_path)
        
        # 2. Performance radar chart  
        radar_path = os.path.join(save_dir, "performance_radar_chart.png")
        visualizer.create_performance_radar_chart(comprehensive_metrics, radar_path)
        
        # 3. Detailed comparison table
        table_path = os.path.join(save_dir, "detailed_comparison_table.png")
        visualizer.create_detailed_comparison_table(comprehensive_metrics, table_path)
        
        # 4. Statistical analysis plots
        self._create_statistical_plots(comprehensive_metrics, save_dir)
        
        # 5. Performance trends
        self._create_performance_trends(comprehensive_metrics, save_dir)
        
        self.logger.info(f"Comprehensive visualizations saved to {save_dir}")
    
    def _create_statistical_plots(self, comprehensive_metrics: Dict, save_dir: str):
        """Create statistical analysis plots"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('Statistical Performance Analysis', fontsize=16, fontweight='bold')
            
            algorithms = list(comprehensive_metrics.keys())
            
            # 1. Box plot for trajectory counts
            ax = axes[0, 0]
            traj_data = []
            labels = []
            
            for alg in algorithms:
                raw_data = comprehensive_metrics[alg]['raw_data']
                if raw_data['trajectory_count']:
                    traj_data.append(raw_data['trajectory_count'])
                    labels.append(alg)
            
            if traj_data:
                bp = ax.boxplot(traj_data, labels=labels, patch_artist=True)
                for patch, color in zip(bp['boxes'], plt.cm.Set1(np.linspace(0, 1, len(labels)))):
                    patch.set_facecolor(color)
                ax.set_title('Trajectory Count Distribution')
                ax.set_ylabel('Number of Trajectories')
                ax.tick_params(axis='x', rotation=45)
            
            # 2. Computation time variability
            ax = axes[0, 1]
            time_data = []
            time_labels = []
            
            for alg in algorithms:
                raw_data = comprehensive_metrics[alg]['raw_data']
                if raw_data['computation_times']:
                    time_data.append(raw_data['computation_times'])
                    time_labels.append(alg)
            
            if time_data:
                bp = ax.boxplot(time_data, labels=time_labels, patch_artist=True)
                for patch, color in zip(bp['boxes'], plt.cm.Set1(np.linspace(0, 1, len(time_labels)))):
                    patch.set_facecolor(color)
                ax.set_title('Computation Time Distribution')
                ax.set_ylabel('Time (seconds)')
                ax.tick_params(axis='x', rotation=45)
            
            # 3. Quality score histogram
            ax = axes[1, 0]
            for i, alg in enumerate(algorithms):
                raw_data = comprehensive_metrics[alg]['raw_data']
                if raw_data['quality_scores']:
                    ax.hist(raw_data['quality_scores'], alpha=0.7, 
                           label=alg, bins=20, density=True)
            
            ax.set_title('Quality Score Distribution')
            ax.set_xlabel('Quality Score')
            ax.set_ylabel('Density')
            ax.legend()
            
            # 4. Efficiency comparison
            ax = axes[1, 1]
            efficiencies = []
            eff_labels = []
            
            for alg in algorithms:
                eff = comprehensive_metrics[alg]['avg_efficiency_scores']
                efficiencies.append(eff)
                eff_labels.append(alg)
            
            bars = ax.bar(eff_labels, efficiencies, 
                         color=plt.cm.Set1(np.linspace(0, 1, len(eff_labels))), alpha=0.7)
            ax.set_title('Processing Efficiency Comparison')
            ax.set_ylabel('Trajectories per Second')
            ax.tick_params(axis='x', rotation=45)
            
            # Add value labels on bars
            for bar, eff in zip(bars, efficiencies):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                       f'{eff:.1f}', ha='center', va='bottom')
            
            plt.tight_layout()
            
            save_path = os.path.join(save_dir, "statistical_analysis.png")
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"Statistical plots saved to {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to create statistical plots: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def _create_performance_trends(self, comprehensive_metrics: Dict, save_dir: str):
        """Create performance trend analysis"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('Performance Trends Analysis', fontsize=16, fontweight='bold')
            
            algorithms = list(comprehensive_metrics.keys())
            colors = plt.cm.Set1(np.linspace(0, 1, len(algorithms)))
            
            # 1. Performance vs Speed Trade-off
            ax = axes[0, 0]
            for i, alg in enumerate(algorithms):
                metrics = comprehensive_metrics[alg]
                x = metrics['avg_computation_times']
                y = metrics['composite_performance_score']
                ax.scatter(x, y, s=100, c=[colors[i]], alpha=0.7, label=alg)
                ax.annotate(alg, (x, y), xytext=(5, 5), textcoords='offset points')
            
            ax.set_xlabel('Average Computation Time (s)')
            ax.set_ylabel('Composite Performance Score')
            ax.set_title('Performance vs Speed Trade-off')
            ax.grid(True, alpha=0.3)
            
            # 2. Quality vs Efficiency
            ax = axes[0, 1]
            for i, alg in enumerate(algorithms):
                metrics = comprehensive_metrics[alg]
                x = metrics['avg_efficiency_scores']
                y = metrics['avg_quality_scores']
                ax.scatter(x, y, s=100, c=[colors[i]], alpha=0.7, label=alg)
                ax.annotate(alg, (x, y), xytext=(5, 5), textcoords='offset points')
            
            ax.set_xlabel('Efficiency (trajectories/s)')
            ax.set_ylabel('Average Quality Score')
            ax.set_title('Quality vs Efficiency Trade-off')
            ax.grid(True, alpha=0.3)
            
            # 3. Consistency Analysis
            ax = axes[1, 0]
            consistency_metrics = []
            for alg in algorithms:
                metrics = comprehensive_metrics[alg]
                time_cv = metrics['std_computation_times'] / max(metrics['avg_computation_times'], 1e-6)
                quality_cv = metrics['std_quality_scores'] / max(metrics['avg_quality_scores'], 1e-6)
                consistency_score = 1.0 / (1.0 + time_cv + quality_cv)
                consistency_metrics.append(consistency_score)
            
            bars = ax.bar(algorithms, consistency_metrics, color=colors, alpha=0.7)
            ax.set_title('Algorithm Consistency Score')
            ax.set_ylabel('Consistency Score (higher is better)')
            ax.tick_params(axis='x', rotation=45)
            
            for bar, score in zip(bars, consistency_metrics):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                       f'{score:.3f}', ha='center', va='bottom')
            
            # 4. Overall Ranking
            ax = axes[1, 1]
            ranking_categories = ['Speed', 'Quality', 'Efficiency', 'Consistency']
            
            # Calculate rankings for each category
            speed_ranking = {alg: i+1 for i, (alg, _) in enumerate(
                sorted(comprehensive_metrics.items(), key=lambda x: x[1]['avg_computation_times']))}
            quality_ranking = {alg: i+1 for i, (alg, _) in enumerate(
                sorted(comprehensive_metrics.items(), key=lambda x: x[1]['avg_quality_scores'], reverse=True))}
            efficiency_ranking = {alg: i+1 for i, (alg, _) in enumerate(
                sorted(comprehensive_metrics.items(), key=lambda x: x[1]['avg_efficiency_scores'], reverse=True))}
            consistency_ranking = {alg: i+1 for i, (alg, score) in enumerate(
                sorted(zip(algorithms, consistency_metrics), key=lambda x: x[1], reverse=True))}
            
            # Create heatmap data
            ranking_data = []
            for alg in algorithms:
                ranking_data.append([
                    speed_ranking[alg],
                    quality_ranking[alg], 
                    efficiency_ranking[alg],
                    consistency_ranking[alg]
                ])
            
            im = ax.imshow(ranking_data, cmap='RdYlGn_r', aspect='auto')
            ax.set_xticks(range(len(ranking_categories)))
            ax.set_xticklabels(ranking_categories)
            ax.set_yticks(range(len(algorithms)))
            ax.set_yticklabels(algorithms)
            ax.set_title('Algorithm Ranking Heatmap (1=Best)')
            
            # Add text annotations
            for i in range(len(algorithms)):
                for j in range(len(ranking_categories)):
                    text = ax.text(j, i, ranking_data[i][j], ha="center", va="center", color="black")
            
            plt.colorbar(im, ax=ax)
            
            plt.tight_layout()
            
            save_path = os.path.join(save_dir, "performance_trends.png")
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"Performance trends saved to {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to create performance trends: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def export_results_to_csv(self, comprehensive_metrics: Dict, save_path: str):
        """Export detailed results to CSV for further analysis"""
        try:
            data_rows = []
            
            for algorithm_name, metrics in comprehensive_metrics.items():
                row = {
                    'Algorithm': algorithm_name,
                    'Avg_Trajectories': metrics['avg_trajectory_count'],
                    'Std_Trajectories': metrics['std_trajectory_count'],
                    'Avg_Computation_Time': metrics['avg_computation_times'],
                    'Std_Computation_Time': metrics['std_computation_times'],
                    'Avg_Quality': metrics['avg_quality_scores'],
                    'Std_Quality': metrics['std_quality_scores'],
                    'Avg_Length': metrics['avg_trajectory_lengths'],
                    'Std_Length': metrics['std_trajectory_lengths'],
                    'Avg_Efficiency': metrics['avg_efficiency_scores'],
                    'Composite_Score': metrics['composite_performance_score'],
                    'Min_Trajectories': metrics['min_trajectory_count'],
                    'Max_Trajectories': metrics['max_trajectory_count'],
                    'Min_Time': metrics['min_computation_times'],
                    'Max_Time': metrics['max_computation_times'],
                    'Min_Quality': metrics['min_quality_scores'],
                    'Max_Quality': metrics['max_quality_scores']
                }
                data_rows.append(row)
            
            df = pd.DataFrame(data_rows)
            df.to_csv(save_path, index=False)
            
            self.logger.info(f"Results exported to CSV: {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to export results to CSV: {e}")


def run_enhanced_algorithm_comparison(config, all_results, visualizer):
    """Run enhanced algorithm comparison with improved analysis"""
    comparison = EnhancedAlgorithmComparison(config)
    
    print("\n" + "="*60)
    print("Running Enhanced Algorithm Comparison Analysis...")
    print("="*60)
    
    try:
        # Calculate comprehensive metrics
        print("📊 Calculating comprehensive performance metrics...")
        comprehensive_metrics = comparison.calculate_comprehensive_metrics(all_results)
        
        if not comprehensive_metrics:
            print("❌ No algorithm results available for comparison")
            return None
        
        print(f"✓ Analyzed {len(comprehensive_metrics)} algorithms")
        
        # Generate detailed report
        print("📝 Generating detailed analysis report...")
        detailed_report = comparison.generate_detailed_report(comprehensive_metrics)
        
        # Save report
        comparison_dir = os.path.join(config.RESULTS_ROOT, "algorithm_comparison")
        os.makedirs(comparison_dir, exist_ok=True)
        
        report_path = os.path.join(comparison_dir, "enhanced_comparison_report.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(detailed_report)
        
        print(f"✓ Detailed report saved: {report_path}")
        
        # Create comprehensive visualizations
        print("📈 Creating comprehensive visualizations...")
        comparison.create_comprehensive_visualizations(
            comprehensive_metrics, comparison_dir, visualizer)
        
        # Export to CSV for further analysis
        csv_path = os.path.join(comparison_dir, "algorithm_metrics.csv")
        comparison.export_results_to_csv(comprehensive_metrics, csv_path)
        
        # Display summary
        print("\n" + "="*60)
        print("ALGORITHM COMPARISON SUMMARY")
        print("="*60)
        
        # Find best performers
        best_overall = max(comprehensive_metrics.items(), 
                          key=lambda x: x[1]['composite_performance_score'])
        fastest = min(comprehensive_metrics.items(), 
                     key=lambda x: x[1]['avg_computation_times'])
        highest_quality = max(comprehensive_metrics.items(), 
                            key=lambda x: x[1]['avg_quality_scores'])
        
        print(f"🏆 Best Overall: {best_overall[0].upper()} (Score: {best_overall[1]['composite_performance_score']:.3f})")
        print(f"⚡ Fastest: {fastest[0].upper()} ({fastest[1]['avg_computation_times']:.4f}s)")
        print(f"🎯 Highest Quality: {highest_quality[0].upper()} (Score: {highest_quality[1]['avg_quality_scores']:.3f})")
        
        print(f"\n📂 Results Location:")
        print(f"   • Report: {report_path}")
        print(f"   • Visualizations: {comparison_dir}")
        print(f"   • CSV Data: {csv_path}")
        
        print("\n" + "="*60)
        print("Enhanced Algorithm Comparison Complete! 🎉")
        print("="*60)
        
        return {
            'comprehensive_metrics': comprehensive_metrics,
            'report_path': report_path,
            'visualization_dir': comparison_dir,
            'csv_path': csv_path
        }
        
    except Exception as e:
        logging.getLogger(__name__).error(f"Enhanced algorithm comparison failed: {e}")
        print(f"❌ Algorithm comparison failed: {e}")
        return None

# ========== config.py ==========
# 相对路径: config.py
# 在项目中的相对位置: ./config.py

import os
import numpy as np

class Config:
    # Data path configuration
    DATA_ROOT = "../data/ds005262"
    RESULTS_ROOT = "./results"
    LOGS_ROOT = "./logs"
    
    # Ensure directories exist
    for path in [RESULTS_ROOT, LOGS_ROOT, 
                 os.path.join(RESULTS_ROOT, "topographies"),
                 os.path.join(RESULTS_ROOT, "trajectories"),
                 os.path.join(RESULTS_ROOT, "analysis"),
                 os.path.join(RESULTS_ROOT, "videos"),
                 os.path.join(RESULTS_ROOT, "algorithm_comparison")]:
        os.makedirs(path, exist_ok=True)
    
    # EEG data processing parameters
    SAMPLING_RATE = 500  
    LOW_FREQ = 1.0       
    HIGH_FREQ = 50.0     
    
    # Topography generation parameters
    TOPO_SIZE = (128, 128)
    INTERPOLATION_METHOD = 'cubic'
     
    # 帧数控制参数 - 新增
    MAX_FRAMES_PER_EPOCH = 300          # 每个epoch最多处理的帧数
    MAX_ANIMATION_FRAMES = 300          # 动画最大帧数
    MAX_SAVE_FRAMES = 50                # 保存帧序列的最大帧数
    
    # 实验规模配置 - 支持所有被试
    MAX_SUBJECTS = 12               # 处理所有12个被试
    MAX_EPOCHS_PER_SUBJECT = 3      # 每个被试处理3个epoch
    MAX_SESSIONS_PER_SUBJECT = 5    # 每个被试最多处理5个session
    MEMORY_LIMIT_MB = 4096          # 增加内存限制

    
    # Algorithm comparison configuration
    ENABLE_ALGORITHM_COMPARISON = True
    COMPARISON_ALGORITHMS = [
        'greedy',           # Greedy matching (original default)
        'hungarian',        # Hungarian algorithm
        'kalman',          # Kalman prediction
        'overlap',         # Overlap matching
        'hybrid'           # Hybrid algorithm
    ]
    
    # Target tracking parameters
    THRESHOLD_PERCENTILE = 88
    MIN_REGION_SIZE = 25       
    MAX_REGIONS = 6            
    
    # Trajectory analysis parameters
    TIME_WINDOW = 2.0          
    TRAJECTORY_SMOOTH_FACTOR = 3  
    
    # Visualization parameters
    COLORMAP = 'RdYlBu_r'      
    FPS = 10                   
    DPI = 150                  
    
    # Algorithm-specific parameters
    ALGORITHM_CONFIGS = {
        'greedy': {
            'distance_threshold': 25.0,
            'enable_prediction': False,
            'enable_reconnection': True,
            'max_inactive_frames': 25,
            'description': 'Greedy matching algorithm - fast local optimum'
        },
        'hungarian': {
            'distance_threshold': 25.0,
            'enable_prediction': False,
            'enable_reconnection': True,
            'max_inactive_frames': 25,
            'description': 'Hungarian algorithm - global optimal matching'
        },
        'kalman': {
            'distance_threshold': 30.0,
            'enable_prediction': True,
            'prediction_weight': 0.4,
            'enable_reconnection': True,
            'max_inactive_frames': 30,
            'description': 'Kalman prediction algorithm - motion-based prediction'
        },
        'overlap': {
            'overlap_threshold': 0.3,
            'distance_threshold': 35.0,
            'enable_reconnection': True,
            'max_inactive_frames': 20,
            'description': 'Overlap matching - region overlap based'
        },
        'hybrid': {
            'distance_threshold': 25.0,
            'overlap_weight': 0.4,
            'intensity_weight': 0.1,
            'area_weight': 0.1,
            'enable_prediction': True,
            'enable_reconnection': True,
            'max_inactive_frames': 30,
            'description': 'Hybrid algorithm - comprehensive multi-feature'
        }
    }
    
    # Performance evaluation metrics
    EVALUATION_METRICS = [
        'trajectory_count',           
        'average_trajectory_length',  
        'max_trajectory_length',     
        'tracking_continuity',       
        'trajectory_smoothness',     
        'computation_time',          
        'memory_usage',             
        'detection_stability',      
        'trajectory_quality'        
    ]
    
    # Visualization configuration
    VISUALIZATION_CONFIG = {
        'generate_comparison_plots': True,    
        'generate_heatmaps': True,           
        'generate_trajectory_overlays': True, 
        'generate_detailed_reports': True,    
        'save_individual_results': True,     
        'create_summary_animations': False   # Disabled for performance
    }
    
    # Tracking optimization parameters
    TRACKING_OPTIMIZATION = {
        'enable_adaptive_threshold': True,     
        'enable_prediction': True,             
        'enable_reconnection': True,           
        'base_distance_threshold': 25.0,      
        'max_distance_threshold': 60.0,       
        'reconnection_distance': 40.0,        
        'max_inactive_frames': 25,            
        'prediction_weight': 0.3,             
        'quality_threshold': 0.2,             
        'min_trajectory_length': 3            
    }
    
    # Visualization optimization parameters
    VISUALIZATION_OPTIMIZATION = {
        'auto_font_detection': False,         # Disabled to avoid Chinese font issues
        'fallback_to_english': True,         
        'max_animation_frames': MAX_ANIMATION_FRAMES,
        'save_frame_sequence_fallback': True, 
        'trajectory_alpha': 0.8,             
        'show_direction_arrows': True,       
        'legend_max_items': 10               
    }
    
    # Standard electrode positions
    ELECTRODE_POSITIONS = {
        'Fp1': (-0.3, 0.85), 'Fp2': (0.3, 0.85), 'Fpz': (0, 0.9),
        'F7': (-0.7, 0.4), 'F3': (-0.4, 0.4), 'Fz': (0, 0.4), 'F4': (0.4, 0.4), 'F8': (0.7, 0.4),
        'FC5': (-0.5, 0.2), 'FC1': (-0.2, 0.2), 'FCz': (0, 0.2), 'FC2': (0.2, 0.2), 'FC6': (0.5, 0.2),
        'T7': (-0.85, 0), 'C3': (-0.4, 0), 'Cz': (0, 0), 'C4': (0.4, 0), 'T8': (0.85, 0),
        'CP5': (-0.5, -0.2), 'CP1': (-0.2, -0.2), 'CPz': (0, -0.2), 'CP2': (0.2, -0.2), 'CP6': (0.5, -0.2),
        'P7': (-0.7, -0.4), 'P3': (-0.4, -0.4), 'Pz': (0, -0.4), 'P4': (0.4, -0.4), 'P8': (0.7, -0.4),
        'PO9': (-0.8, -0.65), 'PO7': (-0.6, -0.65), 'PO3': (-0.25, -0.65), 'POz': (0, -0.65), 
        'PO4': (0.25, -0.65), 'PO8': (0.6, -0.65), 'PO10': (0.8, -0.65),
        'O1': (-0.3, -0.85), 'Oz': (0, -0.9), 'O2': (0.3, -0.85),
        
        # Additional electrodes
        'AF7': (-0.5, 0.65), 'AF3': (-0.25, 0.65), 'AFz': (0, 0.65), 'AF4': (0.25, 0.65), 'AF8': (0.5, 0.65),
        'F5': (-0.55, 0.4), 'F1': (-0.2, 0.4), 'F2': (0.2, 0.4), 'F6': (0.55, 0.4),
        'FT9': (-0.9, 0.2), 'FT7': (-0.75, 0.2), 'FT8': (0.75, 0.2), 'FT10': (0.9, 0.2),
        'C5': (-0.55, 0), 'C1': (-0.2, 0), 'C2': (0.2, 0), 'C6': (0.55, 0),
        'TP9': (-0.9, -0.2), 'TP7': (-0.75, -0.2), 'TP8': (0.75, -0.2), 'TP10': (0.9, -0.2),
        'P5': (-0.55, -0.4), 'P1': (-0.2, -0.4), 'P2': (0.2, -0.4), 'P6': (0.55, -0.4),
        
        # Case variants
        'FP1': (-0.3, 0.85), 'FP2': (0.3, 0.85),
        'fp1': (-0.3, 0.85), 'fp2': (0.3, 0.85), 'fpz': (0, 0.9),
        'f7': (-0.7, 0.4), 'f3': (-0.4, 0.4), 'fz': (0, 0.4), 'f4': (0.4, 0.4), 'f8': (0.7, 0.4),
        't7': (-0.85, 0), 'c3': (-0.4, 0), 'cz': (0, 0), 'c4': (0.4, 0), 't8': (0.85, 0),
        'p7': (-0.7, -0.4), 'p3': (-0.4, -0.4), 'pz': (0, -0.4), 'p4': (0.4, -0.4), 'p8': (0.7, -0.4),
        'o1': (-0.3, -0.85), 'oz': (0, -0.9), 'o2': (0.3, -0.85),
    }
    
    # Frame control methods
    @classmethod
    def get_max_frames(cls, frame_type: str = 'epoch') -> int:
        """Get maximum frame limit"""
        frame_limits = {
            'epoch': cls.MAX_FRAMES_PER_EPOCH,
            'animation': cls.MAX_ANIMATION_FRAMES,
            'save': cls.MAX_SAVE_FRAMES
        }
        return frame_limits.get(frame_type, cls.MAX_FRAMES_PER_EPOCH)
    
    @classmethod
    def set_max_frames(cls, max_frames: int, frame_type: str = 'epoch'):
        """Dynamically set maximum frames"""
        if frame_type == 'epoch':
            cls.MAX_FRAMES_PER_EPOCH = max_frames
        elif frame_type == 'animation':
            cls.MAX_ANIMATION_FRAMES = max_frames
        elif frame_type == 'save':
            cls.MAX_SAVE_FRAMES = max_frames
        
        # Sync related configuration
        cls.VISUALIZATION_OPTIMIZATION['max_animation_frames'] = cls.MAX_ANIMATION_FRAMES
    
    @staticmethod
    def get_default_electrode_position(ch_name: str, n_channels: int, ch_index: int):
        """Generate default position for unknown electrodes"""
        angle = 2 * np.pi * ch_index / n_channels
        radius = 0.7
        x = radius * np.cos(angle)
        y = radius * np.sin(angle)
        return (x, y)
    
    @classmethod
    def get_algorithm_config(cls, algorithm_name: str):
        """Get specific algorithm configuration"""
        return cls.ALGORITHM_CONFIGS.get(algorithm_name, cls.ALGORITHM_CONFIGS['greedy'])
    
    @classmethod
    def get_experiment_summary(cls):
        """Get experiment configuration summary"""
        return {
            'total_subjects': cls.MAX_SUBJECTS,
            'algorithms_count': len(cls.COMPARISON_ALGORITHMS),
            'algorithm_names': cls.COMPARISON_ALGORITHMS,
            'metrics_count': len(cls.EVALUATION_METRICS),
            'max_epochs_per_subject': cls.MAX_EPOCHS_PER_SUBJECT,
            'max_sessions_per_subject': cls.MAX_SESSIONS_PER_SUBJECT,
            'max_frames_per_epoch': cls.MAX_FRAMES_PER_EPOCH,
            'algorithm_comparison_enabled': cls.ENABLE_ALGORITHM_COMPARISON
        }
    
    @classmethod
    def auto_adjust_parameters(cls, data_characteristics: dict):
        """Auto-adjust parameters based on data characteristics"""
        if 'signal_strength' in data_characteristics:
            signal_strength = data_characteristics['signal_strength']
            
            if signal_strength < 0.3:  # Weak signal
                cls.THRESHOLD_PERCENTILE = 85
                cls.MIN_REGION_SIZE = 15
                print("✓ Detected weak signal, adjusted to high sensitivity parameters")
                
            elif signal_strength > 0.8:  # Strong signal
                cls.THRESHOLD_PERCENTILE = 92
                cls.MIN_REGION_SIZE = 40
                print("✓ Detected strong signal, adjusted to high precision parameters")
        
        if 'noise_level' in data_characteristics:
            noise_level = data_characteristics['noise_level']
            
            if noise_level > 0.6:  # High noise
                cls.TRAJECTORY_SMOOTH_FACTOR = 5
                print("✓ Detected high noise, enabled strong smoothing")
            elif noise_level < 0.2:  # Low noise
                cls.TRAJECTORY_SMOOTH_FACTOR = 2
                print("✓ Detected low noise, enabled fine tracking")
    
    @classmethod
    def get_config_summary(cls):
        """Get current configuration summary"""
        summary = {
            'detection_sensitivity': 'High' if cls.THRESHOLD_PERCENTILE < 90 else 'Medium' if cls.THRESHOLD_PERCENTILE < 95 else 'Low',
            'tracking_aggressiveness': 'High' if cls.TRACKING_OPTIMIZATION['base_distance_threshold'] > 25 else 'Medium',
            'quality_filter': 'Strict' if cls.TRACKING_OPTIMIZATION['quality_threshold'] > 0.25 else 'Lenient',
            'smoothing_level': 'High' if cls.TRAJECTORY_SMOOTH_FACTOR > 4 else 'Medium' if cls.TRAJECTORY_SMOOTH_FACTOR > 2 else 'Low',
            'algorithm_comparison': 'Enabled' if cls.ENABLE_ALGORITHM_COMPARISON else 'Disabled',
            'algorithms_to_compare': len(cls.COMPARISON_ALGORITHMS),
            'max_frames_per_epoch': cls.MAX_FRAMES_PER_EPOCH
        }
        return summary

# ========== main.py ==========
# 相对路径: main.py
# 在项目中的相对位置: ./main.py

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced EEG Topography Motion Trajectory Analysis Main Program
Algorithm Comparison Edition with Improved Visualization and Analysis
Version: 3.1.0 - Enhanced Edition
Updated: 2025-08-01
"""

import os
import sys
import logging
import json
import pickle
import numpy as np
import gc
import argparse
import platform
from datetime import datetime
from tqdm import tqdm
import warnings
import time

# Suppress warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# Add paths
sys.path.append('src')
sys.path.append('trackers')

# Font configuration - English only
def setup_matplotlib_font():
    """Configure matplotlib font for English only"""
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    
    try:
        fm._rebuild()
    except:
        pass
    
    # Use safe English fonts only
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Liberation Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    print("✓ Font configuration: English labels only")
    return True

# Set up font
USE_ENGLISH_ONLY = setup_matplotlib_font()

from config import Config
from src import EEGDataLoader, TopographyGenerator, TrajectoryAnalyzer, Visualizer
from trackers import TrackerFactory
from algorithm_comparison import run_enhanced_algorithm_comparison

def setup_logging():
    """Set up logging system"""
    log_dir = Config.LOGS_ROOT
    os.makedirs(log_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(log_dir, f"enhanced_experiment_{timestamp}.log")
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    logging.basicConfig(
        level=logging.INFO,
        handlers=[file_handler, console_handler]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"Enhanced logging system initialized: {log_file}")
    
    return logger

def check_dependencies():
    """Check required dependencies"""
    required_packages = {
        'mne': 'MNE-Python',
        'numpy': 'NumPy',
        'scipy': 'SciPy',
        'matplotlib': 'Matplotlib',
        'sklearn': 'Scikit-learn',
        'cv2': 'OpenCV',
        'tqdm': 'tqdm',
        'pandas': 'Pandas',
        'seaborn': 'Seaborn'
    }
    
    missing_packages = []
    
    for package, name in required_packages.items():
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(name)
    
    if missing_packages:
        print("❌ Missing required dependencies:")
        for package in missing_packages:
            print(f"  - {package}")
        print("\nPlease install using: pip install -r requirements.txt")
        return False
    
    return True

def print_system_info():
    """Print system information"""
    print("=" * 80)
    print("EEG TOPOGRAPHY MOTION TRAJECTORY ANALYSIS SYSTEM")
    print("Enhanced Algorithm Comparison Edition")
    print("=" * 80)
    print(f"Python Version: {platform.python_version()}")
    print(f"Operating System: {platform.system()} {platform.release()}")
    print(f"Processor: {platform.machine()}")
    print(f"Font Support: English Only (for compatibility)")
    
    # Display experiment configuration
    summary = Config.get_experiment_summary()
    print(f"\nExperiment Configuration:")
    print(f"  • Subjects to Process: {summary['total_subjects']}")
    print(f"  • Algorithm Comparison: {len(summary['algorithm_names'])} algorithms")
    print(f"  • Algorithms: {', '.join(summary['algorithm_names'])}")
    print(f"  • Evaluation Metrics: {summary['metrics_count']}")
    print(f"  • Max Frames per Epoch: {summary['max_frames_per_epoch']}")
    print(f"  • Max Epochs per Subject: {summary['max_epochs_per_subject']}")
    print(f"  • Algorithm Comparison: {'Enabled' if summary['algorithm_comparison_enabled'] else 'Disabled'}")
    
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"  • Total Memory: {memory.total / (1024**3):.1f} GB")
        print(f"  • Available Memory: {memory.available / (1024**3):.1f} GB")
    except ImportError:
        pass
    
    print("=" * 80)

def validate_config():
    """Validate configuration parameters"""
    logger = logging.getLogger(__name__)
    
    # Check data directory
    if not os.path.exists(Config.DATA_ROOT):
        error_msg = f"Data directory not found: {Config.DATA_ROOT}"
        logger.error(error_msg)
        print(f"\n❌ {error_msg}")
        print("Please check DATA_ROOT setting in config.py")
        return False
    
    # Validate algorithm configuration
    validation_results = TrackerFactory.validate_algorithm_config(Config)
    invalid_algorithms = [alg for alg, valid in validation_results.items() if not valid]
    
    if invalid_algorithms:
        logger.warning(f"Invalid algorithm configurations: {invalid_algorithms}")
        print(f"⚠️  Potentially problematic algorithm configurations: {', '.join(invalid_algorithms)}")
    
    # Check available algorithms
    available = TrackerFactory.get_available_algorithms()
    missing = [alg for alg in Config.COMPARISON_ALGORITHMS if alg not in available]
    
    if missing:
        logger.error(f"Unavailable algorithms: {missing}")
        print(f"❌ Unavailable algorithms: {', '.join(missing)}")
        return False
    
    # Validate frame configuration
    if Config.MAX_FRAMES_PER_EPOCH <= 0:
        logger.error(f"Invalid max frames configuration: {Config.MAX_FRAMES_PER_EPOCH}")
        print(f"❌ Invalid max frames configuration: {Config.MAX_FRAMES_PER_EPOCH}")
        return False
    
    logger.info(f"Configuration validation complete, max frames limit: {Config.MAX_FRAMES_PER_EPOCH}")
    return True

def process_subject_with_multiple_algorithms(data_loader, topo_generator, analyzer, visualizer,
                                           subject_id, sessions, logger):
    """Process single subject data with multiple algorithms"""
    subject_results = {}
    
    logger.info(f"Processing subject {subject_id} ({len(sessions)} sessions, {len(Config.COMPARISON_ALGORITHMS)} algorithms)")
    
    # Create all trackers
    trackers = TrackerFactory.create_all_trackers(Config)
    if not trackers:
        logger.error(f"Unable to create trackers")
        return None
    
    logger.info(f"Successfully created {len(trackers)} trackers: {', '.join(trackers.keys())}")
    
    session_progress = 0
    total_sessions = len(sessions)
    
    for session_id, session_data in sessions.items():
        session_progress += 1
        session_key = f"{subject_id}_{session_id}"
        logger.info(f"  Processing session {session_id} ({session_progress}/{total_sessions})")
        
        try:
            epochs = session_data['epochs']
            positions = session_data['positions']
            ch_names = epochs.ch_names
            
            # Select multiple epochs for analysis
            n_epochs_to_analyze = min(len(epochs), Config.MAX_EPOCHS_PER_SUBJECT)
            
            session_algorithm_results = {}
            
            epoch_progress = 0
            for epoch_idx in range(n_epochs_to_analyze):
                epoch_progress += 1
                
                try:
                    epoch_data = epochs.get_data()[epoch_idx]
                    
                    # Generate topography sequence
                    logger.info(f"    Generating epoch {epoch_idx+1} topography sequence...")
                    
                    # Use configuration parameters to limit time points
                    max_time_points = min(epoch_data.shape[1], Config.MAX_FRAMES_PER_EPOCH)
                    epoch_data_subset = epoch_data[:, :max_time_points]
                    
                    logger.info(f"    Using frame limit: {Config.MAX_FRAMES_PER_EPOCH}, processing: {max_time_points} frames")
                    
                    topographies = topo_generator.generate_time_series_topographies(
                        epoch_data_subset[np.newaxis, :, :], positions, ch_names
                    )[0]
                    
                    if topographies is None or topographies.size == 0:
                        logger.warning(f"    Epoch {epoch_idx+1}: topography generation failed")
                        continue
                    
                    # Normalize topographies
                    for t in range(topographies.shape[0]):
                        topographies[t] = topo_generator.normalize_topography(topographies[t])
                    
                    # Use each algorithm for trajectory tracking
                    epoch_algorithm_results = {}
                    algorithm_progress = 0
                    
                    for algorithm_name, tracker in trackers.items():
                        algorithm_progress += 1
                        
                        try:
                            logger.info(f"    Tracking epoch {epoch_idx+1} with {algorithm_name} algorithm "
                                      f"({algorithm_progress}/{len(trackers)})...")
                            
                            start_time = time.time()
                            tracking_results = tracker.track_sequence(topographies)
                            end_time = time.time()
                            
                            if not tracking_results or 'trajectories' not in tracking_results:
                                logger.warning(f"    {algorithm_name}: Epoch {epoch_idx+1} tracking returned empty results")
                                continue
                            
                            trajectories = tracking_results['trajectories']
                            if not trajectories:
                                logger.warning(f"    {algorithm_name}: Epoch {epoch_idx+1} no valid trajectories detected")
                                continue
                            
                            # Record results
                            epoch_algorithm_results[algorithm_name] = {
                                'trajectories': trajectories,
                                'metrics': tracking_results.get('metrics', {}),
                                'summary': tracking_results.get('summary', {}),
                                'computation_time': end_time - start_time,
                                'processed_frames': topographies.shape[0],
                                'tracking_results': tracking_results  # Keep full results for visualization
                            }
                            
                            logger.info(f"    {algorithm_name}: Epoch {epoch_idx+1} found {len(trajectories)} trajectories "
                                      f"(processed {topographies.shape[0]} frames, time: {end_time - start_time:.3f}s)")
                            
                        except Exception as e:
                            logger.error(f"    {algorithm_name}: Epoch {epoch_idx+1} tracking failed: {e}")
                            continue
                    
                    # If results exist, save epoch-level comparisons
                    if epoch_algorithm_results:
                        # Save representative visualizations for each algorithm
                        for algorithm_name, results in epoch_algorithm_results.items():
                            trajectories = results['trajectories']
                            
                            # Save trajectory plot
                            traj_path = os.path.join(Config.RESULTS_ROOT, "trajectories", 
                                                   f"{session_key}_epoch{epoch_idx}_{algorithm_name}_trajectories.png")
                            try:
                                title = f"Subject {subject_id} Session {session_id} Epoch {epoch_idx} - {algorithm_name.upper()} Algorithm ({results['processed_frames']} frames)"
                                visualizer.plot_trajectories(
                                    trajectories, topographies.shape[1:],
                                    title=title,
                                    save_path=traj_path
                                )
                            except Exception as e:
                                logger.warning(f"Failed to save {algorithm_name} trajectory plot: {e}")
                        
                        # Merge epoch results into session results
                        for algorithm_name, results in epoch_algorithm_results.items():
                            if algorithm_name not in session_algorithm_results:
                                session_algorithm_results[algorithm_name] = {
                                    'trajectories': {},
                                    'total_computation_time': 0,
                                    'epoch_count': 0,
                                    'metrics_sum': {},
                                    'total_frames_processed': 0
                                }
                            
                            # Merge trajectories (add epoch prefix)
                            for traj_id, traj_data in results['trajectories'].items():
                                key = f"epoch{epoch_idx}_{traj_id}"
                                session_algorithm_results[algorithm_name]['trajectories'][key] = traj_data
                            
                            # Accumulate statistics
                            session_algorithm_results[algorithm_name]['total_computation_time'] += results['computation_time']
                            session_algorithm_results[algorithm_name]['epoch_count'] += 1
                            session_algorithm_results[algorithm_name]['total_frames_processed'] += results['processed_frames']
                            
                            # Accumulate metrics
                            for metric, value in results.get('metrics', {}).items():
                                if metric not in session_algorithm_results[algorithm_name]['metrics_sum']:
                                    session_algorithm_results[algorithm_name]['metrics_sum'][metric] = []
                                session_algorithm_results[algorithm_name]['metrics_sum'][metric].append(value)
                    
                    # Memory cleanup
                    del topographies
                    gc.collect()
                    
                except Exception as e:
                    logger.error(f"    Epoch {epoch_idx+1} processing failed: {e}")
                    continue
            
            # Process session-level results
            if session_algorithm_results:
                # Calculate average metrics
                for algorithm_name in session_algorithm_results:
                    alg_result = session_algorithm_results[algorithm_name]
                    
                    # Calculate average metrics
                    avg_metrics = {}
                    for metric, values in alg_result['metrics_sum'].items():
                        if values:
                            avg_metrics[metric] = np.mean(values)
                    
                    # Update results
                    alg_result['average_metrics'] = avg_metrics
                    alg_result['total_trajectories'] = len(alg_result['trajectories'])
                    alg_result['avg_frames_per_epoch'] = alg_result['total_frames_processed'] / alg_result['epoch_count'] if alg_result['epoch_count'] > 0 else 0
                    
                    session_algorithm_results[algorithm_name] = alg_result
                
                subject_results[session_id] = session_algorithm_results
                
                logger.info(f"  Session {session_id}: algorithm comparison completed")
                
                # Display brief results for each algorithm
                for algorithm_name, alg_result in session_algorithm_results.items():
                    logger.info(f"    {algorithm_name}: {alg_result['total_trajectories']} trajectories, "
                              f"avg time {alg_result['total_computation_time']/alg_result['epoch_count']:.3f}s, "
                              f"avg frames {alg_result['avg_frames_per_epoch']:.0f}/epoch")
            else:
                logger.warning(f"  Session {session_id}: all algorithms failed to find valid trajectories")
                
        except Exception as e:
            logger.error(f"  Error processing session {session_id}: {e}")
            continue
    
    return subject_results if subject_results else None

def create_enhanced_summary_report(all_results, logger):
    """Create enhanced summary report with detailed insights"""
    logger.info("Generating enhanced summary report...")
    
    try:
        # Collect comprehensive statistics
        algorithm_stats = {}
        subject_performance = {}
        
        for subject_id, sessions in all_results.items():
            subject_performance[subject_id] = {}
            
            for session_id, session_data in sessions.items():
                for algorithm_name, alg_data in session_data.items():
                    if algorithm_name not in algorithm_stats:
                        algorithm_stats[algorithm_name] = {
                            'total_trajectories': [],
                            'computation_times': [],
                            'trajectory_lengths': [],
                            'trajectory_qualities': [],
                            'frames_processed': [],
                            'sessions_processed': 0
                        }
                    
                    # Collect statistics
                    algorithm_stats[algorithm_name]['total_trajectories'].append(alg_data['total_trajectories'])
                    algorithm_stats[algorithm_name]['computation_times'].append(alg_data['total_computation_time'])
                    algorithm_stats[algorithm_name]['frames_processed'].append(alg_data.get('total_frames_processed', 0))
                    algorithm_stats[algorithm_name]['sessions_processed'] += 1
                    
                    # Collect trajectory statistics
                    for traj_data in alg_data['trajectories'].values():
                        algorithm_stats[algorithm_name]['trajectory_lengths'].append(traj_data['length'])
                        algorithm_stats[algorithm_name]['trajectory_qualities'].append(traj_data.get('quality_score', 0))
                    
                    # Track subject performance
                    if algorithm_name not in subject_performance[subject_id]:
                        subject_performance[subject_id][algorithm_name] = {
                            'total_trajectories': 0,
                            'total_time': 0,
                            'sessions': 0
                        }
                    
                    subject_performance[subject_id][algorithm_name]['total_trajectories'] += alg_data['total_trajectories']
                    subject_performance[subject_id][algorithm_name]['total_time'] += alg_data['total_computation_time']
                    subject_performance[subject_id][algorithm_name]['sessions'] += 1
        
        # Generate enhanced report
        report = []
        report.append("=" * 100)
        report.append("ENHANCED EEG TRAJECTORY TRACKING ALGORITHM COMPARISON REPORT")
        report.append("=" * 100)
        report.append(f"Experiment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"Total Subjects Processed: {len(all_results)}")
        report.append(f"Total Sessions Analyzed: {sum(len(sessions) for sessions in all_results.values())}")
        report.append(f"Algorithms Compared: {len(algorithm_stats)}")
        report.append(f"Frame Limit Configuration: {Config.MAX_FRAMES_PER_EPOCH} frames/epoch")
        report.append("")
        
        # Executive Summary
        report.append("EXECUTIVE SUMMARY")
        report.append("=" * 50)
        
        best_performers = {}
        for category in ['total_trajectories', 'computation_times', 'trajectory_qualities']:
            if category == 'computation_times':
                # Lower is better for computation time
                best_alg = min(algorithm_stats.items(), 
                             key=lambda x: np.mean(x[1][category]) if x[1][category] else float('inf'))
                best_performers[category] = (best_alg[0], np.mean(best_alg[1][category]))
            else:
                # Higher is better for other metrics
                best_alg = max(algorithm_stats.items(), 
                             key=lambda x: np.mean(x[1][category]) if x[1][category] else 0)
                best_performers[category] = (best_alg[0], np.mean(best_alg[1][category]))
        
        report.append(f"🏆 Most Trajectories Detected: {best_performers['total_trajectories'][0].upper()} "
                     f"({best_performers['total_trajectories'][1]:.1f} avg)")
        report.append(f"⚡ Fastest Processing: {best_performers['computation_times'][0].upper()} "
                     f"({best_performers['computation_times'][1]:.4f}s avg)")
        report.append(f"🎯 Highest Quality: {best_performers['trajectory_qualities'][0].upper()} "
                     f"({best_performers['trajectory_qualities'][1]:.3f} avg quality)")
        report.append("")
        
        # Detailed Algorithm Performance
        report.append("DETAILED ALGORITHM PERFORMANCE ANALYSIS")
        report.append("=" * 60)
        
        for algorithm_name, stats in algorithm_stats.items():
            if not stats['total_trajectories']:
                continue
            
            avg_trajectories = np.mean(stats['total_trajectories'])
            std_trajectories = np.std(stats['total_trajectories'])
            avg_time = np.mean(stats['computation_times'])
            std_time = np.std(stats['computation_times'])
            avg_quality = np.mean(stats['trajectory_qualities']) if stats['trajectory_qualities'] else 0
            std_quality = np.std(stats['trajectory_qualities']) if stats['trajectory_qualities'] else 0
            avg_length = np.mean(stats['trajectory_lengths']) if stats['trajectory_lengths'] else 0
            avg_frames = np.mean(stats['frames_processed']) if stats['frames_processed'] else 0
            
            # Calculate efficiency and consistency
            efficiency = avg_trajectories / max(avg_time, 1e-6)
            time_consistency = 1.0 / (1.0 + std_time / max(avg_time, 1e-6))
            quality_consistency = 1.0 / (1.0 + std_quality / max(avg_quality, 1e-6)) if avg_quality > 0 else 0
            
            report.append(f"\n{algorithm_name.upper()} ALGORITHM ANALYSIS:")
            report.append("-" * (len(algorithm_name) + 20))
            report.append(f"  Sessions Processed: {stats['sessions_processed']}")
            report.append(f"  Average Trajectories: {avg_trajectories:.2f} ± {std_trajectories:.2f}")
            report.append(f"  Average Processing Time: {avg_time:.4f}s ± {std_time:.4f}s")
            report.append(f"  Average Trajectory Quality: {avg_quality:.3f} ± {std_quality:.3f}")
            report.append(f"  Average Trajectory Length: {avg_length:.1f} frames")
            report.append(f"  Average Frames Processed: {avg_frames:.0f}/session")
            report.append(f"  Processing Efficiency: {efficiency:.1f} trajectories/second")
            report.append(f"  Time Consistency: {time_consistency:.3f}")
            report.append(f"  Quality Consistency: {quality_consistency:.3f}")
            
            # Performance rating
            if efficiency > 10 and avg_quality > 0.7 and time_consistency > 0.8:
                rating = "EXCELLENT"
            elif efficiency > 5 and avg_quality > 0.5 and time_consistency > 0.6:
                rating = "GOOD"
            elif efficiency > 2 and avg_quality > 0.3:
                rating = "FAIR"
            else:
                rating = "NEEDS_IMPROVEMENT"
            
            report.append(f"  Overall Rating: {rating}")
        
        # Subject-wise Performance Analysis
        report.append(f"\n\nSUBJECT-WISE PERFORMANCE SUMMARY")
        report.append("=" * 50)
        
        for subject_id, subject_data in subject_performance.items():
            report.append(f"\nSubject {subject_id}:")
            
            for algorithm_name, perf_data in subject_data.items():
                avg_traj_per_session = perf_data['total_trajectories'] / max(perf_data['sessions'], 1)
                avg_time_per_session = perf_data['total_time'] / max(perf_data['sessions'], 1)
                
                report.append(f"  {algorithm_name}: {avg_traj_per_session:.1f} traj/session, "
                             f"{avg_time_per_session:.3f}s/session")
        
        # Recommendations
        report.append(f"\n\nRECOMMENDATIONS & INSIGHTS")
        report.append("=" * 50)
        
        # Performance-based recommendations
        fastest_alg = best_performers['computation_times'][0]
        most_accurate_alg = best_performers['trajectory_qualities'][0]
        most_sensitive_alg = best_performers['total_trajectories'][0]
        
        report.append("Algorithm Selection Guidelines:")
        report.append(f"• For Real-time Applications: {fastest_alg.upper()} (fastest processing)")
        report.append(f"• For High-precision Analysis: {most_accurate_alg.upper()} (highest quality)")
        report.append(f"• For Maximum Detection: {most_sensitive_alg.upper()} (most trajectories)")
        
        report.append("\nPerformance Optimization Insights:")
        total_sessions = sum(stats['sessions_processed'] for stats in algorithm_stats.values())
        if total_sessions > 0:
            avg_processing_time = np.mean([np.mean(stats['computation_times']) 
                                         for stats in algorithm_stats.values() 
                                         if stats['computation_times']])
            
            report.append(f"• Average processing time across all algorithms: {avg_processing_time:.3f}s")
            report.append(f"• Frame processing efficiency varies by algorithm (see detailed analysis)")
            report.append(f"• Quality-speed trade-off is evident across different algorithms")
        
        # Configuration insights
        report.append(f"\nConfiguration Impact Analysis:")
        report.append(f"• Frame limit setting ({Config.MAX_FRAMES_PER_EPOCH} frames/epoch) affects:")
        report.append(f"  - Processing speed (lower = faster)")
        report.append(f"  - Memory usage (lower = less memory)")
        report.append(f"  - Trajectory completeness (higher = more complete)")
        
        report.append("\nGeneral Insights:")
        report.append("• Algorithm performance may vary significantly with different EEG data characteristics")
        report.append("• Consider data-specific parameter tuning for optimal results")
        report.append("• Multiple algorithm approaches provide robust analysis framework")
        
        return "\n".join(report)
        
    except Exception as e:
        logger.error(f"Enhanced summary report generation failed: {e}")
        return "Enhanced summary report generation failed. Please check logs for details."

def cleanup_memory():
    """Clean up memory"""
    gc.collect()
    
    try:
        import psutil
        process = psutil.Process()
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / (1024 * 1024)
        
        if memory_mb > Config.MEMORY_LIMIT_MB:
            logging.getLogger(__name__).warning(
                f"High memory usage: {memory_mb:.1f} MB (limit: {Config.MEMORY_LIMIT_MB} MB)"
            )
            return False
    except ImportError:
        pass
    
    return True

def print_final_summary(all_results, enhanced_comparison_results):
    """Print final experiment summary"""
    print("\n" + "="*80)
    print("ENHANCED ALGORITHM COMPARISON EXPERIMENT SUMMARY")
    print("="*80)
    
    # Basic statistics
    n_subjects = len(all_results)
    total_sessions = sum(len(sessions) for sessions in all_results.values())
    
    print(f"✓ Successfully Processed:")
    print(f"  • Subjects: {n_subjects}")
    print(f"  • Total Sessions: {total_sessions}")
    print(f"  • Frame Limit: {Config.MAX_FRAMES_PER_EPOCH} frames/epoch")
    
    if enhanced_comparison_results:
        metrics = enhanced_comparison_results['comprehensive_metrics']
        print(f"  • Algorithms Compared: {len(metrics)}")
        print(f"  • Algorithm List: {', '.join(metrics.keys())}")
        
        # Show top performers
        if metrics:
            best_overall = max(metrics.items(), key=lambda x: x[1]['composite_performance_score'])
            fastest = min(metrics.items(), key=lambda x: x[1]['avg_computation_times'])
            highest_quality = max(metrics.items(), key=lambda x: x[1]['avg_quality_scores'])
            
            print(f"\n🏆 Top Performers:")
            print(f"  • Best Overall: {best_overall[0].upper()} (Score: {best_overall[1]['composite_performance_score']:.3f})")
            print(f"  • Fastest: {fastest[0].upper()} ({fastest[1]['avg_computation_times']:.4f}s)")
            print(f"  • Highest Quality: {highest_quality[0].upper()} (Score: {highest_quality[1]['avg_quality_scores']:.3f})")
    
    # Output locations
    print(f"\n📂 Results Saved To:")
    print(f"  • Trajectory Plots: {os.path.join(Config.RESULTS_ROOT, 'trajectories')}")
    print(f"  • Algorithm Comparison: {os.path.join(Config.RESULTS_ROOT, 'algorithm_comparison')}")
    
    if enhanced_comparison_results:
        print(f"  • Detailed Report: {enhanced_comparison_results['report_path']}")
        print(f"  • Visualization Suite: {enhanced_comparison_results['visualization_dir']}")
        print(f"  • CSV Data: {enhanced_comparison_results['csv_path']}")
    
    print("="*80)
    print("🎉 Enhanced Algorithm Comparison Experiment Complete!")
    print("="*80)

def main():
    """Main experiment workflow"""
    parser = argparse.ArgumentParser(description='Enhanced EEG Trajectory Analysis with Algorithm Comparison')
    parser.add_argument('--subjects', type=int, default=None, 
                       help='Maximum number of subjects to process')
    parser.add_argument('--epochs', type=int, default=None,
                       help='Maximum epochs per subject')
    parser.add_argument('--frames', type=int, default=None,
                       help='Maximum frames per epoch')
    parser.add_argument('--algorithms', nargs='+', default=None,
                       help='Algorithms to compare', choices=Config.COMPARISON_ALGORITHMS)
    parser.add_argument('--disable-comparison', action='store_true',
                       help='Disable algorithm comparison (use greedy only)')
    parser.add_argument('--fast-mode', action='store_true',
                       help='Enable fast mode (reduced frames and epochs)')
    
    args = parser.parse_args()
    
    # Fast mode configuration
    if args.fast_mode:
        Config.set_max_frames(100, 'epoch')
        Config.MAX_EPOCHS_PER_SUBJECT = 1
        Config.MAX_SUBJECTS = 3
        print("🚀 Fast mode enabled: reduced processing for quick testing")
    
    # Print system information
    print_system_info()
    
    # Check dependencies
    if not check_dependencies():
        return 1
    
    # Set up logging
    logger = setup_logging()
    logger.info("Starting Enhanced EEG Topography Motion Trajectory Analysis Experiment")
    
    try:
        # Validate configuration
        if not validate_config():
            return 1
        
        # Apply command line arguments
        if args.subjects:
            Config.MAX_SUBJECTS = args.subjects
        if args.epochs:
            Config.MAX_EPOCHS_PER_SUBJECT = args.epochs
        if args.frames:
            Config.set_max_frames(args.frames, 'epoch')
            logger.info(f"Frame limit set to: {args.frames}")
        if args.algorithms:
            Config.COMPARISON_ALGORITHMS = args.algorithms
        if args.disable_comparison:
            Config.ENABLE_ALGORITHM_COMPARISON = False
            Config.COMPARISON_ALGORITHMS = ['greedy']
        
        # Initialize components
        logger.info("Initializing enhanced analysis components...")
        
        data_loader = EEGDataLoader(Config.DATA_ROOT, Config)
        topo_generator = TopographyGenerator(Config)
        analyzer = TrajectoryAnalyzer(Config)
        visualizer = Visualizer(Config)
        
        # Load data
        logger.info("Loading EEG data...")
        all_data = data_loader.load_all_subjects(Config.MAX_SUBJECTS)
        
        if not all_data:
            logger.error("Failed to load any EEG data, please check data path and format")
            print("\n❌ Failed to load any EEG data, please check data path and format")
            return 1
        
        logger.info(f"Successfully loaded data from {len(all_data)} subjects")
        
        # Store all results
        all_results = {}
        
        # Process each subject
        total_subjects = len(all_data)
        processed_subjects = 0
        
        print(f"\n🔄 Processing {total_subjects} subjects with {len(Config.COMPARISON_ALGORITHMS)} algorithms...")
        
        for subject_id, sessions in tqdm(all_data.items(), desc="Processing subjects"):
            try:
                if Config.ENABLE_ALGORITHM_COMPARISON:
                    subject_results = process_subject_with_multiple_algorithms(
                        data_loader, topo_generator, analyzer, visualizer,
                        subject_id, sessions, logger
                    )
                else:
                    logger.info("Using single algorithm mode (greedy)")
                    subject_results = None
                
                if subject_results:
                    all_results[subject_id] = subject_results
                    processed_subjects += 1
                    
                    # Periodic memory cleanup
                    if processed_subjects % 2 == 0:
                        cleanup_memory()
                        logger.info(f"Processed {processed_subjects}/{total_subjects} subjects")
                else:
                    logger.warning(f"Subject {subject_id} produced no valid results")
                    
            except Exception as e:
                logger.error(f"Serious error processing subject {subject_id}: {e}")
                continue
        
        if processed_subjects == 0:
            logger.error("No subject data was successfully processed")
            print("\n❌ No subject data was successfully processed")
            return 1
        
        logger.info(f"Data processing complete, successfully processed {processed_subjects} subjects")
        
        # Generate enhanced algorithm comparison and visualizations
        enhanced_comparison_results = None
        if Config.ENABLE_ALGORITHM_COMPARISON and all_results:
            print("\n📊 Running enhanced algorithm comparison analysis...")
            enhanced_comparison_results = run_enhanced_algorithm_comparison(all_results, visualizer, Config)
            
            if enhanced_comparison_results:
                # Create enhanced summary report
                enhanced_report = create_enhanced_summary_report(all_results, logger)
                
                # Save enhanced report
                enhanced_report_path = os.path.join(Config.RESULTS_ROOT, "enhanced_experiment_summary.txt")
                with open(enhanced_report_path, 'w', encoding='utf-8') as f:
                    f.write(enhanced_report)
                
                logger.info(f"Enhanced summary report saved: {enhanced_report_path}")
                
                # Create overall summary visualization
                summary_viz_path = os.path.join(Config.RESULTS_ROOT, "experiment_summary.png")
                visualizer.create_summary_visualization(all_results, summary_viz_path)
        else:
            logger.info("Algorithm comparison disabled or no valid results")
        
        # Save complete results
        results_path = os.path.join(Config.RESULTS_ROOT, "complete_experiment_results.pkl")
        try:
            with open(results_path, 'wb') as f:
                pickle.dump({
                    'experiment_results': all_results,
                    'enhanced_comparison': enhanced_comparison_results,
                    'config_summary': Config.get_config_summary(),
                    'experiment_summary': Config.get_experiment_summary()
                }, f, protocol=pickle.HIGHEST_PROTOCOL)
            logger.info(f"Complete results saved: {results_path}")
        except Exception as e:
            logger.error(f"Failed to save complete results: {e}")
        
        # Print final summary
        print_final_summary(all_results, enhanced_comparison_results)
        
        logger.info("Enhanced algorithm comparison experiment completed successfully!")
        return 0
        
    except KeyboardInterrupt:
        logger.info("Experiment was interrupted by user")
        print("\n🛑 Experiment was interrupted by user")
        return 130
        
    except Exception as e:
        logger.error(f"Unexpected error during experiment: {e}")
        print(f"\n❌ Unexpected error during experiment: {e}")
        return 1
        
    finally:
        cleanup_memory()

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)

# ========== quick_test.py ==========
# 相对路径: quick_test.py
# 在项目中的相对位置: ./quick_test.py

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced EEG Trajectory Tracking Algorithm Comparison System - Quick Test Script
Validates system installation and basic functionality with English interface
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import logging
import platform

# Set matplotlib to English only
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Liberation Sans']

def test_dependencies():
    """Test dependency installation"""
    print("🔍 Testing dependency installation...")
    
    required_packages = {
        'numpy': 'NumPy',
        'scipy': 'SciPy', 
        'matplotlib': 'Matplotlib',
        'sklearn': 'Scikit-learn',
        'cv2': 'OpenCV',
        'tqdm': 'tqdm',
        'mne': 'MNE-Python',
        'pandas': 'Pandas',
        'seaborn': 'Seaborn'
    }
    
    missing_packages = []
    installed_packages = []
    
    for package, name in required_packages.items():
        try:
            __import__(package)
            installed_packages.append(name)
            print(f"  ✓ {name}")
        except ImportError:
            missing_packages.append(name)
            print(f"  ❌ {name} - Not installed")
    
    print(f"\nInstallation status: {len(installed_packages)}/{len(required_packages)} packages installed")
    
    if missing_packages:
        print(f"\n❌ Missing dependencies: {', '.join(missing_packages)}")
        print("Please run: pip install -r requirements.txt")
        return False
    else:
        print("✅ All dependencies correctly installed!")
        return True

def test_tracker_factory():
    """Test tracker factory"""
    print("\n🏭 Testing tracker factory...")
    
    try:
        # Add paths
        sys.path.append('trackers')
        sys.path.append('src')
        from trackers import TrackerFactory
        from config import Config
        
        # Test available algorithms
        algorithms = TrackerFactory.get_available_algorithms()
        print(f"  ✓ Available algorithms: {', '.join(algorithms)}")
        
        # Test tracker creation
        success_count = 0
        for algorithm in algorithms:
            try:
                tracker = TrackerFactory.create_tracker(algorithm, Config)
                if tracker is not None:
                    print(f"  ✓ {algorithm} tracker created successfully")
                    success_count += 1
                else:
                    print(f"  ❌ {algorithm} tracker creation failed")
            except Exception as e:
                print(f"  ❌ {algorithm} tracker creation exception: {e}")
        
        print(f"\nTracker creation status: {success_count}/{len(algorithms)} algorithms available")
        return success_count > 0
        
    except Exception as e:
        print(f"  ❌ Tracker factory test failed: {e}")
        return False

def test_synthetic_data():
    """Test synthetic data processing with enhanced algorithms"""
    print("\n🧪 Testing synthetic data processing...")
    
    try:
        sys.path.append('src')
        sys.path.append('trackers')
        
        from src.topography import TopographyGenerator
        from trackers import TrackerFactory
        from config import Config
        
        # Create synthetic topography data
        n_frames = 30  # Reduced for faster testing
        size = (64, 64)  # Smaller size for speed
        
        print(f"  🔧 Generating {n_frames} frames of {size} synthetic topographies...")
        
        # Create moving activation regions
        topographies = np.zeros((n_frames, size[0], size[1]))
        
        for i in range(n_frames):
            # Create moving Gaussian activation
            center_x = 20 + int(15 * np.sin(2 * np.pi * i / 20))
            center_y = 20 + int(10 * np.cos(2 * np.pi * i / 15))
            
            y, x = np.ogrid[:size[0], :size[1]]
            activation = np.exp(-((x - center_x)**2 + (y - center_y)**2) / (2 * 4**2))
            topographies[i] = activation
        
        print("  ✓ Synthetic topography generation complete")
        
        # Test tracking algorithms
        test_algorithms = Config.COMPARISON_ALGORITHMS[:3]  # Test first 3 algorithms
        
        algorithm_results = {}
        
        for algorithm in test_algorithms:
            try:
                print(f"  🎯 Testing {algorithm} algorithm...")
                
                tracker = TrackerFactory.create_tracker(algorithm, Config)
                if tracker is None:
                    print(f"    ❌ {algorithm} tracker creation failed")
                    continue
                
                import time
                start_time = time.time()
                result = tracker.track_sequence(topographies)
                end_time = time.time()
                
                if result and 'trajectories' in result:
                    trajectories = result['trajectories']
                    metrics = result.get('metrics', {})
                    
                    algorithm_results[algorithm] = {
                        'trajectory_count': len(trajectories),
                        'computation_time': end_time - start_time,
                        'metrics': metrics
                    }
                    
                    print(f"    ✓ {algorithm}: {len(trajectories)} trajectories detected")
                    print(f"    ✓ Processing time: {end_time - start_time:.3f}s")
                    
                    if len(trajectories) > 0:
                        first_traj = list(trajectories.values())[0]
                        print(f"    ✓ Trajectory length: {first_traj['length']} frames")
                else:
                    print(f"    ⚠️  {algorithm}: No trajectories detected")
                    algorithm_results[algorithm] = {
                        'trajectory_count': 0,
                        'computation_time': end_time - start_time,
                        'metrics': {}
                    }
                
            except Exception as e:
                print(f"    ❌ {algorithm} test failed: {e}")
                algorithm_results[algorithm] = {
                    'trajectory_count': 0,
                    'computation_time': 0,
                    'error': str(e)
                }
        
        # Display comparison results
        if algorithm_results:
            print(f"\n  📊 Algorithm Performance Comparison:")
            print(f"  {'Algorithm':<12} {'Trajectories':<12} {'Time (s)':<10} {'Status'}")
            print(f"  {'-'*50}")
            
            for alg, results in algorithm_results.items():
                status = "✓ Pass" if results['trajectory_count'] > 0 else "⚠ No detection"
                if 'error' in results:
                    status = "❌ Error"
                
                print(f"  {alg:<12} {results['trajectory_count']:<12} {results['computation_time']:<10.3f} {status}")
        
        return True
        
    except Exception as e:
        print(f"  ❌ Synthetic data test failed: {e}")
        return False

def test_enhanced_visualization():
    """Test enhanced visualization functionality"""
    print("\n🎨 Testing enhanced visualization functionality...")
    
    try:
        # Test matplotlib setup
        import matplotlib
        matplotlib.use('Agg')  # Use non-interactive backend
        
        # Create comprehensive test plots
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('Enhanced EEG Trajectory Analysis - Visualization Test', fontsize=14, fontweight='bold')
        
        # Test 1: Basic plotting with English labels
        ax = axes[0, 0]
        x = np.linspace(0, 10, 100)
        y = np.sin(x)
        ax.plot(x, y, 'b-', linewidth=2, label='Test Signal')
        ax.set_title('Signal Processing Test')
        ax.set_xlabel('Time (s)')
        ax.set_ylabel('Amplitude')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Test 2: Algorithm comparison simulation
        ax = axes[0, 1]
        algorithms = ['Greedy', 'Hungarian', 'Kalman', 'Overlap', 'Hybrid']
        performance = [4.2, 4.8, 3.9, 4.1, 4.6]
        colors = plt.cm.Set1(np.linspace(0, 1, len(algorithms)))
        
        bars = ax.bar(algorithms, performance, color=colors, alpha=0.7)
        ax.set_title('Algorithm Performance Comparison')
        ax.set_ylabel('Average Trajectories')
        ax.tick_params(axis='x', rotation=45)
        
        # Add value labels
        for bar, perf in zip(bars, performance):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                   f'{perf:.1f}', ha='center', va='bottom')
        
        # Test 3: Topography simulation
        ax = axes[1, 0]
        size = 64
        x = np.linspace(-1, 1, size)
        y = np.linspace(-1, 1, size)
        X, Y = np.meshgrid(x, y)
        Z = np.exp(-(X**2 + Y**2) / 0.3) * np.cos(3*X) * np.sin(3*Y)
        
        im = ax.imshow(Z, cmap='RdYlBu_r', origin='lower', extent=[-1, 1, -1, 1])
        ax.set_title('EEG Topography Simulation')
        ax.set_xlabel('X Position')
        ax.set_ylabel('Y Position')
        
        # Add head outline
        circle = plt.Circle((0, 0), 0.9, fill=False, color='black', linewidth=2)
        ax.add_patch(circle)
        
        # Test 4: Trajectory visualization
        ax = axes[1, 1]
        
        # Simulate trajectory data
        t = np.linspace(0, 4*np.pi, 50)
        traj1_x = 0.3 * np.cos(t) + 0.1 * np.sin(3*t)
        traj1_y = 0.3 * np.sin(t) + 0.1 * np.cos(2*t)
        traj2_x = -0.2 * np.cos(1.5*t) + 0.15 * np.sin(2*t)
        traj2_y = 0.4 * np.sin(1.5*t) - 0.1 * np.cos(4*t)
        
        ax.plot(traj1_x, traj1_y, 'r-', linewidth=2, alpha=0.8, label='Trajectory 1')
        ax.plot(traj2_x, traj2_y, 'b-', linewidth=2, alpha=0.8, label='Trajectory 2')
        
        # Mark start and end points
        ax.scatter([traj1_x[0], traj2_x[0]], [traj1_y[0], traj2_y[0]], 
                  c=['red', 'blue'], s=100, marker='o', label='Start', zorder=5)
        ax.scatter([traj1_x[-1], traj2_x[-1]], [traj1_y[-1], traj2_y[-1]], 
                  c=['red', 'blue'], s=100, marker='s', label='End', zorder=5)
        
        ax.set_title('Trajectory Tracking Simulation')
        ax.set_xlabel('X Coordinate')
        ax.set_ylabel('Y Coordinate')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_aspect('equal')
        
        plt.tight_layout()
        
        # Save test plots
        test_dir = './test_results'
        os.makedirs(test_dir, exist_ok=True)
        
        main_test_path = os.path.join(test_dir, 'enhanced_visualization_test.png')
        plt.savefig(main_test_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"  ✓ Enhanced visualization test saved: {main_test_path}")
        
        # Test algorithm comparison visualization
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Simulate comprehensive algorithm comparison
        metrics = {
            'Trajectory Count': [4.2, 4.8, 3.9, 4.1, 4.6],
            'Quality Score': [0.72, 0.85, 0.78, 0.74, 0.82],
            'Processing Time': [0.15, 0.45, 0.25, 0.35, 0.55],
            'Efficiency': [28, 11, 16, 12, 8]
        }
        
        x = np.arange(len(algorithms))
        width = 0.2
        
        for i, (metric, values) in enumerate(metrics.items()):
            # Normalize values for comparison
            if metric == 'Processing Time':
                # Lower is better for time, so invert
                norm_values = [1.0 - (v - min(values)) / (max(values) - min(values)) for v in values]
            else:
                norm_values = [(v - min(values)) / (max(values) - min(values)) for v in values]
            
            ax.bar(x + i * width, norm_values, width, label=metric, alpha=0.8)
        
        ax.set_title('Normalized Algorithm Performance Comparison', fontweight='bold')
        ax.set_xlabel('Algorithms')
        ax.set_ylabel('Normalized Performance (0-1)')
        ax.set_xticks(x + width * 1.5)
        ax.set_xticklabels(algorithms)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        comparison_path = os.path.join(test_dir, 'algorithm_comparison_test.png')
        plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"  ✓ Algorithm comparison test saved: {comparison_path}")
        
        return True
        
    except Exception as e:
        print(f"  ❌ Enhanced visualization test failed: {e}")
        return False

def test_config():
    """Test configuration file"""
    print("\n⚙️ Testing configuration file...")
    
    try:
        from config import Config
        
        # Test basic configuration
        print(f"  ✓ Data path: {Config.DATA_ROOT}")
        print(f"  ✓ Results path: {Config.RESULTS_ROOT}")
        print(f"  ✓ Max subjects: {Config.MAX_SUBJECTS}")
        print(f"  ✓ Algorithm comparison: {'Enabled' if Config.ENABLE_ALGORITHM_COMPARISON else 'Disabled'}")
        print(f"  ✓ Comparison algorithms: {', '.join(Config.COMPARISON_ALGORITHMS)}")
        print(f"  ✓ Max frames per epoch: {Config.MAX_FRAMES_PER_EPOCH}")
        
        # Test configuration methods
        summary = Config.get_experiment_summary()
        print(f"  ✓ Experiment summary: {summary['algorithms_count']} algorithms, {summary['total_subjects']} subjects")
        
        # Test algorithm configuration
        for algorithm in Config.COMPARISON_ALGORITHMS:
            alg_config = Config.get_algorithm_config(algorithm)
            print(f"  ✓ {algorithm} config: {len(alg_config)} parameters")
        
        # Test frame control
        frame_limit = Config.get_max_frames('epoch')
        print(f"  ✓ Frame control: {frame_limit} frames/epoch limit")
        
        return True
        
    except Exception as e:
        print(f"  ❌ Configuration test failed: {e}")
        return False

def generate_enhanced_test_report(results):
    """Generate enhanced test report"""
    print("\n" + "="*80)
    print("🎯 ENHANCED EEG TRAJECTORY TRACKING SYSTEM - QUICK TEST REPORT")
    print("="*80)
    print(f"Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("")
    
    test_items = [
        ('Dependency Installation', results.get('dependencies', False)),
        ('Tracker Factory', results.get('tracker_factory', False)),
        ('Synthetic Data Processing', results.get('synthetic_data', False)),
        ('Enhanced Visualization', results.get('enhanced_visualization', False)),
        ('Configuration System', results.get('config', False))
    ]
    
    passed_tests = sum(1 for _, result in test_items if result)
    total_tests = len(test_items)
    
    print("Test Results:")
    for item_name, passed in test_items:
        status = "✅ PASS" if passed else "❌ FAIL"
        print(f"  {item_name:<25}: {status}")
    
    print(f"\nOverall Result: {passed_tests}/{total_tests} tests passed")
    
    # Provide detailed feedback based on results
    if passed_tests == total_tests:
        print("🎉 EXCELLENT! System is fully operational and ready for use!")
        print("\nRecommended Next Steps:")
        print("  1. Prepare your EEG data (see README.md for data format)")
        print("  2. Quick test: python main.py --fast-mode")
        print("  3. Full experiment: python main.py")
        print("  4. View results in ./results/ directory")
        
    elif passed_tests >= 4:
        print("✅ GOOD! System is functional with minor issues.")
        print("⚠️  Some advanced features may have limitations.")
        print("\nRecommended Next Steps:")
        print("  1. Review failed tests and address issues if needed")
        print("  2. Try quick test: python main.py --fast-mode")
        print("  3. Check system logs for detailed error information")
        
    elif passed_tests >= 2:
        print("⚠️  PARTIAL! Basic functionality works but issues detected.")
        print("🔧 Some components need attention before full operation.")
        print("\nRecommended Actions:")
        print("  1. Fix failed dependency installations")
        print("  2. Check Python version (requires 3.8+)")
        print("  3. Verify system compatibility")
        
    else:
        print("❌ CRITICAL! Major system issues detected.")
        print("🚨 System requires significant troubleshooting.")
        print("\nRequired Actions:")
        print("  1. Check Python version (requires 3.8+)")
        print("  2. Reinstall dependencies: pip install -r requirements.txt")
        print("  3. Verify system compatibility and permissions")
        print("  4. Check installation logs for specific errors")
    
    print(f"\n📁 Test outputs saved in: ./test_results/")
    
    # System information
    print(f"\nSystem Information:")
    print(f"  • Python: {sys.version.split()[0]}")
    
    try:
        import platform as plt_module
        print(f"  • Platform: {plt_module.system().lower()}")
        print(f"  • Architecture: {plt_module.machine()}")
    except Exception as e:
        print(f"  • Platform: {sys.platform}")
        print(f"  • Architecture: Unknown")
    
    # Performance estimate
    if passed_tests >= 4:
        estimated_time = "2-5 minutes per subject" if passed_tests == total_tests else "3-8 minutes per subject"
        print(f"  • Estimated processing time: {estimated_time}")
        print(f"  • Recommended subjects for testing: 2-3")
        print(f"  • Memory requirement: 2-4 GB for typical datasets")
    
    print("\n📋 For detailed help, documentation, and troubleshooting:")
    print("   • Check README.md")
    print("   • Review example configurations")
    print("   • Examine log files in ./logs/")
    print("="*80)

def run_performance_benchmark():
    """Run quick performance benchmark"""
    print("\n⚡ Running performance benchmark...")
    
    try:
        import time
        
        # Test computation performance
        start_time = time.time()
        
        # Matrix operations test
        size = 1000
        a = np.random.rand(size, size)
        b = np.random.rand(size, size)
        c = np.dot(a, b)
        
        matrix_time = time.time() - start_time
        
        # Memory allocation test
        start_time = time.time()
        large_array = np.zeros((2000, 2000, 10))
        del large_array
        
        memory_time = time.time() - start_time
        
        print(f"  ✓ Matrix computation: {matrix_time:.3f}s")
        print(f"  ✓ Memory allocation: {memory_time:.3f}s")
        
        # Performance assessment
        if matrix_time < 0.5 and memory_time < 0.1:
            performance = "Excellent"
        elif matrix_time < 2.0 and memory_time < 0.5:
            performance = "Good"
        elif matrix_time < 5.0 and memory_time < 1.0:
            performance = "Fair"
        else:
            performance = "Poor"
        
        print(f"  📊 Overall performance: {performance}")
        
        return True
        
    except Exception as e:
        print(f"  ❌ Performance benchmark failed: {e}")
        return False

def main():
    """Main test function"""
    print("🚀 ENHANCED EEG TRAJECTORY TRACKING ALGORITHM COMPARISON SYSTEM")
    print("   Quick Functionality Test & System Validation")
    print("="*80)
    print("This test validates system installation and basic functionality")
    print("Estimated time: 2-3 minutes")
    print("")
    
    # Suppress some logging for cleaner output
    logging.getLogger().setLevel(logging.WARNING)
    
    # Run test suite
    results = {}
    
    results['dependencies'] = test_dependencies()
    results['config'] = test_config()
    results['tracker_factory'] = test_tracker_factory()
    results['synthetic_data'] = test_synthetic_data()
    results['enhanced_visualization'] = test_enhanced_visualization()
    
    # Optional performance benchmark
    print("\n🎭 Additional Tests:")
    results['performance'] = run_performance_benchmark()
    
    # Generate comprehensive test report
    generate_enhanced_test_report(results)
    
    return 0 if all(results.values()) else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)

# ========== src/__init__.py ==========
# 相对路径: src/__init__.py
# 在项目中的相对位置: ./src/__init__.py

# EEG脑电地形图运动轨迹分析包
__version__ = "1.0.0"
__author__ = "EEG Research Team"

from .data_loader import EEGDataLoader
from .topography import TopographyGenerator
from .trajectory_analysis import TrajectoryAnalyzer
from .visualization import Visualizer

__all__ = [
    'EEGDataLoader',
    'TopographyGenerator', 
    'TrajectoryAnalyzer',
    'Visualizer'
]

# ========== src/data_loader.py ==========
# 相对路径: src/data_loader.py
# 在项目中的相对位置: ./src/data_loader.py

import os
import mne
import numpy as np
import pandas as pd
from tqdm import tqdm
import logging
import gc
from typing import List, Tuple, Dict, Optional

class EEGDataLoader:
    def __init__(self, data_root: str, config):
        self.data_root = data_root
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # 设置MNE日志级别
        mne.set_log_level('WARNING')
        
    def get_subject_sessions(self, subject_id: str) -> List[str]:
        """获取指定被试的所有session"""
        subject_dir = os.path.join(self.data_root, f"sub-{subject_id}")
        if not os.path.exists(subject_dir):
            self.logger.warning(f"Subject directory not found: {subject_dir}")
            return []
        
        sessions = []
        try:
            for item in os.listdir(subject_dir):
                if item.startswith("ses-") and os.path.isdir(os.path.join(subject_dir, item)):
                    session_num = item.split("-")[1]
                    sessions.append(session_num)
        except Exception as e:
            self.logger.error(f"Error reading subject directory {subject_dir}: {e}")
            return []
        
        return sorted(sessions, key=lambda x: int(x) if x.isdigit() else 0)
    
    def find_eeg_files(self, subject_id: str, session_id: str) -> Optional[str]:
        """查找EEG文件，支持多种格式"""
        eeg_dir = os.path.join(self.data_root, f"sub-{subject_id}", f"ses-{session_id}", "eeg")
        
        if not os.path.exists(eeg_dir):
            self.logger.warning(f"EEG directory not found: {eeg_dir}")
            return None
        
        # 按优先级搜索不同格式的文件
        file_patterns = [
            f"sub-{subject_id}_ses-{session_id}_task-innerspeech_eeg.vhdr",
            f"sub-{subject_id}_ses-{session_id}_task-innerspeech_eeg.edf",
            f"sub-{subject_id}_ses-{session_id}_task-innerspeech_eeg.fif",
            f"sub-{subject_id}_ses-{session_id}_eeg.vhdr",
            f"sub-{subject_id}_ses-{session_id}_eeg.edf",
            f"sub-{subject_id}_ses-{session_id}_eeg.fif"
        ]
        
        for pattern in file_patterns:
            file_path = os.path.join(eeg_dir, pattern)
            if os.path.exists(file_path):
                return file_path
        
        # 如果找不到特定模式，列出所有EEG文件
        try:
            eeg_files = [f for f in os.listdir(eeg_dir) 
                        if f.endswith(('.vhdr', '.edf', '.fif', '.set', '.cnt'))]
            if eeg_files:
                return os.path.join(eeg_dir, eeg_files[0])
        except Exception as e:
            self.logger.error(f"Error listing EEG directory {eeg_dir}: {e}")
        
        return None
    
    def load_raw_eeg(self, subject_id: str, session_id: str) -> Optional[mne.io.Raw]:
        """加载原始EEG数据，支持多种格式"""
        eeg_file = self.find_eeg_files(subject_id, session_id)
        
        if not eeg_file:
            self.logger.warning(f"No EEG file found for subject {subject_id}, session {session_id}")
            return None
        
        try:
            # 根据文件扩展名选择加载方法
            file_ext = os.path.splitext(eeg_file)[1].lower()
            
            if file_ext == '.vhdr':
                raw = mne.io.read_raw_brainvision(eeg_file, preload=True, verbose=False)
            elif file_ext == '.edf':
                raw = mne.io.read_raw_edf(eeg_file, preload=True, verbose=False)
            elif file_ext == '.fif':
                raw = mne.io.read_raw_fif(eeg_file, preload=True, verbose=False)
            elif file_ext == '.set':
                raw = mne.io.read_raw_eeglab(eeg_file, preload=True, verbose=False)
            elif file_ext == '.cnt':
                raw = mne.io.read_raw_cnt(eeg_file, preload=True, verbose=False)
            else:
                self.logger.error(f"Unsupported file format: {file_ext}")
                return None
            
            self.logger.info(f"Successfully loaded {eeg_file}")
            return raw
            
        except Exception as e:
            self.logger.error(f"Error loading EEG data from {eeg_file}: {e}")
            return None
    
    def preprocess_eeg(self, raw: mne.io.Raw) -> Optional[mne.io.Raw]:
        """预处理EEG数据"""
        try:
            # 创建副本避免修改原始数据
            raw_copy = raw.copy()
            
            # 检查并设置电极类型
            if len(raw_copy.info['chs']) > 0:
                # 自动检测EEG通道
                raw_copy.set_channel_types({ch: 'eeg' for ch in raw_copy.ch_names 
                                          if not ch.startswith(('EOG', 'ECG', 'EMG', 'TRIG', 'STIM'))})
            
            # 选择EEG通道
            raw_copy.pick_types(eeg=True, exclude='bads')
            
            if len(raw_copy.ch_names) == 0:
                self.logger.error("No EEG channels found after preprocessing")
                return None
            
            # 设置参考电极
            try:
                raw_copy.set_eeg_reference('average', projection=True, verbose=False)
                raw_copy.apply_proj(verbose=False)
            except Exception as e:
                self.logger.warning(f"Failed to set average reference: {e}")
            
            # 滤波
            try:
                raw_copy.filter(l_freq=self.config.LOW_FREQ, h_freq=self.config.HIGH_FREQ, 
                              fir_design='firwin', verbose=False)
            except Exception as e:
                self.logger.warning(f"Filtering failed: {e}")
            
            # 重采样（如果需要）
            if raw_copy.info['sfreq'] != self.config.SAMPLING_RATE:
                try:
                    raw_copy.resample(self.config.SAMPLING_RATE, verbose=False)
                except Exception as e:
                    self.logger.warning(f"Resampling failed: {e}")
            
            return raw_copy
            
        except Exception as e:
            self.logger.error(f"Preprocessing failed: {e}")
            return None
    
    def extract_epochs(self, raw: mne.io.Raw, epoch_length: float = None, 
                      overlap: float = 0.5, max_epochs: int = None) -> Optional[mne.Epochs]:
        """提取固定长度的epoch"""
        if epoch_length is None:
            epoch_length = self.config.TIME_WINDOW
        
        if max_epochs is None:
            max_epochs = self.config.MAX_EPOCHS_PER_SUBJECT
        
        try:
            # 创建虚拟事件
            duration = epoch_length
            interval = duration * (1 - overlap)
            
            n_samples = int(duration * raw.info['sfreq'])
            step_samples = int(interval * raw.info['sfreq'])
            
            if n_samples >= len(raw.times):
                self.logger.warning("Epoch length longer than recording, using full recording")
                n_samples = len(raw.times) - 1
            
            events = []
            event_id = 1
            
            # 限制epoch数量以节省内存
            max_start_sample = len(raw.times) - n_samples
            epoch_count = 0
            
            for start_sample in range(0, max_start_sample, step_samples):
                if epoch_count >= max_epochs:
                    break
                events.append([start_sample, 0, event_id])
                epoch_count += 1
            
            if not events:
                self.logger.error("No epochs could be created")
                return None
            
            events = np.array(events)
            
            epochs = mne.Epochs(raw, events, event_id={'epoch': event_id}, 
                               tmin=0, tmax=duration-1/raw.info['sfreq'], 
                               baseline=None, preload=True, verbose=False)
            
            # 检查epoch质量
            if len(epochs) == 0:
                self.logger.error("No valid epochs after creation")
                return None
            
            self.logger.info(f"Created {len(epochs)} epochs of {duration}s each")
            return epochs
            
        except Exception as e:
            self.logger.error(f"Epoch extraction failed: {e}")
            return None
    
    def get_electrode_positions(self, ch_names: List[str]) -> Dict[str, Tuple[float, float]]:
        """获取电极位置，改进的匹配算法"""
        positions = {}
        unmatched_channels = []
        
        for ch_name in ch_names:
            # 清理通道名称
            clean_name = ch_name.strip()
            position_found = False
            
            # 尝试多种匹配方式
            search_variants = [
                clean_name,
                clean_name.upper(),
                clean_name.lower(),
                clean_name.capitalize(),
                clean_name.replace(' ', ''),
                clean_name.replace('-', ''),
                clean_name.replace('_', '')
            ]
            
            for variant in search_variants:
                if variant in self.config.ELECTRODE_POSITIONS:
                    positions[ch_name] = self.config.ELECTRODE_POSITIONS[variant]
                    position_found = True
                    break
            
            if not position_found:
                unmatched_channels.append(ch_name)
        
        # 为未匹配的电极分配默认位置
        if unmatched_channels:
            self.logger.warning(f"Using default positions for electrodes: {unmatched_channels}")
            for i, ch_name in enumerate(unmatched_channels):
                default_pos = self.config.get_default_electrode_position(
                    ch_name, len(ch_names), len(positions) + i
                )
                positions[ch_name] = default_pos
        
        return positions
    
    def check_memory_usage(self) -> bool:
        """检查内存使用情况"""
        try:
            import psutil
            memory_usage = psutil.virtual_memory().percent
            if memory_usage > 85:  # 超过85%内存使用率
                self.logger.warning(f"High memory usage: {memory_usage:.1f}%")
                gc.collect()  # 强制垃圾回收
                return False
            return True
        except ImportError:
            return True  # 如果没有psutil，假设内存充足
    
    def load_all_subjects(self, max_subjects: Optional[int] = None) -> Dict:
        """加载所有被试数据，改进内存管理"""
        all_data = {}
        
        if max_subjects is None:
            max_subjects = self.config.MAX_SUBJECTS
        
        # 获取所有被试ID
        subject_ids = []
        try:
            for item in os.listdir(self.data_root):
                if item.startswith("sub-") and os.path.isdir(os.path.join(self.data_root, item)):
                    subject_id = item.split("-")[1]
                    subject_ids.append(subject_id)
        except Exception as e:
            self.logger.error(f"Error reading data directory {self.data_root}: {e}")
            return {}
        
        subject_ids = sorted(subject_ids, key=lambda x: int(x) if x.isdigit() else 0)
        if max_subjects:
            subject_ids = subject_ids[:max_subjects]
        
        self.logger.info(f"Found {len(subject_ids)} subjects to process")
        
        successful_loads = 0
        for subject_id in tqdm(subject_ids, desc="Loading subjects"):
            if not self.check_memory_usage():
                self.logger.warning("Memory usage too high, stopping data loading")
                break
            
            sessions = self.get_subject_sessions(subject_id)
            if not sessions:
                continue
            
            all_data[subject_id] = {}
            
            for session_id in sessions:
                try:
                    raw = self.load_raw_eeg(subject_id, session_id)
                    if raw is not None:
                        raw = self.preprocess_eeg(raw)
                        if raw is not None:
                            epochs = self.extract_epochs(raw)
                            if epochs is not None:
                                all_data[subject_id][session_id] = {
                                    'raw': raw,
                                    'epochs': epochs,
                                    'positions': self.get_electrode_positions(raw.ch_names)
                                }
                                successful_loads += 1
                                self.logger.info(f"Successfully loaded subject {subject_id}, session {session_id}")
                            else:
                                self.logger.warning(f"Failed to extract epochs for subject {subject_id}, session {session_id}")
                        else:
                            self.logger.warning(f"Failed to preprocess data for subject {subject_id}, session {session_id}")
                    else:
                        self.logger.warning(f"Failed to load raw data for subject {subject_id}, session {session_id}")
                        
                except Exception as e:
                    self.logger.error(f"Error processing subject {subject_id}, session {session_id}: {e}")
                    continue
            
            # 如果这个被试没有成功加载任何session，移除它
            if not all_data[subject_id]:
                del all_data[subject_id]
                
            # 定期清理内存
            if successful_loads % 5 == 0:
                gc.collect()
        
        self.logger.info(f"Successfully loaded data from {len(all_data)} subjects")
        return all_data

# ========== src/topography.py ==========
# 相对路径: src/topography.py
# 在项目中的相对位置: ./src/topography.py

import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import griddata
from scipy.ndimage import gaussian_filter
import cv2
from typing import Dict, Tuple, List, Optional
import logging
import warnings

# 抑制插值警告
warnings.filterwarnings('ignore', category=RuntimeWarning)

class TopographyGenerator:
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # 预计算头部掩码以提高效率
        self._head_mask = self.create_head_mask(config.TOPO_SIZE)
        
    def create_head_mask(self, size: Tuple[int, int]) -> np.ndarray:
        """创建头部轮廓掩码"""
        h, w = size
        center = (w // 2, h // 2)
        radius = min(w, h) // 2 - 5
        
        # 创建圆形掩码
        y, x = np.ogrid[:h, :w]
        mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
        
        return mask.astype(bool)
    
    def electrode_to_pixel(self, pos: Tuple[float, float], size: Tuple[int, int]) -> Tuple[int, int]:
        """将电极位置转换为像素坐标"""
        x, y = pos
        h, w = size
        
        # 标准化坐标到像素坐标
        # 电极坐标范围 [-1, 1] 映射到像素坐标
        pixel_x = int((x + 1) * w / 2)
        pixel_y = int((1 - y) * h / 2)  # Y轴翻转
        
        # 确保在边界内
        pixel_x = max(0, min(w - 1, pixel_x))
        pixel_y = max(0, min(h - 1, pixel_y))
        
        return pixel_x, pixel_y
    
    def validate_electrode_data(self, eeg_data: np.ndarray, 
                               electrode_positions: Dict[str, Tuple[float, float]],
                               ch_names: List[str]) -> Tuple[np.ndarray, List[Tuple[float, float]], List[str]]:
        """验证和清理电极数据"""
        valid_positions = []
        valid_values = []
        valid_names = []
        
        for i, ch_name in enumerate(ch_names):
            if ch_name in electrode_positions:
                pos = electrode_positions[ch_name]
                
                # 检查位置是否合理
                if abs(pos[0]) <= 1.2 and abs(pos[1]) <= 1.2:  # 允许略微超出标准范围
                    # 检查数据是否有效
                    if i < len(eeg_data) and not np.isnan(eeg_data[i]) and not np.isinf(eeg_data[i]):
                        valid_positions.append(pos)
                        valid_values.append(eeg_data[i])
                        valid_names.append(ch_name)
                    else:
                        self.logger.warning(f"Invalid data for electrode {ch_name}: {eeg_data[i] if i < len(eeg_data) else 'missing'}")
                else:
                    self.logger.warning(f"Invalid position for electrode {ch_name}: {pos}")
            else:
                self.logger.warning(f"No position found for electrode {ch_name}")
        
        return np.array(valid_values), valid_positions, valid_names
    
    def generate_topography(self, eeg_data: np.ndarray, 
                          electrode_positions: Dict[str, Tuple[float, float]],
                          ch_names: List[str]) -> np.ndarray:
        """生成脑电地形图"""
        size = self.config.TOPO_SIZE
        
        # 验证和清理数据
        values, positions, valid_names = self.validate_electrode_data(
            eeg_data, electrode_positions, ch_names
        )
        
        if len(positions) < 3:
            self.logger.warning(f"Not enough valid electrode positions for interpolation: {len(positions)}")
            return np.zeros(size)
        
        positions = np.array(positions)
        
        # 创建插值网格
        xi = np.linspace(-1.2, 1.2, size[1])  # 稍微扩大范围以获得更好的边界效果
        yi = np.linspace(-1.2, 1.2, size[0])
        xi_grid, yi_grid = np.meshgrid(xi, yi)
        
        # 执行插值
        try:
            # 首先尝试cubic插值
            topography = griddata(positions, values, (xi_grid, yi_grid), 
                                method=self.config.INTERPOLATION_METHOD, 
                                fill_value=0)
            
            # 检查插值结果
            if np.all(np.isnan(topography)):
                raise ValueError("Cubic interpolation failed")
                
        except (ValueError, Exception) as e:
            self.logger.warning(f"Cubic interpolation failed: {e}, trying linear interpolation")
            try:
                topography = griddata(positions, values, (xi_grid, yi_grid), 
                                    method='linear', fill_value=0)
            except Exception as e2:
                self.logger.warning(f"Linear interpolation failed: {e2}, trying nearest neighbor")
                topography = griddata(positions, values, (xi_grid, yi_grid), 
                                    method='nearest', fill_value=0)
        
        # 处理NaN值
        topography = np.nan_to_num(topography, nan=0.0, posinf=0.0, neginf=0.0)
        
        # 应用头部掩码
        topography[~self._head_mask] = 0
        
        # 平滑处理
        try:
            sigma = max(1.0, min(size) / 64.0)  # 自适应平滑参数
            topography = gaussian_filter(topography, sigma=sigma)
        except Exception as e:
            self.logger.warning(f"Gaussian filtering failed: {e}")
        
        return topography
    
    def generate_time_series_topographies(self, epochs_data: np.ndarray,
                                        electrode_positions: Dict[str, Tuple[float, float]],
                                        ch_names: List[str]) -> np.ndarray:
        """为时间序列数据生成地形图序列"""
        n_epochs, n_channels, n_times = epochs_data.shape
        size = self.config.TOPO_SIZE
        
        self.logger.info(f"生成地形图序列: {n_epochs} epochs, {n_channels} channels, {n_times} time points")
        
        # 初始化输出数组
        topographies = np.zeros((n_epochs, n_times, size[0], size[1]))
        
        # 预处理电极位置信息
        valid_electrode_indices = []
        valid_positions = []
        
        for i, ch_name in enumerate(ch_names):
            if ch_name in electrode_positions:
                pos = electrode_positions[ch_name]
                if abs(pos[0]) <= 1.2 and abs(pos[1]) <= 1.2:
                    valid_electrode_indices.append(i)
                    valid_positions.append(pos)
        
        if len(valid_positions) < 3:
            self.logger.error("Not enough valid electrodes for topography generation")
            return topographies
        
        self.logger.info(f"Using {len(valid_positions)} valid electrodes for interpolation")
        
        # 生成地形图
        for epoch in range(n_epochs):
            for time_point in range(n_times):
                # 提取有效电极的数据
                valid_data = epochs_data[epoch, valid_electrode_indices, time_point]
                
                # 检查数据质量
                if np.any(np.isfinite(valid_data)) and np.std(valid_data) > 1e-10:
                    try:
                        topo = self._generate_single_topography(valid_data, valid_positions)
                        topographies[epoch, time_point] = topo
                    except Exception as e:
                        self.logger.warning(f"Failed to generate topography for epoch {epoch}, time {time_point}: {e}")
                        topographies[epoch, time_point] = np.zeros(size)
                else:
                    # 数据质量不好或全为零，使用零地形图
                    topographies[epoch, time_point] = np.zeros(size)
        
        return topographies
    
    def _generate_single_topography(self, eeg_data: np.ndarray, 
                                   positions: List[Tuple[float, float]]) -> np.ndarray:
        """生成单个地形图（内部方法，已知数据有效）"""
        size = self.config.TOPO_SIZE
        positions = np.array(positions)
        
        # 创建插值网格
        xi = np.linspace(-1.2, 1.2, size[1])
        yi = np.linspace(-1.2, 1.2, size[0])
        xi_grid, yi_grid = np.meshgrid(xi, yi)
        
        # 执行插值
        try:
            topography = griddata(positions, eeg_data, (xi_grid, yi_grid), 
                                method=self.config.INTERPOLATION_METHOD, 
                                fill_value=0)
            
            if np.all(np.isnan(topography)):
                topography = griddata(positions, eeg_data, (xi_grid, yi_grid), 
                                    method='linear', fill_value=0)
        except:
            topography = griddata(positions, eeg_data, (xi_grid, yi_grid), 
                                method='nearest', fill_value=0)
        
        # 处理异常值
        topography = np.nan_to_num(topography, nan=0.0, posinf=0.0, neginf=0.0)
        
        # 应用头部掩码
        topography[~self._head_mask] = 0
        
        # 平滑处理
        sigma = max(1.0, min(size) / 64.0)
        topography = gaussian_filter(topography, sigma=sigma)
        
        return topography
    
    def normalize_topography(self, topography: np.ndarray, 
                           method: str = 'minmax') -> np.ndarray:
        """标准化地形图"""
        # 只考虑头部区域内的值
        masked_topo = topography[self._head_mask]
        
        if len(masked_topo) == 0 or np.all(masked_topo == 0):
            return topography
        
        if method == 'minmax':
            topo_min = np.min(masked_topo)
            topo_max = np.max(masked_topo)
            
            if topo_max > topo_min:
                # 只标准化头部区域
                normalized = topography.copy()
                normalized[self._head_mask] = (masked_topo - topo_min) / (topo_max - topo_min)
                return normalized
            else:
                return topography
                
        elif method == 'zscore':
            mean_val = np.mean(masked_topo)
            std_val = np.std(masked_topo)
            
            if std_val > 1e-10:
                normalized = topography.copy()
                normalized[self._head_mask] = (masked_topo - mean_val) / std_val
                return normalized
            else:
                return topography
                
        elif method == 'robust':
            # 使用中位数和四分位距进行robust标准化
            median_val = np.median(masked_topo)
            q75, q25 = np.percentile(masked_topo, [75, 25])
            iqr = q75 - q25
            
            if iqr > 1e-10:
                normalized = topography.copy()
                normalized[self._head_mask] = (masked_topo - median_val) / iqr
                return normalized
            else:
                return topography
        else:
            return topography
    
    def enhance_topography(self, topography: np.ndarray, 
                          enhancement_factor: float = 1.5) -> np.ndarray:
        """增强地形图对比度"""
        enhanced = topography.copy()
        
        # 只处理头部区域
        masked_data = enhanced[self._head_mask]
        
        if len(masked_data) > 0:
            # 使用sigmoid函数增强对比度
            mean_val = np.mean(masked_data)
            enhanced_data = mean_val + (masked_data - mean_val) * enhancement_factor
            
            # 使用tanh函数平滑截断
            enhanced_data = np.tanh(enhanced_data)
            
            enhanced[self._head_mask] = enhanced_data
        
        return enhanced
    
    def save_topography(self, topography: np.ndarray, filepath: str,
                       colormap: str = None, title: str = "") -> None:
        """保存地形图"""
        if colormap is None:
            colormap = self.config.COLORMAP
        
        plt.figure(figsize=(8, 8))
        
        # 创建地形图
        im = plt.imshow(topography, cmap=colormap, interpolation='bilinear', origin='upper')
        
        # 添加颜色条
        cbar = plt.colorbar(im, shrink=0.8)
        cbar.set_label('激活强度 (μV)', fontsize=12)
        
        # 添加头部轮廓
        center = (topography.shape[1]//2, topography.shape[0]//2)
        radius = min(topography.shape)//2 - 5
        circle = plt.Circle(center, radius, fill=False, color='black', linewidth=2)
        plt.gca().add_patch(circle)
        
        plt.title(title if title else 'EEG Topography', fontsize=14, fontweight='bold')
        plt.axis('off')
        plt.tight_layout()
        
        try:
            plt.savefig(filepath, dpi=150, bbox_inches='tight')
            self.logger.info(f"Topography saved to {filepath}")
        except Exception as e:
            self.logger.error(f"Failed to save topography to {filepath}: {e}")
        finally:
            plt.close()
    
    def get_electrode_contributions(self, topography: np.ndarray,
                                  electrode_positions: Dict[str, Tuple[float, float]],
                                  ch_names: List[str]) -> Dict[str, float]:
        """计算各电极对地形图的贡献度"""
        contributions = {}
        size = self.config.TOPO_SIZE
        
        for ch_name in ch_names:
            if ch_name in electrode_positions:
                pos = electrode_positions[ch_name]
                pixel_x, pixel_y = self.electrode_to_pixel(pos, size)
                
                # 提取电极周围区域的平均值作为贡献度
                radius = 5
                y_min = max(0, pixel_y - radius)
                y_max = min(size[0], pixel_y + radius + 1)
                x_min = max(0, pixel_x - radius)
                x_max = min(size[1], pixel_x + radius + 1)
                
                region = topography[y_min:y_max, x_min:x_max]
                contributions[ch_name] = float(np.mean(region)) if region.size > 0 else 0.0
        
        return contributions
    
    def create_difference_topography(self, topo1: np.ndarray, topo2: np.ndarray) -> np.ndarray:
        """创建差异地形图"""
        if topo1.shape != topo2.shape:
            self.logger.error("Topographies must have the same shape for difference calculation")
            return np.zeros_like(topo1)
        
        difference = topo1 - topo2
        
        # 只保留头部区域的差异
        difference[~self._head_mask] = 0
        
        return difference

# ========== src/trajectory_analysis.py ==========
# 相对路径: src/trajectory_analysis.py
# 在项目中的相对位置: ./src/trajectory_analysis.py

import numpy as np
import pandas as pd
from scipy.spatial.distance import pdist, squareform, euclidean
from scipy.cluster.hierarchy import linkage, fcluster
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import logging

# 使用fastdtw替代dtw
try:
    from fastdtw import fastdtw
    DTW_AVAILABLE = True
except ImportError:
    DTW_AVAILABLE = False

class TrajectoryAnalyzer:
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        if not DTW_AVAILABLE:
            self.logger.warning("FastDTW not available, using Euclidean distance for trajectory comparison")
    
    def compute_trajectory_features(self, trajectory: np.ndarray) -> Dict:
        """计算轨迹特征"""
        if len(trajectory) < 2:
            return {}
        
        try:
            # 基本几何特征
            length = len(trajectory)
            
            # 计算逐步距离
            step_distances = np.linalg.norm(np.diff(trajectory, axis=0), axis=1)
            total_distance = np.sum(step_distances)
            displacement = np.linalg.norm(trajectory[-1] - trajectory[0])
            
            # 速度特征
            mean_velocity = np.mean(step_distances) if len(step_distances) > 0 else 0
            max_velocity = np.max(step_distances) if len(step_distances) > 0 else 0
            velocity_std = np.std(step_distances) if len(step_distances) > 0 else 0
            
            # 方向特征
            if length > 2:
                directions = np.diff(trajectory, axis=0)
                angles = np.arctan2(directions[:, 1], directions[:, 0])
                angle_changes = np.diff(angles)
                # 处理角度跳跃
                angle_changes = np.mod(angle_changes + np.pi, 2*np.pi) - np.pi
                mean_angle_change = np.mean(np.abs(angle_changes))
                tortuosity = total_distance / (displacement + 1e-8)
            else:
                mean_angle_change = 0
                tortuosity = 1
            
            # 覆盖区域
            if length > 2:
                min_coords = np.min(trajectory, axis=0)
                max_coords = np.max(trajectory, axis=0)
                ranges = max_coords - min_coords
                bounding_area = np.prod(ranges) if np.all(ranges > 0) else 0
            else:
                bounding_area = 0
            
            # 质心和散布
            centroid = np.mean(trajectory, axis=0)
            distances_to_centroid = np.linalg.norm(trajectory - centroid, axis=1)
            mean_spread = np.mean(distances_to_centroid)
            max_spread = np.max(distances_to_centroid)
            
            # 轨迹复杂度
            complexity = np.sum(np.abs(np.diff(step_distances))) if len(step_distances) > 1 else 0
            
            return {
                'length': length,
                'total_distance': total_distance,
                'displacement': displacement,
                'mean_velocity': mean_velocity,
                'max_velocity': max_velocity,
                'velocity_std': velocity_std,
                'mean_angle_change': mean_angle_change,
                'tortuosity': tortuosity,
                'bounding_area': bounding_area,
                'straightness': displacement / (total_distance + 1e-8),
                'mean_spread': mean_spread,
                'max_spread': max_spread,
                'complexity': complexity
            }
            
        except Exception as e:
            self.logger.error(f"Error computing trajectory features: {e}")
            return {}
    
    def compute_dtw_distance(self, traj1: np.ndarray, traj2: np.ndarray) -> float:
        """计算两条轨迹之间的DTW距离"""
        try:
            if DTW_AVAILABLE:
                distance, _ = fastdtw(traj1, traj2, dist=euclidean)
                return distance
            else:
                # 使用形状匹配的欧几里得距离作为后备
                return self.compute_shape_distance(traj1, traj2)
        except Exception as e:
            self.logger.warning(f"DTW computation failed: {e}, using shape distance")
            return self.compute_shape_distance(traj1, traj2)
    
    def compute_shape_distance(self, traj1: np.ndarray, traj2: np.ndarray) -> float:
        """计算轨迹形状距离（当DTW不可用时的后备方案）"""
        try:
            # 标准化轨迹长度
            from scipy.interpolate import interp1d
            
            # 选择较短轨迹的长度作为标准长度
            target_length = min(len(traj1), len(traj2), 50)  # 限制最大长度以提高效率
            
            if len(traj1) < 2 or len(traj2) < 2:
                return np.linalg.norm(traj1.flatten() - traj2.flatten())
            
            # 创建插值函数
            t1 = np.linspace(0, 1, len(traj1))
            t2 = np.linspace(0, 1, len(traj2))
            t_new = np.linspace(0, 1, target_length)
            
            # 对每个维度进行插值
            traj1_interp = np.zeros((target_length, traj1.shape[1]))
            traj2_interp = np.zeros((target_length, traj2.shape[1]))
            
            for dim in range(traj1.shape[1]):
                f1 = interp1d(t1, traj1[:, dim], kind='linear', bounds_error=False, fill_value='extrapolate')
                f2 = interp1d(t2, traj2[:, dim], kind='linear', bounds_error=False, fill_value='extrapolate')
                traj1_interp[:, dim] = f1(t_new)
                traj2_interp[:, dim] = f2(t_new)
            
            # 计算欧几里得距离
            return np.linalg.norm(traj1_interp - traj2_interp)
            
        except Exception as e:
            self.logger.warning(f"Shape distance computation failed: {e}")
            # 最后的后备方案：简单的端点距离
            return euclidean(traj1[-1], traj2[-1]) + euclidean(traj1[0], traj2[0])
    
    def compute_trajectory_similarity_matrix(self, trajectories: Dict) -> np.ndarray:
        """计算轨迹相似性矩阵"""
        trajectory_list = list(trajectories.values())
        n_trajectories = len(trajectory_list)
        
        if n_trajectories < 2:
            return np.array([[1.0]])
        
        # 计算距离矩阵
        distance_matrix = np.zeros((n_trajectories, n_trajectories))
        
        self.logger.info(f"Computing similarity matrix for {n_trajectories} trajectories")
        
        for i in range(n_trajectories):
            for j in range(i+1, n_trajectories):
                traj1 = trajectory_list[i]['trajectory']
                traj2 = trajectory_list[j]['trajectory']
                
                try:
                    distance = self.compute_dtw_distance(traj1, traj2)
                    distance_matrix[i, j] = distance
                    distance_matrix[j, i] = distance
                except Exception as e:
                    self.logger.warning(f"Distance computation failed for trajectories {i}, {j}: {e}")
                    distance_matrix[i, j] = float('inf')
                    distance_matrix[j, i] = float('inf')
        
        # 转换为相似性矩阵
        max_distance = np.max(distance_matrix[distance_matrix != float('inf')])
        if max_distance > 0:
            # 处理无穷大值
            distance_matrix[distance_matrix == float('inf')] = max_distance * 2
            similarity_matrix = 1 - distance_matrix / (max_distance * 2)
        else:
            similarity_matrix = np.ones_like(distance_matrix)
        
        # 确保对角线为1
        np.fill_diagonal(similarity_matrix, 1.0)
        
        return similarity_matrix
    
    def cluster_trajectories(self, trajectories: Dict, method: str = 'hierarchical',
                           n_clusters: Optional[int] = None) -> Dict:
        """聚类轨迹"""
        if len(trajectories) < 2:
            return {'labels': [0], 'n_clusters': 1, 'trajectory_ids': list(trajectories.keys())}
        
        # 计算特征矩阵
        features = []
        trajectory_ids = []
        
        for traj_id, traj_data in trajectories.items():
            traj_features = self.compute_trajectory_features(traj_data['trajectory'])
            if traj_features:  # 确保特征不为空
                feature_vector = [
                    traj_features.get('total_distance', 0),
                    traj_features.get('displacement', 0),
                    traj_features.get('mean_velocity', 0),
                    traj_features.get('tortuosity', 1),
                    traj_features.get('straightness', 0),
                    traj_features.get('bounding_area', 0),
                    traj_features.get('mean_spread', 0),
                    traj_features.get('complexity', 0)
                ]
                features.append(feature_vector)
                trajectory_ids.append(traj_id)
        
        if len(features) < 2:
            return {'labels': [0], 'n_clusters': 1, 'trajectory_ids': trajectory_ids}
        
        features = np.array(features)
        
        # 标准化特征
        try:
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features)
        except Exception as e:
            self.logger.warning(f"Feature scaling failed: {e}, using original features")
            features_scaled = features
        
        # 处理NaN和无穷大值
        features_scaled = np.nan_to_num(features_scaled, nan=0.0, posinf=1.0, neginf=-1.0)
        
        try:
            if method == 'hierarchical':
                labels, n_clusters = self._hierarchical_clustering(features_scaled, n_clusters)
            elif method == 'kmeans':
                labels, n_clusters = self._kmeans_clustering(features_scaled, n_clusters)
            elif method == 'dbscan':
                labels, n_clusters = self._dbscan_clustering(features_scaled)
            else:
                self.logger.error(f"Unknown clustering method: {method}")
                return {'labels': [0] * len(features), 'n_clusters': 1, 'trajectory_ids': trajectory_ids}
            
        except Exception as e:
            self.logger.error(f"Clustering failed: {e}")
            return {'labels': [0] * len(features), 'n_clusters': 1, 'trajectory_ids': trajectory_ids}
        
        return {
            'labels': labels,
            'n_clusters': n_clusters,
            'trajectory_ids': trajectory_ids,
            'features': features_scaled
        }
    
    def _hierarchical_clustering(self, features: np.ndarray, n_clusters: Optional[int]) -> Tuple[np.ndarray, int]:
        """层次聚类"""
        linkage_matrix = linkage(features, method='ward')
        
        if n_clusters is None:
            # 自动确定聚类数
            max_clusters = min(len(features) // 2, 5)
            best_score = -1
            best_n_clusters = 2
            
            for n in range(2, max_clusters + 1):
                try:
                    labels = fcluster(linkage_matrix, n, criterion='maxclust')
                    if len(np.unique(labels)) > 1:
                        score = silhouette_score(features, labels)
                        if score > best_score:
                            best_score = score
                            best_n_clusters = n
                except Exception as e:
                    self.logger.warning(f"Silhouette score computation failed for n={n}: {e}")
                    continue
            
            n_clusters = best_n_clusters
        
        labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')
        return labels, n_clusters
    
    def _kmeans_clustering(self, features: np.ndarray, n_clusters: Optional[int]) -> Tuple[np.ndarray, int]:
        """K-means聚类"""
        if n_clusters is None:
            n_clusters = min(len(features) // 2, 3)
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = kmeans.fit_predict(features)
        return labels, n_clusters
    
    def _dbscan_clustering(self, features: np.ndarray) -> Tuple[np.ndarray, int]:
        """DBSCAN聚类"""
        dbscan = DBSCAN(eps=0.5, min_samples=2)
        labels = dbscan.fit_predict(features)
        n_clusters = len(np.unique(labels[labels >= 0]))
        return labels, n_clusters
    
    def analyze_subject_consistency(self, subject_trajectories: Dict) -> Dict:
        """分析单个被试的轨迹一致性"""
        results = {}
        
        for subject_id, sessions in subject_trajectories.items():
            self.logger.info(f"Analyzing consistency for subject {subject_id}")
            subject_results = {}
            
            # 收集该被试的所有轨迹
            all_trajectories = {}
            for session_id, trajectories in sessions.items():
                for traj_id, traj_data in trajectories.items():
                    key = f"{session_id}_{traj_id}"
                    all_trajectories[key] = traj_data
            
            if len(all_trajectories) > 1:
                try:
                    # 计算相似性矩阵
                    similarity_matrix = self.compute_trajectory_similarity_matrix(all_trajectories)
                    
                    # 聚类分析
                    clustering_results = self.cluster_trajectories(all_trajectories)
                    
                    # 计算一致性指标
                    upper_triangle = similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]
                    mean_similarity = np.mean(upper_triangle)
                    consistency_score = mean_similarity
                    
                    subject_results = {
                        'n_trajectories': len(all_trajectories),
                        'mean_similarity': float(mean_similarity),
                        'consistency_score': float(consistency_score),
                        'n_clusters': clustering_results['n_clusters'],
                        'clustering': clustering_results,
                        'similarity_matrix': similarity_matrix
                    }
                    
                except Exception as e:
                    self.logger.error(f"Consistency analysis failed for subject {subject_id}: {e}")
                    subject_results = {
                        'n_trajectories': len(all_trajectories),
                        'error': str(e)
                    }
            else:
                subject_results = {
                    'n_trajectories': len(all_trajectories),
                    'note': 'Insufficient trajectories for analysis'
                }
            
            results[subject_id] = subject_results
        
        return results
    
    def compare_subjects(self, subject_trajectories: Dict) -> Dict:
        """比较不同被试之间的差异"""
        # 计算每个被试的总体特征
        subject_features = {}
        
        for subject_id, sessions in subject_trajectories.items():
            all_trajectories = {}
            for session_id, trajectories in sessions.items():
                for traj_id, traj_data in trajectories.items():
                    key = f"{session_id}_{traj_id}"
                    all_trajectories[key] = traj_data
            
            if all_trajectories:
                # 计算平均特征
                features_list = []
                for traj_data in all_trajectories.values():
                    traj_features = self.compute_trajectory_features(traj_data['trajectory'])
                    if traj_features:
                        features_list.append(traj_features)
                
                if features_list:
                    # 计算平均特征
                    mean_features = {}
                    for key in features_list[0].keys():
                        values = [f[key] for f in features_list if key in f and not np.isnan(f[key])]
                        mean_features[key] = np.mean(values) if values else 0
                    
                    subject_features[subject_id] = mean_features
        
        # 计算被试间距离矩阵
        inter_subject_similarity = {}
        if len(subject_features) > 1:
            subject_ids = list(subject_features.keys())
            n_subjects = len(subject_ids)
            distance_matrix = np.zeros((n_subjects, n_subjects))
            
            # 提取特征向量
            feature_keys = list(subject_features[subject_ids[0]].keys())
            subject_vectors = []
            
            for subject_id in subject_ids:
                vector = [subject_features[subject_id][key] for key in feature_keys]
                subject_vectors.append(vector)
            
            subject_vectors = np.array(subject_vectors)
            
            # 计算距离矩阵
            for i in range(n_subjects):
                for j in range(i+1, n_subjects):
                    dist = euclidean(subject_vectors[i], subject_vectors[j])
                    distance_matrix[i, j] = dist
                    distance_matrix[j, i] = dist
            
            # 转换为相似性
            max_dist = np.max(distance_matrix)
            if max_dist > 0:
                similarity_matrix = 1 - distance_matrix / max_dist
            else:
                similarity_matrix = np.ones_like(distance_matrix)
            
            np.fill_diagonal(similarity_matrix, 1.0)
            inter_subject_similarity = {
                'similarity_matrix': similarity_matrix,
                'subject_ids': subject_ids
            }
        
        return {
            'subject_features': subject_features,
            'n_subjects': len(subject_features),
            'inter_subject_similarity': inter_subject_similarity
        }
    
    def generate_summary_report(self, analysis_results: Dict) -> str:
        """生成分析报告"""
        report = []
        report.append("=" * 60)
        report.append("EEG轨迹分析报告")
        report.append("=" * 60)
        report.append("")
        
        # 总体统计
        if 'subject_consistency' in analysis_results:
            consistency_results = analysis_results['subject_consistency']
            n_subjects = len(consistency_results)
            report.append(f"分析被试数量: {n_subjects}")
            
            # 一致性统计
            consistency_scores = []
            trajectory_counts = []
            
            for subject_id, results in consistency_results.items():
                if 'consistency_score' in results:
                    consistency_scores.append(results['consistency_score'])
                    trajectory_counts.append(results['n_trajectories'])
            
            if consistency_scores:
                mean_consistency = np.mean(consistency_scores)
                std_consistency = np.std(consistency_scores)
                min_consistency = np.min(consistency_scores)
                max_consistency = np.max(consistency_scores)
                
                report.append(f"平均一致性得分: {mean_consistency:.3f} ± {std_consistency:.3f}")
                report.append(f"一致性得分范围: {min_consistency:.3f} - {max_consistency:.3f}")
                
                total_trajectories = sum(trajectory_counts)
                mean_trajectories = np.mean(trajectory_counts)
                report.append(f"总轨迹数量: {total_trajectories}")
                report.append(f"平均每被试轨迹数: {mean_trajectories:.1f}")
            
            report.append("")
        
        # 各被试详细结果
        if 'subject_consistency' in analysis_results:
            report.append("各被试一致性分析详情:")
            report.append("-" * 40)
            
            for subject_id, results in consistency_results.items():
                report.append(f"被试 {subject_id}:")
                
                if 'error' in results:
                    report.append(f"  分析出错: {results['error']}")
                elif 'note' in results:
                    report.append(f"  {results['note']}")
                    report.append(f"  轨迹数量: {results['n_trajectories']}")
                else:
                    report.append(f"  轨迹数量: {results['n_trajectories']}")
                    if 'consistency_score' in results:
                        report.append(f"  一致性得分: {results['consistency_score']:.3f}")
                        report.append(f"  聚类数量: {results['n_clusters']}")
                        
                        # 如果有聚类信息，显示聚类分布
                        if 'clustering' in results and 'labels' in results['clustering']:
                            labels = results['clustering']['labels']
                            unique_labels, counts = np.unique(labels, return_counts=True)
                            cluster_info = [f"簇{label}: {count}条轨迹" for label, count in zip(unique_labels, counts)]
                            report.append(f"  聚类分布: {', '.join(cluster_info)}")
                
                report.append("")
        
        # 被试间比较
        if 'subject_comparison' in analysis_results:
            comparison_results = analysis_results['subject_comparison']
            report.append("被试间比较:")
            report.append("-" * 40)
            
            if 'inter_subject_similarity' in comparison_results:
                similarity_info = comparison_results['inter_subject_similarity']
                if 'similarity_matrix' in similarity_info:
                    similarity_matrix = similarity_info['similarity_matrix']
                    # 计算平均被试间相似性（排除对角线）
                    upper_triangle = similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]
                    mean_inter_similarity = np.mean(upper_triangle)
                    report.append(f"平均被试间相似性: {mean_inter_similarity:.3f}")
                    
                    # 找出最相似和最不相似的被试对
                    subject_ids = similarity_info['subject_ids']
                    max_idx = np.unravel_index(np.argmax(upper_triangle), 
                                             (len(subject_ids), len(subject_ids)))
                    min_idx = np.unravel_index(np.argmin(upper_triangle), 
                                             (len(subject_ids), len(subject_ids)))
                    
                    if len(subject_ids) > 1:
                        # 重新计算上三角矩阵的索引
                        triu_indices = np.triu_indices_from(similarity_matrix, k=1)
                        max_pos = np.argmax(upper_triangle)
                        min_pos = np.argmin(upper_triangle)
                        
                        max_i, max_j = triu_indices[0][max_pos], triu_indices[1][max_pos]
                        min_i, min_j = triu_indices[0][min_pos], triu_indices[1][min_pos]
                        
                        report.append(f"最相似被试对: {subject_ids[max_i]} - {subject_ids[max_j]} "
                                    f"(相似性: {similarity_matrix[max_i, max_j]:.3f})")
                        report.append(f"最不相似被试对: {subject_ids[min_i]} - {subject_ids[min_j]} "
                                    f"(相似性: {similarity_matrix[min_i, min_j]:.3f})")
            
            report.append("")
        
        # 添加方法说明
        report.append("分析方法说明:")
        report.append("-" * 40)
        report.append("• 轨迹特征: 包括总距离、位移、速度、弯曲度、直线度等")
        if DTW_AVAILABLE:
            report.append("• 相似性计算: 使用动态时间规整(DTW)算法")
        else:
            report.append("• 相似性计算: 使用形状匹配的欧几里得距离")
        report.append("• 聚类方法: 层次聚类，自动确定最佳聚类数")
        report.append("• 一致性评分: 基于轨迹间平均相似性计算")
        
        return "\n".join(report)

# ========== src/visualization.py ==========
# 相对路径: src/visualization.py
# 在项目中的相对位置: ./src/visualization.py

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import seaborn as sns
import cv2
from typing import Dict, List, Tuple, Optional
import os
import logging
import warnings

# Suppress warnings
warnings.filterwarnings('ignore', category=UserWarning)

# Set up matplotlib for English only
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Liberation Sans']

class Visualizer:
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Set color theme
        self.colors = plt.cm.Set1(np.linspace(0, 1, 10))
        self.background_color = '#f8f9fa'
        self.grid_color = '#e9ecef'
        
        self.logger.info("Visualizer initialized with English labels")
    
    def setup_figure_style(self, fig, title: str = ""):
        """Set unified figure style"""
        fig.patch.set_facecolor(self.background_color)
        if title:
            fig.suptitle(title, fontsize=16, fontweight='bold', y=0.95)
    
    def add_head_outline(self, ax, center: Tuple[float, float], radius: float, 
                        color: str = 'black', linewidth: float = 2):
        """Add head outline"""
        circle = plt.Circle(center, radius, fill=False, color=color, 
                           linewidth=linewidth, alpha=0.8)
        ax.add_patch(circle)
        
        # Add nose marker
        nose_x, nose_y = center[0], center[1] + radius * 0.1
        ax.plot([nose_x], [nose_y], 'k^', markersize=8, alpha=0.8)
        
        # Add ear markers
        ear_y = center[1]
        left_ear_x = center[0] - radius * 1.1
        right_ear_x = center[0] + radius * 1.1
        ax.plot([left_ear_x, right_ear_x], [ear_y, ear_y], 'k-', 
                linewidth=3, alpha=0.6)
    
    def plot_topography(self, topography: np.ndarray, title: str = "", 
                       save_path: Optional[str] = None, show_colorbar: bool = True,
                       electrode_positions: Optional[Dict] = None) -> None:
        """Plot single topography"""
        try:
            fig, ax = plt.subplots(figsize=(10, 8))
            self.setup_figure_style(fig, title)
            
            # Create topography
            im = ax.imshow(topography, cmap=self.config.COLORMAP, 
                          interpolation='bilinear', origin='upper',
                          extent=[0, topography.shape[1], topography.shape[0], 0])
            
            # Add colorbar
            if show_colorbar:
                cbar = plt.colorbar(im, ax=ax, shrink=0.8, pad=0.02)
                cbar.set_label('Activation Intensity (μV)', fontsize=12, fontweight='bold')
                cbar.ax.tick_params(labelsize=10)
            
            # Add head outline
            center = (topography.shape[1]//2, topography.shape[0]//2)
            radius = min(topography.shape)//2 - 5
            self.add_head_outline(ax, center, radius)
            
            # Mark electrodes if provided
            if electrode_positions:
                self.plot_electrode_positions(ax, electrode_positions, topography.shape)
            
            # Set axes
            ax.set_xlim(0, topography.shape[1])
            ax.set_ylim(topography.shape[0], 0)
            ax.set_aspect('equal')
            ax.axis('off')
            
            # Add scale bar
            self.add_scale_bar(ax, topography.shape)
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=self.config.DPI, bbox_inches='tight', 
                           facecolor=self.background_color)
                plt.close()
                self.logger.info(f"Topography saved to {save_path}")
            else:
                plt.show()
                
        except Exception as e:
            self.logger.error(f"Failed to plot topography: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def plot_electrode_positions(self, ax, electrode_positions: Dict, 
                               topography_shape: Tuple[int, int]):
        """Mark electrode positions on topography"""
        for ch_name, (x, y) in electrode_positions.items():
            # Convert coordinates
            pixel_x = (x + 1) * topography_shape[1] / 2
            pixel_y = (1 - y) * topography_shape[0] / 2
            
            # Draw electrode point
            ax.plot(pixel_x, pixel_y, 'wo', markersize=6, 
                   markeredgecolor='black', markeredgewidth=1)
            
            # Add electrode label (only for key electrodes to avoid crowding)
            if ch_name in ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2']:
                ax.text(pixel_x, pixel_y-8, ch_name, ha='center', va='top',
                       fontsize=8, fontweight='bold', color='white',
                       bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.7))
    
    def add_scale_bar(self, ax, shape: Tuple[int, int]):
        """Add scale bar"""
        scale_length = shape[1] // 10
        scale_x = shape[1] * 0.05
        scale_y = shape[0] * 0.95
        
        ax.plot([scale_x, scale_x + scale_length], [scale_y, scale_y], 
               'k-', linewidth=3)
        ax.text(scale_x + scale_length/2, scale_y - 5, f'{scale_length}px',
               ha='center', va='top', fontsize=10, fontweight='bold')
    
    def plot_trajectories(self, trajectories: Dict, topography_shape: Tuple[int, int],
                         title: str = "", save_path: Optional[str] = None,
                         show_legend: bool = True, alpha: float = 0.8) -> None:
        """Plot trajectories"""
        try:
            fig, ax = plt.subplots(figsize=(12, 10))
            self.setup_figure_style(fig, title)
            
            # Create background
            background = np.zeros(topography_shape)
            ax.imshow(background, cmap='gray', alpha=0.2, origin='upper',
                     extent=[0, topography_shape[1], topography_shape[0], 0])
            
            # Add grid
            ax.grid(True, alpha=0.3, color=self.grid_color, linewidth=0.5)
            
            # Plot trajectories
            legend_elements = []
            
            for i, (traj_id, traj_data) in enumerate(trajectories.items()):
                trajectory = traj_data['trajectory']
                color = self.colors[i % len(self.colors)]
                
                # Plot trajectory line
                line = ax.plot(trajectory[:, 1], trajectory[:, 0], 
                              color=color, linewidth=3, alpha=alpha, 
                              label=f'Trajectory {traj_id}')[0]
                
                # Mark start point
                start_point = ax.scatter(trajectory[0, 1], trajectory[0, 0], 
                                       color=color, s=150, marker='o', 
                                       edgecolors='white', linewidth=2, 
                                       zorder=5, alpha=0.9)
                
                # Mark end point
                end_point = ax.scatter(trajectory[-1, 1], trajectory[-1, 0], 
                                     color=color, s=150, marker='s', 
                                     edgecolors='white', linewidth=2, 
                                     zorder=5, alpha=0.9)
                
                # Add direction arrows
                self.add_direction_arrows(ax, trajectory, color, alpha)
                
                # Add trajectory info
                trajectory_info = f"Trajectory {traj_id}\nLength: {len(trajectory)} points"
                
                # Safely get intensity information
                intensity_value = None
                for key in ['mean_intensity', 'final_intensity', 'intensity']:
                    if key in traj_data:
                        intensity_value = traj_data[key]
                        break
                
                if intensity_value is not None:
                    trajectory_info += f"\nIntensity: {intensity_value:.2f}"
                
                legend_elements.append((line, trajectory_info))
            
            # Add head outline
            center = (topography_shape[1]//2, topography_shape[0]//2)
            radius = min(topography_shape)//2 - 5
            self.add_head_outline(ax, center, radius)
            
            # Set axes
            ax.set_xlim(0, topography_shape[1])
            ax.set_ylim(topography_shape[0], 0)
            ax.set_aspect('equal')
            ax.set_xlabel('X Coordinate (pixels)', fontsize=12, fontweight='bold')
            ax.set_ylabel('Y Coordinate (pixels)', fontsize=12, fontweight='bold')
            
            # Add legend
            if show_legend and legend_elements:
                legend_lines = [elem[0] for elem in legend_elements]
                legend_labels = [elem[1] for elem in legend_elements]
                ax.legend(legend_lines, legend_labels, bbox_to_anchor=(1.05, 1), 
                         loc='upper left', fontsize=10)
            
            # Add statistics
            self.add_trajectory_stats(ax, trajectories, topography_shape)
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=self.config.DPI, bbox_inches='tight',
                           facecolor=self.background_color)
                plt.close()
                self.logger.info(f"Trajectories plot saved to {save_path}")
            else:
                plt.show()
                
        except Exception as e:
            self.logger.error(f"Failed to plot trajectories: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def add_direction_arrows(self, ax, trajectory: np.ndarray, color, alpha: float):
        """Add trajectory direction arrows"""
        if len(trajectory) < 3:
            return
        
        # Add arrows at key points in trajectory
        arrow_positions = [len(trajectory)//4, len(trajectory)//2, 3*len(trajectory)//4]
        
        for pos in arrow_positions:
            if pos < len(trajectory) - 1:
                start = trajectory[pos]
                end = trajectory[pos + 1]
                
                dx = end[1] - start[1]
                dy = end[0] - start[0]
                
                # Only show arrow if movement is significant
                if abs(dx) > 0.5 or abs(dy) > 0.5:
                    try:
                        ax.arrow(start[1], start[0], dx, dy, 
                                head_width=3, head_length=4, fc=color, ec=color,
                                alpha=alpha*0.7, length_includes_head=True)
                    except:
                        pass  # Ignore arrow drawing errors
    
    def add_trajectory_stats(self, ax, trajectories: Dict, shape: Tuple[int, int]):
        """Add trajectory statistics"""
        stats_text = f"Total Trajectories: {len(trajectories)}\n"
        
        if trajectories:
            lengths = [len(traj_data['trajectory']) for traj_data in trajectories.values()]
            stats_text += f"Average Length: {np.mean(lengths):.1f} points\n"
            stats_text += f"Length Range: {min(lengths)}-{max(lengths)} points"
        
        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
               fontsize=10, verticalalignment='top',
               bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8))
    
    def create_algorithm_comparison_plot(self, algorithm_results: Dict, save_path: str):
        """Create comprehensive algorithm comparison visualization"""
        try:
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('EEG Trajectory Tracking Algorithm Comparison', fontsize=16, fontweight='bold')
            
            algorithms = list(algorithm_results.keys())
            colors = plt.cm.Set1(np.linspace(0, 1, len(algorithms)))
            
            # 1. Trajectory Count Comparison
            ax = axes[0, 0]
            trajectory_counts = []
            for alg in algorithms:
                count = algorithm_results[alg].get('avg_trajectories', 0)
                trajectory_counts.append(count)
            
            bars = ax.bar(algorithms, trajectory_counts, color=colors, alpha=0.7)
            ax.set_title('Average Trajectory Count', fontweight='bold')
            ax.set_ylabel('Number of Trajectories')
            ax.tick_params(axis='x', rotation=45)
            
            # Add value labels
            for bar, count in zip(bars, trajectory_counts):
                if count > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                           f'{count:.1f}', ha='center', va='bottom')
            
            # 2. Computation Time Comparison
            ax = axes[0, 1]
            comp_times = []
            for alg in algorithms:
                time = algorithm_results[alg].get('avg_time', 0)
                comp_times.append(time)
            
            bars = ax.bar(algorithms, comp_times, color=colors, alpha=0.7)
            ax.set_title('Average Computation Time', fontweight='bold')
            ax.set_ylabel('Time (seconds)')
            ax.tick_params(axis='x', rotation=45)
            
            for bar, time in zip(bars, comp_times):
                if time > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                           f'{time:.3f}s', ha='center', va='bottom', fontsize=9)
            
            # 3. Trajectory Quality Comparison
            ax = axes[0, 2]
            qualities = []
            for alg in algorithms:
                quality = algorithm_results[alg].get('avg_quality', 0)
                qualities.append(quality)
            
            bars = ax.bar(algorithms, qualities, color=colors, alpha=0.7)
            ax.set_title('Average Trajectory Quality', fontweight='bold')
            ax.set_ylabel('Quality Score')
            ax.tick_params(axis='x', rotation=45)
            ax.set_ylim(0, 1)
            
            for bar, quality in zip(bars, qualities):
                if quality > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                           f'{quality:.3f}', ha='center', va='bottom')
            
            # 4. Trajectory Length Comparison
            ax = axes[1, 0]
            lengths = []
            for alg in algorithms:
                length = algorithm_results[alg].get('avg_length', 0)
                lengths.append(length)
            
            bars = ax.bar(algorithms, lengths, color=colors, alpha=0.7)
            ax.set_title('Average Trajectory Length', fontweight='bold')
            ax.set_ylabel('Length (frames)')
            ax.tick_params(axis='x', rotation=45)
            
            for bar, length in zip(bars, lengths):
                if length > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                           f'{length:.1f}', ha='center', va='bottom')
            
            # 5. Performance Efficiency (Trajectories per Second)
            ax = axes[1, 1]
            efficiencies = []
            for alg in algorithms:
                traj_count = algorithm_results[alg].get('avg_trajectories', 0)
                time = algorithm_results[alg].get('avg_time', 1e-6)  # Avoid division by zero
                efficiency = traj_count / time if time > 0 else 0
                efficiencies.append(efficiency)
            
            bars = ax.bar(algorithms, efficiencies, color=colors, alpha=0.7)
            ax.set_title('Processing Efficiency', fontweight='bold')
            ax.set_ylabel('Trajectories per Second')
            ax.tick_params(axis='x', rotation=45)
            
            for bar, eff in zip(bars, efficiencies):
                if eff > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                           f'{eff:.1f}', ha='center', va='bottom')
            
            # 6. Overall Performance Score
            ax = axes[1, 2]
            performance_scores = []
            for alg in algorithms:
                # Calculate composite performance score
                traj_score = min(1.0, algorithm_results[alg].get('avg_trajectories', 0) / 5.0)
                quality_score = algorithm_results[alg].get('avg_quality', 0)
                time_penalty = max(0, 1.0 - algorithm_results[alg].get('avg_time', 0) / 0.5)
                
                overall_score = (traj_score * 0.4 + quality_score * 0.4 + time_penalty * 0.2)
                performance_scores.append(overall_score)
            
            bars = ax.bar(algorithms, performance_scores, color=colors, alpha=0.7)
            ax.set_title('Overall Performance Score', fontweight='bold')
            ax.set_ylabel('Composite Score')
            ax.tick_params(axis='x', rotation=45)
            ax.set_ylim(0, 1)
            
            for bar, score in zip(bars, performance_scores):
                if score > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                           f'{score:.3f}', ha='center', va='bottom')
            
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"Algorithm comparison plot saved to {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to create algorithm comparison plot: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def create_performance_radar_chart(self, algorithm_results: Dict, save_path: str):
        """Create radar chart for algorithm performance comparison"""
        try:
            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
            
            # Performance metrics
            metrics = ['Trajectory Count', 'Quality Score', 'Speed', 'Efficiency', 'Stability']
            algorithms = list(algorithm_results.keys())
            colors = plt.cm.Set1(np.linspace(0, 1, len(algorithms)))
            
            # Normalize metrics to 0-1 scale
            max_values = {}
            for metric in metrics:
                if metric == 'Trajectory Count':
                    max_values[metric] = max([alg.get('avg_trajectories', 0) for alg in algorithm_results.values()])
                elif metric == 'Quality Score':
                    max_values[metric] = 1.0
                elif metric == 'Speed':
                    min_time = min([alg.get('avg_time', 1) for alg in algorithm_results.values() if alg.get('avg_time', 1) > 0])
                    max_values[metric] = min_time  # Lower time is better
                elif metric == 'Efficiency':
                    max_values[metric] = max([alg.get('avg_trajectories', 0) / max(alg.get('avg_time', 1), 1e-6) 
                                            for alg in algorithm_results.values()])
                elif metric == 'Stability':
                    max_values[metric] = 1.0
            
            # Plot each algorithm
            angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
            angles += angles[:1]  # Complete the circle
            
            for i, (alg_name, alg_data) in enumerate(algorithm_results.items()):
                values = []
                
                # Calculate normalized values
                traj_count = alg_data.get('avg_trajectories', 0)
                values.append(traj_count / max(max_values['Trajectory Count'], 1))
                
                quality = alg_data.get('avg_quality', 0)
                values.append(quality)
                
                time = alg_data.get('avg_time', 1)
                speed_score = max_values['Speed'] / max(time, 1e-6) if time > 0 else 0
                values.append(min(1.0, speed_score))
                
                efficiency = traj_count / max(time, 1e-6)
                values.append(efficiency / max(max_values['Efficiency'], 1))
                
                stability = 1.0 - min(1.0, alg_data.get('computation_time_std', 0) / max(time, 1e-6))
                values.append(max(0, stability))
                
                values += values[:1]  # Complete the circle
                
                ax.plot(angles, values, 'o-', linewidth=2, label=alg_name, 
                       color=colors[i % len(colors)])
                ax.fill(angles, values, alpha=0.15, color=colors[i % len(colors)])
            
            # Customize the chart
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(metrics)
            ax.set_ylim(0, 1)
            ax.set_title('Algorithm Performance Radar Chart', size=16, fontweight='bold', pad=20)
            ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
            ax.grid(True)
            
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"Performance radar chart saved to {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to create radar chart: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def create_detailed_comparison_table(self, algorithm_results: Dict, save_path: str):
        """Create detailed comparison table visualization"""
        try:
            # Prepare data for table
            data = []
            headers = ['Algorithm', 'Avg Trajectories', 'Avg Quality', 'Avg Time (s)', 
                      'Efficiency', 'Best For']
            
            best_for = {
                'greedy': 'Real-time processing',
                'hungarian': 'High precision tasks',
                'kalman': 'Predictable motion',
                'overlap': 'Shape-stable objects',
                'hybrid': 'Complex scenarios'
            }
            
            for alg_name, alg_data in algorithm_results.items():
                row = [
                    alg_name.capitalize(),
                    f"{alg_data.get('avg_trajectories', 0):.2f}",
                    f"{alg_data.get('avg_quality', 0):.3f}",
                    f"{alg_data.get('avg_time', 0):.4f}",
                    f"{alg_data.get('avg_trajectories', 0) / max(alg_data.get('avg_time', 1), 1e-6):.1f}",
                    best_for.get(alg_name, 'General purpose')
                ]
                data.append(row)
            
            # Create table plot
            fig, ax = plt.subplots(figsize=(14, 8))
            ax.axis('tight')
            ax.axis('off')
            
            table = ax.table(cellText=data, colLabels=headers, cellLoc='center', loc='center')
            table.auto_set_font_size(False)
            table.set_fontsize(10)
            table.scale(1.2, 1.5)
            
            # Style the table
            for i in range(len(headers)):
                table[(0, i)].set_facecolor('#40466e')
                table[(0, i)].set_text_props(weight='bold', color='white')
            
            # Color rows alternately
            for i in range(1, len(data) + 1):
                for j in range(len(headers)):
                    if i % 2 == 0:
                        table[(i, j)].set_facecolor('#f1f1f2')
                    else:
                        table[(i, j)].set_facecolor('white')
            
            plt.title('Algorithm Performance Comparison Table', fontsize=16, fontweight='bold', pad=20)
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"Comparison table saved to {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to create comparison table: {e}")
            if 'fig' in locals():
                plt.close(fig)
    
    def create_trajectory_animation(self, topographies: np.ndarray, 
                                  tracking_results: Dict,
                                  save_path: str, fps: int = None) -> None:
        """Create trajectory animation (simplified version)"""
        if fps is None:
            fps = self.config.FPS
        
        try:
            # Save frame sequence instead of animation for better compatibility
            frame_dir = f"{os.path.splitext(save_path)[0]}_frames"
            os.makedirs(frame_dir, exist_ok=True)
            
            n_frames = min(len(topographies), self.config.MAX_SAVE_FRAMES)
            
            for frame in range(n_frames):
                try:
                    fig, ax = plt.subplots(figsize=(10, 8))
                    
                    # Display topography
                    ax.imshow(topographies[frame], cmap=self.config.COLORMAP, 
                             interpolation='bilinear', origin='upper')
                    
                    # Draw trajectories up to current frame
                    if frame < len(tracking_results.get('frame_results', [])):
                        frame_result = tracking_results['frame_results'][frame]
                        
                        for i, region in enumerate(frame_result.get('tracked_regions', [])):
                            trajectory = np.array(region.trajectory)
                            color = self.colors[i % len(self.colors)]
                            
                            if len(trajectory) > 1:
                                ax.plot(trajectory[:, 1], trajectory[:, 0], 
                                       color=color, linewidth=2, alpha=0.8)
                            
                            if len(trajectory) > 0:
                                current_pos = trajectory[-1]
                                ax.scatter(current_pos[1], current_pos[0], 
                                          s=100, c=color, marker='o', 
                                          edgecolors='white', linewidth=2)
                    
                    # Add head outline
                    center = (topographies.shape[2]//2, topographies.shape[1]//2)
                    radius = min(topographies.shape[1:])//2 - 5
                    self.add_head_outline(ax, center, radius)
                    
                    ax.set_title(f'Frame {frame+1}/{n_frames}', fontweight='bold')
                    ax.axis('off')
                    
                    frame_path = os.path.join(frame_dir, f"frame_{frame:04d}.png")
                    plt.savefig(frame_path, dpi=150, bbox_inches='tight')
                    plt.close()
                    
                except Exception as e:
                    self.logger.warning(f"Failed to save frame {frame}: {e}")
                    if 'fig' in locals():
                        plt.close(fig)
                    continue
            
            self.logger.info(f"Animation frames saved to {frame_dir}")
            
        except Exception as e:
            self.logger.error(f"Failed to create animation: {e}")
    
    def create_summary_visualization(self, all_results: Dict, save_path: str):
        """Create comprehensive summary visualization"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('EEG Trajectory Analysis Summary', fontsize=16, fontweight='bold')
            
            # Extract summary statistics
            subject_counts = {}
            algorithm_performance = {}
            
            for subject_id, sessions in all_results.items():
                for session_id, session_data in sessions.items():
                    for algorithm_name, alg_data in session_data.items():
                        if algorithm_name not in algorithm_performance:
                            algorithm_performance[algorithm_name] = {
                                'trajectory_counts': [],
                                'computation_times': [],
                                'qualities': []
                            }
                        
                        algorithm_performance[algorithm_name]['trajectory_counts'].append(
                            alg_data.get('total_trajectories', 0))
                        algorithm_performance[algorithm_name]['computation_times'].append(
                            alg_data.get('total_computation_time', 0))
                        
                        # Calculate average quality
                        qualities = []
                        for traj_data in alg_data.get('trajectories', {}).values():
                            qualities.append(traj_data.get('quality_score', 0))
                        
                        if qualities:
                            algorithm_performance[algorithm_name]['qualities'].append(np.mean(qualities))
            
            # 1. Algorithm Performance Summary
            ax = axes[0, 0]
            algorithms = list(algorithm_performance.keys())
            avg_trajectories = [np.mean(algorithm_performance[alg]['trajectory_counts']) 
                              for alg in algorithms]
            
            bars = ax.bar(algorithms, avg_trajectories, alpha=0.7)
            ax.set_title('Average Trajectories per Algorithm')
            ax.set_ylabel('Number of Trajectories')
            ax.tick_params(axis='x', rotation=45)
            
            # 2. Processing Time Comparison
            ax = axes[0, 1]
            avg_times = [np.mean(algorithm_performance[alg]['computation_times']) 
                        for alg in algorithms]
            
            bars = ax.bar(algorithms, avg_times, alpha=0.7, color='orange')
            ax.set_title('Average Processing Time')
            ax.set_ylabel('Time (seconds)')
            ax.tick_params(axis='x', rotation=45)
            
            # 3. Quality Distribution
            ax = axes[1, 0]
            all_qualities = []
            labels = []
            
            for alg in algorithms:
                qualities = algorithm_performance[alg]['qualities']
                if qualities:
                    all_qualities.extend(qualities)
                    labels.extend([alg] * len(qualities))
            
            if all_qualities:
                unique_algorithms = list(set(labels))
                quality_data = [algorithm_performance[alg]['qualities'] for alg in unique_algorithms]
                
                ax.boxplot(quality_data, labels=unique_algorithms)
                ax.set_title('Quality Score Distribution')
                ax.set_ylabel('Quality Score')
                ax.tick_params(axis='x', rotation=45)
            
            # 4. Summary Statistics
            ax = axes[1, 1]
            ax.axis('off')
            
            # Create summary text
            total_subjects = len(all_results)
            total_sessions = sum(len(sessions) for sessions in all_results.values())
            total_algorithms = len(algorithms)
            
            summary_text = f"""
Experiment Summary:
• Total Subjects: {total_subjects}
• Total Sessions: {total_sessions}  
• Algorithms Compared: {total_algorithms}
• Algorithms: {', '.join(algorithms)}

Best Performing Algorithm:
• Most Trajectories: {algorithms[np.argmax(avg_trajectories)]}
• Fastest Processing: {algorithms[np.argmin(avg_times)]}
"""
            
            ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, 
                   fontsize=12, verticalalignment='top',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgray', alpha=0.8))
            
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"Summary visualization saved to {save_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to create summary visualization: {e}")
            if 'fig' in locals():
                plt.close(fig)

# ========== trackers/__init__.py ==========
# 相对路径: trackers/__init__.py
# 在项目中的相对位置: ./trackers/__init__.py

# 跟踪算法模块
"""
EEG轨迹跟踪算法集合
包含多种不同的轨迹跟踪算法实现
"""

from .base_tracker import BaseTracker
from .greedy_tracker import GreedyTracker
from .hungarian_tracker import HungarianTracker
from .kalman_tracker import KalmanTracker
from .overlap_tracker import OverlapTracker
from .hybrid_tracker import HybridTracker
from .tracker_factory import TrackerFactory

__all__ = [
    'BaseTracker',
    'GreedyTracker', 
    'HungarianTracker',
    'KalmanTracker',
    'OverlapTracker',
    'HybridTracker',
    'TrackerFactory'
]

__version__ = "2.0.0"

# ========== trackers/base_tracker.py ==========
# 相对路径: trackers/base_tracker.py
# 在项目中的相对位置: ./trackers/base_tracker.py

import numpy as np
import cv2
from scipy.ndimage import label, center_of_mass
import logging
import time
from typing import List, Tuple, Dict, Optional
from abc import ABC, abstractmethod

class Region:
    """轨迹区域类"""
    def __init__(self, center: Tuple[float, float], area: float, intensity: float, id: int):
        self.center = center
        self.area = area
        self.intensity = intensity
        self.id = id
        self.trajectory = [center]
        self.active = True
        self.inactive_frames = 0
        self.max_inactive_frames = 25
        self.velocity_history = []
        self.predicted_position = None
        self.last_mask = None
        self.quality_score = 0.0

class BaseTracker(ABC):
    """基础跟踪器抽象类"""
    
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        self.regions = []
        self.next_region_id = 0
        
        # 算法名称（由子类设置）
        self.algorithm_name = "base"
        
        # 性能统计
        self.performance_stats = {
            'total_frames': 0,
            'total_detections': 0,
            'total_matches': 0,
            'computation_times': [],
            'memory_usage': []
        }
    
    def detect_high_activation_regions(self, topography: np.ndarray, frame_idx: int = 0) -> List[Dict]:
        """检测高激活区域 - 通用实现"""
        try:
            # 只考虑非零区域（头部内部）
            valid_mask = topography != 0
            if not np.any(valid_mask):
                return []
            
            valid_values = topography[valid_mask]
            
            # 自适应阈值计算
            threshold = np.percentile(valid_values, self.config.THRESHOLD_PERCENTILE)
            
            # 二值化
            binary = (topography > threshold) & valid_mask
            
            if not np.any(binary):
                # 降低阈值重试
                threshold = np.percentile(valid_values, max(70, self.config.THRESHOLD_PERCENTILE - 15))
                binary = (topography > threshold) & valid_mask
                
                if not np.any(binary):
                    return []
            
            # 形态学操作清理噪声
            try:
                kernel = np.ones((3, 3), np.uint8)
                binary = cv2.morphologyEx(binary.astype(np.uint8), cv2.MORPH_OPEN, kernel)
                binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            except:
                pass
            
            # 连通域分析
            labeled_array, num_features = label(binary)
            
            regions = []
            for i in range(1, num_features + 1):
                region_mask = labeled_array == i
                area = np.sum(region_mask)
                
                if area < self.config.MIN_REGION_SIZE:
                    continue
                
                # 计算质心
                center = center_of_mass(region_mask)
                
                # 计算强度统计
                region_values = topography[region_mask]
                intensity = np.mean(region_values)
                max_intensity = np.max(region_values)
                
                regions.append({
                    'center': center,
                    'area': area,
                    'intensity': intensity,
                    'max_intensity': max_intensity,
                    'mask': region_mask,
                    'threshold_used': threshold
                })
            
            # 按强度和面积的组合排序
            regions.sort(key=lambda x: x['intensity'] * np.sqrt(x['area']), reverse=True)
            selected_regions = regions[:self.config.MAX_REGIONS]
            
            return selected_regions
            
        except Exception as e:
            self.logger.error(f"区域检测失败: {e}")
            return []
    
    @abstractmethod
    def match_regions(self, current_regions: List[Dict], 
                     distance_threshold: float = 20.0, frame_idx: int = 0) -> List[Tuple[int, int]]:
        """匹配区域 - 由子类实现具体算法"""
        pass
    
    def update_tracker(self, topography: np.ndarray, frame_idx: int = 0) -> Dict:
        """更新跟踪器 - 通用框架"""
        start_time = time.time()
        
        try:
            # 检测当前帧的区域
            current_regions = self.detect_high_activation_regions(topography, frame_idx)
            
            # 使用具体算法进行匹配
            matches = self.match_regions(current_regions, frame_idx=frame_idx)
            
            # 更新匹配的区域
            active_regions = [r for r in self.regions if r.active]
            matched_tracked = set()
            matched_current = set()
            
            for tracked_idx, current_idx in matches:
                if tracked_idx < len(active_regions) and current_idx < len(current_regions):
                    region = active_regions[tracked_idx]
                    current_region = current_regions[current_idx]
                    
                    # 更新轨迹
                    region.trajectory.append(current_region['center'])
                    region.area = current_region['area']
                    region.intensity = current_region['intensity']
                    region.inactive_frames = 0
                    region.last_mask = current_region.get('mask')
                    
                    matched_tracked.add(tracked_idx)
                    matched_current.add(current_idx)
            
            # 处理未匹配的跟踪区域
            for i, region in enumerate(active_regions):
                if i not in matched_tracked:
                    region.inactive_frames += 1
                    
                    if region.inactive_frames >= region.max_inactive_frames:
                        region.active = False
            
            # 为未匹配的当前区域创建新的跟踪区域
            for i, current_region in enumerate(current_regions):
                if i not in matched_current:
                    new_region = Region(
                        center=current_region['center'],
                        area=current_region['area'],
                        intensity=current_region['intensity'],
                        id=self.next_region_id
                    )
                    new_region.last_mask = current_region.get('mask')
                    self.regions.append(new_region)
                    self.next_region_id += 1
            
            # 更新性能统计
            computation_time = time.time() - start_time
            self.performance_stats['computation_times'].append(computation_time)
            self.performance_stats['total_frames'] += 1
            self.performance_stats['total_detections'] += len(current_regions)
            self.performance_stats['total_matches'] += len(matches)
            
            return {
                'current_regions': current_regions,
                'tracked_regions': [r for r in self.regions if r.active],
                'all_regions': self.regions,
                'frame_idx': frame_idx,
                'matches': matches,
                'algorithm': self.algorithm_name
            }
            
        except Exception as e:
            self.logger.error(f"跟踪更新失败: {e}")
            return {
                'current_regions': [],
                'tracked_regions': [],
                'all_regions': self.regions,
                'frame_idx': frame_idx,
                'error': str(e),
                'algorithm': self.algorithm_name
            }
    
    def track_sequence(self, topographies: np.ndarray) -> Dict:
        """跟踪整个序列"""
        n_frames = topographies.shape[0]
        tracking_results = []
        
        # 重置跟踪器
        self.reset_tracker()
        
        self.logger.info(f"开始使用{self.algorithm_name}算法跟踪{n_frames}帧")
        
        start_time = time.time()
        
        try:
            for frame_idx in range(n_frames):
                topography = topographies[frame_idx]
                result = self.update_tracker(topography, frame_idx)
                result['frame'] = frame_idx
                tracking_results.append(result)
            
            total_time = time.time() - start_time
            
            # 提取轨迹
            trajectories = self.extract_trajectories()
            
            # 计算性能指标
            metrics = self.calculate_performance_metrics(trajectories, total_time)
            
            self.logger.info(f"{self.algorithm_name}算法完成: {len(trajectories)}条轨迹, "
                           f"耗时{total_time:.2f}秒")
            
            return {
                'algorithm': self.algorithm_name,
                'frame_results': tracking_results,
                'trajectories': trajectories,
                'metrics': metrics,
                'summary': {
                    'total_regions': len(self.regions),
                    'tracked_regions': len(trajectories),
                    'total_frames': n_frames,
                    'total_time': total_time
                }
            }
            
        except Exception as e:
            self.logger.error(f"{self.algorithm_name}算法跟踪失败: {e}")
            return {
                'algorithm': self.algorithm_name,
                'frame_results': tracking_results,
                'trajectories': {},
                'metrics': {},
                'summary': {
                    'total_regions': 0,
                    'tracked_regions': 0,
                    'total_frames': n_frames,
                    'error': str(e)
                }
            }
    
    def reset_tracker(self):
        """重置跟踪器状态"""
        self.regions = []
        self.next_region_id = 0
        self.performance_stats = {
            'total_frames': 0,
            'total_detections': 0,
            'total_matches': 0,
            'computation_times': [],
            'memory_usage': []
        }
    
    def extract_trajectories(self) -> Dict:
        """提取有效轨迹"""
        trajectories = {}
        
        for region in self.regions:
            if len(region.trajectory) > 2:  # 至少跟踪了3帧
                try:
                    trajectory_array = np.array(region.trajectory)
                    
                    # 计算基本统计
                    distances = np.linalg.norm(np.diff(trajectory_array, axis=0), axis=1)
                    total_distance = np.sum(distances)
                    avg_velocity = np.mean(distances) if len(distances) > 0 else 0
                    
                    # 计算轨迹质量分数
                    quality_score = self.compute_trajectory_quality(region)
                    
                    trajectories[region.id] = {
                        'trajectory': trajectory_array,
                        'length': len(region.trajectory),
                        'mean_intensity': float(getattr(region, 'intensity', 0.0)),
                        'area': float(getattr(region, 'area', 0.0)),
                        'total_distance': float(total_distance),
                        'avg_velocity': float(avg_velocity),
                        'inactive_frames': getattr(region, 'inactive_frames', 0),
                        'quality_score': float(quality_score)
                    }
                except Exception as e:
                    self.logger.warning(f"提取轨迹{region.id}失败: {e}")
                    continue
        
        return trajectories
    
    def compute_trajectory_quality(self, region: Region) -> float:
        """计算轨迹质量分数"""
        try:
            trajectory = np.array(region.trajectory)
            
            if len(trajectory) < 2:
                return 0.0
            
            # 长度分数
            length_score = min(1.0, len(trajectory) / 50.0)
            
            # 连续性分数
            continuity_score = max(0.0, 1.0 - region.inactive_frames / region.max_inactive_frames)
            
            # 运动平滑性分数
            if len(trajectory) >= 3:
                velocities = np.linalg.norm(np.diff(trajectory, axis=0), axis=1)
                if len(velocities) > 1:
                    velocity_var = np.var(velocities)
                    smoothness_score = max(0.0, 1.0 - velocity_var / 50.0)
                else:
                    smoothness_score = 0.8
            else:
                smoothness_score = 0.5
            
            # 强度一致性分数
            intensity_score = min(1.0, getattr(region, 'intensity', 0) / 0.5)
            
            # 综合质量分数
            quality_score = (length_score * 0.3 + 
                           continuity_score * 0.3 + 
                           smoothness_score * 0.25 + 
                           intensity_score * 0.15)
            
            return quality_score
            
        except Exception as e:
            self.logger.warning(f"质量计算失败: {e}")
            return 0.0
    
    def calculate_performance_metrics(self, trajectories: Dict, total_time: float) -> Dict:
        """计算性能指标"""
        metrics = {}
        
        try:
            # 基本指标
            metrics['trajectory_count'] = len(trajectories)
            metrics['computation_time'] = total_time
            
            if trajectories:
                lengths = [traj['length'] for traj in trajectories.values()]
                qualities = [traj['quality_score'] for traj in trajectories.values()]
                
                metrics['average_trajectory_length'] = np.mean(lengths)
                metrics['max_trajectory_length'] = np.max(lengths)
                metrics['trajectory_quality'] = np.mean(qualities)
                
                # 连续性指标
                metrics['tracking_continuity'] = self._calculate_continuity(trajectories)
                metrics['trajectory_smoothness'] = self._calculate_smoothness(trajectories)
            else:
                metrics['average_trajectory_length'] = 0
                metrics['max_trajectory_length'] = 0
                metrics['trajectory_quality'] = 0
                metrics['tracking_continuity'] = 0
                metrics['trajectory_smoothness'] = 0
            
            # 检测稳定性
            if self.performance_stats['computation_times']:
                avg_time = np.mean(self.performance_stats['computation_times'])
                time_std = np.std(self.performance_stats['computation_times'])
                metrics['detection_stability'] = 1.0 / (1.0 + time_std / avg_time) if avg_time > 0 else 0
            else:
                metrics['detection_stability'] = 0
            
            # 内存使用（简化版）
            try:
                import psutil
                metrics['memory_usage'] = psutil.Process().memory_info().rss / 1024 / 1024
            except ImportError:
                metrics['memory_usage'] = 0
            
        except Exception as e:
            self.logger.error(f"性能指标计算失败: {e}")
            for metric in self.config.EVALUATION_METRICS:
                metrics[metric] = 0.0
        
        return metrics
    
    def _calculate_continuity(self, trajectories: Dict) -> float:
        """计算跟踪连续性"""
        if not trajectories:
            return 0.0
        
        continuity_scores = []
        for traj_data in trajectories.values():
            trajectory = traj_data['trajectory']
            if len(trajectory) > 2:
                velocities = np.linalg.norm(np.diff(trajectory, axis=0), axis=1)
                if len(velocities) > 1:
                    velocity_stability = 1.0 / (1.0 + np.std(velocities))
                    continuity_scores.append(velocity_stability)
        
        return np.mean(continuity_scores) if continuity_scores else 0.0
    
    def _calculate_smoothness(self, trajectories: Dict) -> float:
        """计算轨迹平滑度"""
        if not trajectories:
            return 0.0
        
        smoothness_scores = []
        for traj_data in trajectories.values():
            trajectory = traj_data['trajectory']
            if len(trajectory) > 3:
                velocities = np.diff(trajectory, axis=0)
                accelerations = np.diff(velocities, axis=0)
                if len(accelerations) > 0:
                    acceleration_magnitude = np.linalg.norm(accelerations, axis=1)
                    if len(acceleration_magnitude) > 1:
                        smoothness = 1.0 / (1.0 + np.std(acceleration_magnitude))
                        smoothness_scores.append(smoothness)
        
        return np.mean(smoothness_scores) if smoothness_scores else 0.0
    
    def get_algorithm_info(self) -> Dict:
        """获取算法信息"""
        return {
            'name': self.algorithm_name,
            'description': getattr(self, 'description', '基础跟踪算法'),
            'parameters': getattr(self, 'algorithm_params', {}),
            'performance_stats': self.performance_stats
        }

# ========== trackers/greedy_tracker.py ==========
# 相对路径: trackers/greedy_tracker.py
# 在项目中的相对位置: ./trackers/greedy_tracker.py

import numpy as np
from scipy.spatial.distance import cdist
from typing import List, Tuple, Dict
from .base_tracker import BaseTracker

class GreedyTracker(BaseTracker):
    """贪婪匹配跟踪算法"""
    
    def __init__(self, config):
        super().__init__(config)
        self.algorithm_name = "greedy"
        self.description = "贪婪匹配算法 - 快速局部最优解"
        
        # 获取算法特定配置
        alg_config = config.get_algorithm_config('greedy')
        self.distance_threshold = alg_config.get('distance_threshold', 25.0)
        self.enable_reconnection = alg_config.get('enable_reconnection', True)
        self.max_inactive_frames = alg_config.get('max_inactive_frames', 25)
        
        self.algorithm_params = {
            'distance_threshold': self.distance_threshold,
            'enable_reconnection': self.enable_reconnection,
            'max_inactive_frames': self.max_inactive_frames
        }
    
    def match_regions(self, current_regions: List[Dict], 
                     distance_threshold: float = None, frame_idx: int = 0) -> List[Tuple[int, int]]:
        """贪婪匹配算法实现"""
        if not current_regions:
            return []
        
        # 获取活跃区域
        active_regions = [r for r in self.regions if r.active]
        if not active_regions:
            return []
        
        # 使用配置的距离阈值
        if distance_threshold is None:
            distance_threshold = self.distance_threshold
        
        try:
            # 获取当前区域中心点和已跟踪区域的最新位置
            current_centers = np.array([r['center'] for r in current_regions])
            tracked_centers = np.array([r.trajectory[-1] for r in active_regions])
            
            # 计算距离矩阵
            distances = cdist(tracked_centers, current_centers)
            
            # 贪婪匹配：按距离从小到大进行匹配
            matches = []
            used_current = set()
            used_tracked = set()
            
            # 获取所有距离的排序索引
            dist_indices = np.unravel_index(np.argsort(distances.ravel()), distances.shape)
            
            for tracked_idx, current_idx in zip(dist_indices[0], dist_indices[1]):
                # 跳过已使用的区域
                if tracked_idx in used_tracked or current_idx in used_current:
                    continue
                
                # 检查距离是否在阈值内
                if distances[tracked_idx, current_idx] < distance_threshold:
                    matches.append((tracked_idx, current_idx))
                    used_tracked.add(tracked_idx)
                    used_current.add(current_idx)
                else:
                    # 由于按距离排序，后续距离只会更大，可以提前结束
                    break
            
            # 如果启用重连，尝试为未匹配的区域进行重连
            if self.enable_reconnection and len(matches) < len(active_regions):
                reconnection_matches = self._attempt_reconnection(
                    current_regions, active_regions, used_current, used_tracked, frame_idx
                )
                matches.extend(reconnection_matches)
            
            self.logger.debug(f"贪婪算法第{frame_idx}帧: 匹配{len(matches)}对区域")
            
            return matches
            
        except Exception as e:
            self.logger.error(f"贪婪匹配算法失败: {e}")
            return []
    
    def _attempt_reconnection(self, current_regions: List[Dict], 
                            active_regions: List, 
                            used_current: set, used_tracked: set, 
                            frame_idx: int) -> List[Tuple[int, int]]:
        """尝试重新连接断开的轨迹"""
        reconnection_matches = []
        
        try:
            # 扩大搜索距离进行重连
            reconnection_threshold = self.distance_threshold * 1.5
            
            # 获取未匹配的区域
            unmatched_tracked = [i for i in range(len(active_regions)) if i not in used_tracked]
            unmatched_current = [i for i in range(len(current_regions)) if i not in used_current]
            
            if not unmatched_tracked or not unmatched_current:
                return reconnection_matches
            
            # 计算未匹配区域间的距离
            unmatched_tracked_centers = np.array([active_regions[i].trajectory[-1] for i in unmatched_tracked])
            unmatched_current_centers = np.array([current_regions[i]['center'] for i in unmatched_current])
            
            distances = cdist(unmatched_tracked_centers, unmatched_current_centers)
            
            # 贪婪重连匹配
            reconnection_used_current = set()
            reconnection_used_tracked = set()
            
            dist_indices = np.unravel_index(np.argsort(distances.ravel()), distances.shape)
            
            for rel_tracked_idx, rel_current_idx in zip(dist_indices[0], dist_indices[1]):
                if rel_tracked_idx in reconnection_used_tracked or rel_current_idx in reconnection_used_current:
                    continue
                
                if distances[rel_tracked_idx, rel_current_idx] < reconnection_threshold:
                    # 转换回原始索引
                    original_tracked_idx = unmatched_tracked[rel_tracked_idx]
                    original_current_idx = unmatched_current[rel_current_idx]
                    
                    # 检查非活跃帧数，如果太多则不重连
                    region = active_regions[original_tracked_idx]
                    if region.inactive_frames < self.max_inactive_frames:
                        reconnection_matches.append((original_tracked_idx, original_current_idx))
                        reconnection_used_tracked.add(rel_tracked_idx)
                        reconnection_used_current.add(rel_current_idx)
                        
                        self.logger.debug(f"重连轨迹{region.id}: 距离{distances[rel_tracked_idx, rel_current_idx]:.2f}")
            
        except Exception as e:
            self.logger.warning(f"重连尝试失败: {e}")
        
        return reconnection_matches
    
    def compute_match_quality(self, tracked_region, current_region, distance: float) -> float:
        """计算匹配质量分数"""
        try:
            # 距离分数（距离越小分数越高）
            distance_score = max(0, 1.0 - distance / self.distance_threshold)
            
            # 强度相似性分数
            intensity_diff = abs(tracked_region.intensity - current_region.get('intensity', 0))
            max_intensity = max(tracked_region.intensity, current_region.get('intensity', 0), 0.1)
            intensity_score = 1.0 - min(1.0, intensity_diff / max_intensity)
            
            # 面积相似性分数
            area_diff = abs(tracked_region.area - current_region.get('area', 0))
            max_area = max(tracked_region.area, current_region.get('area', 0), 1.0)
            area_score = 1.0 - min(1.0, area_diff / max_area)
            
            # 综合分数
            quality_score = (distance_score * 0.6 + 
                           intensity_score * 0.25 + 
                           area_score * 0.15)
            
            return quality_score
            
        except Exception as e:
            self.logger.warning(f"匹配质量计算失败: {e}")
            return distance_score if 'distance_score' in locals() else 0.0
    
    def get_algorithm_info(self) -> Dict:
        """获取算法信息"""
        info = super().get_algorithm_info()
        info.update({
            'description': self.description,
            'characteristics': [
                "快速计算",
                "局部最优解",
                "贪婪策略",
                "支持轨迹重连"
            ],
            'advantages': [
                "计算效率高",
                "实现简单",
                "内存消耗低",
                "适合实时处理"
            ],
            'disadvantages': [
                "可能陷入局部最优",
                "对噪声敏感",
                "匹配质量不如全局算法"
            ],
            'best_for': [
                "实时处理场景",
                "计算资源有限场景",
                "轨迹数量较少场景"
            ]
        })
        return info

# ========== trackers/hungarian_tracker.py ==========
# 相对路径: trackers/hungarian_tracker.py
# 在项目中的相对位置: ./trackers/hungarian_tracker.py

import numpy as np
from scipy.spatial.distance import cdist
from scipy.optimize import linear_sum_assignment
from typing import List, Tuple, Dict
from .base_tracker import BaseTracker

class HungarianTracker(BaseTracker):
    """匈牙利算法跟踪器 - 全局最优匹配"""
    
    def __init__(self, config):
        super().__init__(config)
        self.algorithm_name = "hungarian"
        self.description = "匈牙利算法 - 全局最优匹配解"
        
        # 获取算法特定配置
        alg_config = config.get_algorithm_config('hungarian')
        self.distance_threshold = alg_config.get('distance_threshold', 25.0)
        self.enable_reconnection = alg_config.get('enable_reconnection', True)
        self.max_inactive_frames = alg_config.get('max_inactive_frames', 25)
        
        # 匈牙利算法特定参数
        self.cost_threshold = self.distance_threshold * 2  # 成本阈值
        self.use_weighted_cost = True  # 是否使用加权成本
        
        self.algorithm_params = {
            'distance_threshold': self.distance_threshold,
            'cost_threshold': self.cost_threshold,
            'enable_reconnection': self.enable_reconnection,
            'max_inactive_frames': self.max_inactive_frames,
            'use_weighted_cost': self.use_weighted_cost
        }
    
    def match_regions(self, current_regions: List[Dict], 
                     distance_threshold: float = None, frame_idx: int = 0) -> List[Tuple[int, int]]:
        """匈牙利算法匹配实现"""
        if not current_regions:
            return []
        
        # 获取活跃区域
        active_regions = [r for r in self.regions if r.active]
        if not active_regions:
            return []
        
        # 使用配置的距离阈值
        if distance_threshold is None:
            distance_threshold = self.distance_threshold
        
        try:
            # 构建成本矩阵
            cost_matrix = self._build_cost_matrix(current_regions, active_regions)
            
            if cost_matrix.size == 0:
                return []
            
            # 使用匈牙利算法求解最优分配
            try:
                row_indices, col_indices = linear_sum_assignment(cost_matrix)
            except Exception as e:
                self.logger.warning(f"匈牙利算法求解失败: {e}, 使用备用贪婪算法")
                return self._fallback_greedy_matching(current_regions, active_regions, distance_threshold)
            
            # 筛选有效匹配
            matches = []
            for row_idx, col_idx in zip(row_indices, col_indices):
                cost = cost_matrix[row_idx, col_idx]
                
                # 只接受成本低于阈值的匹配
                if cost < self.cost_threshold:
                    matches.append((row_idx, col_idx))
                    self.logger.debug(f"匹配轨迹{active_regions[row_idx].id}与区域{col_idx}, 成本: {cost:.2f}")
            
            # 如果启用重连，尝试重连未匹配的区域
            if self.enable_reconnection and len(matches) < len(active_regions):
                reconnection_matches = self._attempt_hungarian_reconnection(
                    current_regions, active_regions, matches, frame_idx
                )
                matches.extend(reconnection_matches)
            
            self.logger.debug(f"匈牙利算法第{frame_idx}帧: 匹配{len(matches)}对区域")
            
            return matches
            
        except Exception as e:
            self.logger.error(f"匈牙利算法匹配失败: {e}")
            return self._fallback_greedy_matching(current_regions, active_regions, distance_threshold)
    
    def _build_cost_matrix(self, current_regions: List[Dict], active_regions: List) -> np.ndarray:
        """构建成本矩阵"""
        try:
            n_tracked = len(active_regions)
            n_current = len(current_regions)
            
            # 初始化成本矩阵
            cost_matrix = np.full((n_tracked, n_current), np.inf)
            
            # 计算各种成本组件
            for i, tracked_region in enumerate(active_regions):
                tracked_center = np.array(tracked_region.trajectory[-1])
                
                for j, current_region in enumerate(current_regions):
                    current_center = np.array(current_region['center'])
                    
                    # 计算综合成本
                    cost = self._calculate_assignment_cost(tracked_region, current_region, 
                                                         tracked_center, current_center)
                    cost_matrix[i, j] = cost
            
            return cost_matrix
            
        except Exception as e:
            self.logger.error(f"成本矩阵构建失败: {e}")
            return np.array([])
    
    def _calculate_assignment_cost(self, tracked_region, current_region, 
                                 tracked_center: np.ndarray, current_center: np.ndarray) -> float:
        """计算分配成本"""
        try:
            # 1. 基础距离成本
            distance = np.linalg.norm(tracked_center - current_center)
            distance_cost = distance
            
            # 如果距离超过阈值，返回极高成本
            if distance > self.distance_threshold:
                return np.inf
            
            if not self.use_weighted_cost:
                return distance_cost
            
            # 2. 强度差异成本
            intensity_diff = abs(tracked_region.intensity - current_region.get('intensity', 0))
            max_intensity = max(tracked_region.intensity, current_region.get('intensity', 0), 0.1)
            intensity_cost = intensity_diff / max_intensity * 10  # 权重为10
            
            # 3. 面积差异成本
            area_diff = abs(tracked_region.area - current_region.get('area', 0))
            max_area = max(tracked_region.area, current_region.get('area', 0), 1.0)
            area_cost = area_diff / max_area * 5  # 权重为5
            
            # 4. 速度一致性成本
            velocity_cost = 0
            if len(tracked_region.trajectory) >= 2:
                prev_velocity = np.array(tracked_region.trajectory[-1]) - np.array(tracked_region.trajectory[-2])
                current_velocity = current_center - tracked_center
                velocity_diff = np.linalg.norm(current_velocity - prev_velocity)
                velocity_cost = velocity_diff * 2  # 权重为2
            
            # 5. 非活跃帧数惩罚
            inactive_penalty = tracked_region.inactive_frames * 3  # 权重为3
            
            # 综合成本
            total_cost = (distance_cost + intensity_cost + area_cost + 
                         velocity_cost + inactive_penalty)
            
            return total_cost
            
        except Exception as e:
            self.logger.warning(f"成本计算失败: {e}")
            return distance if 'distance' in locals() else np.inf
    
    def _attempt_hungarian_reconnection(self, current_regions: List[Dict], 
                                      active_regions: List,
                                      existing_matches: List[Tuple[int, int]], 
                                      frame_idx: int) -> List[Tuple[int, int]]:
        """使用匈牙利算法尝试重连"""
        reconnection_matches = []
        
        try:
            # 获取未匹配的区域索引
            matched_tracked = set([m[0] for m in existing_matches])
            matched_current = set([m[1] for m in existing_matches])
            
            unmatched_tracked = [i for i in range(len(active_regions)) if i not in matched_tracked]
            unmatched_current = [i for i in range(len(current_regions)) if i not in matched_current]
            
            if not unmatched_tracked or not unmatched_current:
                return reconnection_matches
            
            # 构建重连成本矩阵（使用更宽松的阈值）
            reconnection_threshold = self.distance_threshold * 2.0
            cost_matrix = np.full((len(unmatched_tracked), len(unmatched_current)), np.inf)
            
            for i, tracked_idx in enumerate(unmatched_tracked):
                tracked_region = active_regions[tracked_idx]
                
                # 只为非活跃帧数不太多的区域尝试重连
                if tracked_region.inactive_frames >= self.max_inactive_frames:
                    continue
                
                tracked_center = np.array(tracked_region.trajectory[-1])
                
                for j, current_idx in enumerate(unmatched_current):
                    current_region = current_regions[current_idx]
                    current_center = np.array(current_region['center'])
                    
                    distance = np.linalg.norm(tracked_center - current_center)
                    
                    if distance < reconnection_threshold:
                        # 重连时的成本包含非活跃惩罚
                        reconnection_cost = distance + tracked_region.inactive_frames * 5
                        cost_matrix[i, j] = reconnection_cost
            
            # 如果有可重连的组合，使用匈牙利算法
            if np.any(cost_matrix < np.inf):
                try:
                    row_indices, col_indices = linear_sum_assignment(cost_matrix)
                    
                    for row_idx, col_idx in zip(row_indices, col_indices):
                        if cost_matrix[row_idx, col_idx] < np.inf:
                            original_tracked_idx = unmatched_tracked[row_idx]
                            original_current_idx = unmatched_current[col_idx]
                            
                            reconnection_matches.append((original_tracked_idx, original_current_idx))
                            
                            region = active_regions[original_tracked_idx]
                            self.logger.debug(f"重连轨迹{region.id}: 成本{cost_matrix[row_idx, col_idx]:.2f}")
                            
                except Exception as e:
                    self.logger.warning(f"重连匈牙利算法失败: {e}")
            
        except Exception as e:
            self.logger.warning(f"重连尝试失败: {e}")
        
        return reconnection_matches
    
    def _fallback_greedy_matching(self, current_regions: List[Dict], 
                                active_regions: List, 
                                distance_threshold: float) -> List[Tuple[int, int]]:
        """备用贪婪匹配算法"""
        try:
            current_centers = np.array([r['center'] for r in current_regions])
            tracked_centers = np.array([r.trajectory[-1] for r in active_regions])
            
            distances = cdist(tracked_centers, current_centers)
            
            matches = []
            used_current = set()
            used_tracked = set()
            
            dist_indices = np.unravel_index(np.argsort(distances.ravel()), distances.shape)
            
            for tracked_idx, current_idx in zip(dist_indices[0], dist_indices[1]):
                if tracked_idx in used_tracked or current_idx in used_current:
                    continue
                
                if distances[tracked_idx, current_idx] < distance_threshold:
                    matches.append((tracked_idx, current_idx))
                    used_tracked.add(tracked_idx)
                    used_current.add(current_idx)
            
            return matches
            
        except Exception as e:
            self.logger.error(f"备用贪婪算法失败: {e}")
            return []
    
    def get_algorithm_info(self) -> Dict:
        """获取算法信息"""
        info = super().get_algorithm_info()
        info.update({
            'description': self.description,
            'characteristics': [
                "全局最优解",
                "成本矩阵优化",
                "多因素权衡",
                "高精度匹配"
            ],
            'advantages': [
                "全局最优匹配",
                "考虑多种特征",
                "匹配质量高",
                "数学基础扎实"
            ],
            'disadvantages': [
                "计算复杂度较高",
                "内存消耗较大",
                "参数调优复杂"
            ],
            'best_for': [
                "高精度要求场景",
                "轨迹质量优先场景",
                "复杂匹配问题",
                "离线分析场景"
            ]
        })
        return info

# ========== trackers/hybrid_tracker.py ==========
# 相对路径: trackers/hybrid_tracker.py
# 在项目中的相对位置: ./trackers/hybrid_tracker.py

import numpy as np
from scipy.spatial.distance import cdist
from scipy.optimize import linear_sum_assignment
from typing import List, Tuple, Dict
from .base_tracker import BaseTracker

class HybridTracker(BaseTracker):
    """混合跟踪器 - 综合多种算法优势"""
    
    def __init__(self, config):
        super().__init__(config)
        self.algorithm_name = "hybrid"
        self.description = "混合算法 - 综合多种特征"
        
        # 获取算法特定配置
        alg_config = config.get_algorithm_config('hybrid')
        self.distance_threshold = alg_config.get('distance_threshold', 25.0)
        self.overlap_weight = alg_config.get('overlap_weight', 0.4)
        self.intensity_weight = alg_config.get('intensity_weight', 0.1)
        self.area_weight = alg_config.get('area_weight', 0.1)
        self.enable_prediction = alg_config.get('enable_prediction', True)
        self.enable_reconnection = alg_config.get('enable_reconnection', True)
        self.max_inactive_frames = alg_config.get('max_inactive_frames', 30)
        
        # 预测相关参数
        self.prediction_weight = 0.3
        
        self.algorithm_params = {
            'distance_threshold': self.distance_threshold,
            'overlap_weight': self.overlap_weight,
            'intensity_weight': self.intensity_weight,
            'area_weight': self.area_weight,
            'enable_prediction': self.enable_prediction,
            'enable_reconnection': self.enable_reconnection,
            'max_inactive_frames': self.max_inactive_frames
        }
    
    def match_regions(self, current_regions: List[Dict], 
                     distance_threshold: float = None, frame_idx: int = 0) -> List[Tuple[int, int]]:
        """混合匹配算法"""
        if not current_regions:
            return []
        
        # 获取活跃区域
        active_regions = [r for r in self.regions if r.active]
        if not active_regions:
            return []
        
        # 使用配置的距离阈值
        if distance_threshold is None:
            distance_threshold = self.distance_threshold
        
        try:
            # 构建综合得分矩阵
            score_matrix = self._build_hybrid_score_matrix(current_regions, active_regions)
            
            if score_matrix.size == 0:
                return []
            
            # 转换为成本矩阵用于匈牙利算法
            cost_matrix = 1.0 - score_matrix
            
            # 使用匈牙利算法求解最优分配
            try:
                row_indices, col_indices = linear_sum_assignment(cost_matrix)
                matches = []
                
                for row_idx, col_idx in zip(row_indices, col_indices):
                    score = score_matrix[row_idx, col_idx]
                    
                    # 只接受得分高于阈值的匹配
                    if score > 0.3:  # 可调阈值
                        matches.append((row_idx, col_idx))
                        self.logger.debug(f"混合匹配轨迹{active_regions[row_idx].id}: "
                                        f"综合得分{score:.3f}")
                
                # 如果启用重连，尝试重连未匹配的区域
                if self.enable_reconnection and len(matches) < len(active_regions):
                    reconnection_matches = self._attempt_hybrid_reconnection(
                        current_regions, active_regions, matches, frame_idx
                    )
                    matches.extend(reconnection_matches)
                
                self.logger.debug(f"混合算法第{frame_idx}帧: 匹配{len(matches)}对区域")
                return matches
                
            except Exception as e:
                self.logger.warning(f"混合匈牙利分配失败: {e}, 使用备用算法")
                return self._fallback_hybrid_matching(current_regions, active_regions, distance_threshold)
            
        except Exception as e:
            self.logger.error(f"混合匹配失败: {e}")
            return []
    
    def _build_hybrid_score_matrix(self, current_regions: List[Dict], active_regions: List) -> np.ndarray:
        """构建混合得分矩阵"""
        try:
            n_tracked = len(active_regions)
            n_current = len(current_regions)
            
            score_matrix = np.zeros((n_tracked, n_current))
            
            for i, tracked_region in enumerate(active_regions):
                for j, current_region in enumerate(current_regions):
                    score = self._calculate_hybrid_score(tracked_region, current_region)
                    score_matrix[i, j] = score
            
            return score_matrix
            
        except Exception as e:
            self.logger.error(f"混合得分矩阵构建失败: {e}")
            return np.array([])
    
    def _calculate_hybrid_score(self, tracked_region, current_region) -> float:
        """计算混合得分"""
        try:
            # 1. 距离得分
            distance_score = self._calculate_distance_score(tracked_region, current_region)
            
            # 2. 预测得分（如果启用）
            prediction_score = 0.0
            if self.enable_prediction:
                prediction_score = self._calculate_prediction_score(tracked_region, current_region)
            
            # 3. 强度相似性得分
            intensity_score = self._calculate_intensity_score(tracked_region, current_region)
            
            # 4. 面积相似性得分
            area_score = self._calculate_area_score(tracked_region, current_region)
            
            # 5. 重叠度得分
            overlap_score = self._calculate_overlap_score(tracked_region, current_region)
            
            # 6. 轨迹质量得分
            quality_score = self._calculate_quality_score(tracked_region)
            
            # 7. 速度一致性得分
            velocity_score = self._calculate_velocity_score(tracked_region, current_region)
            
            # 综合得分（权重可调）
            total_score = (distance_score * 0.25 + 
                         prediction_score * 0.15 + 
                         intensity_score * self.intensity_weight + 
                         area_score * self.area_weight + 
                         overlap_score * self.overlap_weight + 
                         quality_score * 0.1 + 
                         velocity_score * 0.1)
            
            return min(1.0, total_score)
            
        except Exception as e:
            self.logger.warning(f"混合得分计算失败: {e}")
            return 0.0
    
    def _calculate_distance_score(self, tracked_region, current_region) -> float:
        """计算距离得分"""
        try:
            tracked_center = np.array(tracked_region.trajectory[-1])
            current_center = np.array(current_region['center'])
            
            distance = np.linalg.norm(tracked_center - current_center)
            
            if distance > self.distance_threshold:
                return 0.0
            
            return 1.0 - (distance / self.distance_threshold)
            
        except Exception as e:
            self.logger.warning(f"距离得分计算失败: {e}")
            return 0.0
    
    def _calculate_prediction_score(self, tracked_region, current_region) -> float:
        """计算预测得分"""
        try:
            if len(tracked_region.trajectory) < 2:
                return 0.0
            
            # 简单线性预测
            if len(tracked_region.trajectory) == 2:
                velocity = np.array(tracked_region.trajectory[-1]) - np.array(tracked_region.trajectory[-2])
                predicted = np.array(tracked_region.trajectory[-1]) + velocity * self.prediction_weight
            else:
                # 考虑加速度的预测
                current_pos = np.array(tracked_region.trajectory[-1])
                prev_pos = np.array(tracked_region.trajectory[-2])
                prev_prev_pos = np.array(tracked_region.trajectory[-3])
                
                velocity = current_pos - prev_pos
                acceleration = velocity - (prev_pos - prev_prev_pos)
                
                predicted = current_pos + velocity * self.prediction_weight + acceleration * 0.5 * (self.prediction_weight ** 2)
            
            current_center = np.array(current_region['center'])
            prediction_error = np.linalg.norm(predicted - current_center)
            
            # 预测误差越小，得分越高
            max_error = self.distance_threshold
            if prediction_error > max_error:
                return 0.0
            
            return 1.0 - (prediction_error / max_error)
            
        except Exception as e:
            self.logger.warning(f"预测得分计算失败: {e}")
            return 0.0
    
    def _calculate_intensity_score(self, tracked_region, current_region) -> float:
        """计算强度得分"""
        try:
            tracked_intensity = getattr(tracked_region, 'intensity', 0)
            current_intensity = current_region.get('intensity', 0)
            
            if tracked_intensity == 0 and current_intensity == 0:
                return 1.0
            
            max_intensity = max(tracked_intensity, current_intensity, 0.1)
            intensity_diff = abs(tracked_intensity - current_intensity)
            
            return 1.0 - min(1.0, intensity_diff / max_intensity)
            
        except Exception as e:
            self.logger.warning(f"强度得分计算失败: {e}")
            return 0.0
    
    def _calculate_area_score(self, tracked_region, current_region) -> float:
        """计算面积得分"""
        try:
            tracked_area = getattr(tracked_region, 'area', 0)
            current_area = current_region.get('area', 0)
            
            if tracked_area == 0 and current_area == 0:
                return 1.0
            
            max_area = max(tracked_area, current_area, 1.0)
            area_diff = abs(tracked_area - current_area)
            
            return 1.0 - min(1.0, area_diff / max_area)
            
        except Exception as e:
            self.logger.warning(f"面积得分计算失败: {e}")
            return 0.0
    
    def _calculate_overlap_score(self, tracked_region, current_region) -> float:
        """计算重叠度得分"""
        try:
            tracked_center = np.array(tracked_region.trajectory[-1])
            current_center = np.array(current_region['center'])
            distance = np.linalg.norm(tracked_center - current_center)
            
            tracked_area = getattr(tracked_region, 'area', 0)
            current_area = current_region.get('area', 0)
            
            if tracked_area == 0 or current_area == 0:
                return 0.0
            
            # 估算重叠（简化版本）
            estimated_radius_tracked = np.sqrt(tracked_area / np.pi)
            estimated_radius_current = np.sqrt(current_area / np.pi)
            
            radius_sum = estimated_radius_tracked + estimated_radius_current
            
            if distance >= radius_sum:
                return 0.0
            elif distance <= abs(estimated_radius_tracked - estimated_radius_current):
                return 1.0
            else:
                return 1.0 - (distance / radius_sum)
                
        except Exception as e:
            self.logger.warning(f"重叠得分计算失败: {e}")
            return 0.0
    
    def _calculate_quality_score(self, tracked_region) -> float:
        """计算轨迹质量得分"""
        try:
            # 基于轨迹长度和稳定性
            length_score = min(1.0, len(tracked_region.trajectory) / 20.0)
            stability_score = max(0.0, 1.0 - tracked_region.inactive_frames / self.max_inactive_frames)
            
            return (length_score * 0.6 + stability_score * 0.4)
            
        except Exception as e:
            self.logger.warning(f"质量得分计算失败: {e}")
            return 0.5
    
    def _calculate_velocity_score(self, tracked_region, current_region) -> float:
        """计算速度一致性得分"""
        try:
            if len(tracked_region.trajectory) < 2:
                return 0.5
            
            # 计算历史速度
            prev_velocity = np.array(tracked_region.trajectory[-1]) - np.array(tracked_region.trajectory[-2])
            
            # 计算当前速度
            tracked_center = np.array(tracked_region.trajectory[-1])
            current_center = np.array(current_region['center'])
            current_velocity = current_center - tracked_center
            
            # 速度差异
            velocity_diff = np.linalg.norm(current_velocity - prev_velocity)
            
            # 速度差异越小，得分越高
            max_velocity_diff = 20.0  # 可调参数
            return max(0.0, 1.0 - velocity_diff / max_velocity_diff)
            
        except Exception as e:
            self.logger.warning(f"速度得分计算失败: {e}")
            return 0.5
    
    def _attempt_hybrid_reconnection(self, current_regions: List[Dict], 
                                   active_regions: List,
                                   existing_matches: List[Tuple[int, int]], 
                                   frame_idx: int) -> List[Tuple[int, int]]:
        """混合重连尝试"""
        reconnection_matches = []
        
        try:
            # 获取未匹配的区域索引
            matched_tracked = set([m[0] for m in existing_matches])
            matched_current = set([m[1] for m in existing_matches])
            
            unmatched_tracked = [i for i in range(len(active_regions)) if i not in matched_tracked]
            unmatched_current = [i for i in range(len(current_regions)) if i not in matched_current]
            
            if not unmatched_tracked or not unmatched_current:
                return reconnection_matches
            
            # 使用更宽松的阈值进行重连
            for tracked_idx in unmatched_tracked:
                tracked_region = active_regions[tracked_idx]
                
                # 只为非活跃帧数不太多的区域尝试重连
                if tracked_region.inactive_frames >= self.max_inactive_frames:
                    continue
                
                best_match = -1
                best_score = 0
                
                for current_idx in unmatched_current:
                    current_region = current_regions[current_idx]
                    
                    # 计算重连分数（更宽松的条件）
                    score = self._calculate_hybrid_score(tracked_region, current_region)
                    
                    if score > 0.2 and score > best_score:  # 更低的阈值
                        best_score = score
                        best_match = current_idx
                
                if best_match >= 0:
                    reconnection_matches.append((tracked_idx, best_match))
                    unmatched_current.remove(best_match)
                    
                    self.logger.debug(f"混合重连轨迹{tracked_region.id}: 得分{best_score:.3f}")
            
        except Exception as e:
            self.logger.warning(f"混合重连失败: {e}")
        
        return reconnection_matches
    
    def _fallback_hybrid_matching(self, current_regions: List[Dict], 
                                 active_regions: List, 
                                 distance_threshold: float) -> List[Tuple[int, int]]:
        """备用混合匹配"""
        try:
            matches = []
            used_current = set()
            used_tracked = set()
            
            # 计算所有得分对
            score_pairs = []
            for i, tracked_region in enumerate(active_regions):
                for j, current_region in enumerate(current_regions):
                    score = self._calculate_hybrid_score(tracked_region, current_region)
                    if score > 0.3:
                        score_pairs.append((score, i, j))
            
            # 按得分排序
            score_pairs.sort(reverse=True)
            
            # 贪婪选择
            for score, tracked_idx, current_idx in score_pairs:
                if tracked_idx not in used_tracked and current_idx not in used_current:
                    matches.append((tracked_idx, current_idx))
                    used_tracked.add(tracked_idx)
                    used_current.add(current_idx)
            
            return matches
            
        except Exception as e:
            self.logger.error(f"备用混合算法失败: {e}")
            return []
    
    def get_algorithm_info(self) -> Dict:
        """获取算法信息"""
        info = super().get_algorithm_info()
        info.update({
            'description': self.description,
            'characteristics': [
                "多算法融合",
                "综合特征评估",
                "自适应权重",
                "全局优化"
            ],
            'advantages': [
                "综合多种算法优势",
                "适应性强",
                "匹配精度高",
                "鲁棒性好"
            ],
            'disadvantages': [
                "计算复杂度最高",
                "参数众多",
                "调优困难",
                "资源消耗大"
            ],
            'best_for': [
                "复杂跟踪场景",
                "高精度要求",
                "多变环境",
                "离线分析场景"
            ]
        })
        return info

# ========== trackers/kalman_tracker.py ==========
# 相对路径: trackers/kalman_tracker.py
# 在项目中的相对位置: ./trackers/kalman_tracker.py

import numpy as np
from scipy.spatial.distance import cdist
from scipy.optimize import linear_sum_assignment
from typing import List, Tuple, Dict
from .base_tracker import BaseTracker

class KalmanTracker(BaseTracker):
    """卡尔曼预测跟踪器"""
    
    def __init__(self, config):
        super().__init__(config)
        self.algorithm_name = "kalman"
        self.description = "卡尔曼预测算法 - 基于运动预测"
        
        # 获取算法特定配置
        alg_config = config.get_algorithm_config('kalman')
        self.distance_threshold = alg_config.get('distance_threshold', 30.0)
        self.prediction_weight = alg_config.get('prediction_weight', 0.4)
        self.enable_reconnection = alg_config.get('enable_reconnection', True)
        self.max_inactive_frames = alg_config.get('max_inactive_frames', 30)
        
        self.algorithm_params = {
            'distance_threshold': self.distance_threshold,
            'prediction_weight': self.prediction_weight,
            'enable_reconnection': self.enable_reconnection,
            'max_inactive_frames': self.max_inactive_frames
        }
    
    def match_regions(self, current_regions: List[Dict], 
                     distance_threshold: float = None, frame_idx: int = 0) -> List[Tuple[int, int]]:
        """卡尔曼预测匹配算法"""
        if not current_regions:
            return []
        
        # 获取活跃区域
        active_regions = [r for r in self.regions if r.active]
        if not active_regions:
            return []
        
        # 使用配置的距离阈值
        if distance_threshold is None:
            distance_threshold = self.distance_threshold
        
        try:
            # 预测下一帧位置
            predicted_centers = []
            for region in active_regions:
                predicted_pos = self._predict_next_position(region)
                predicted_centers.append(predicted_pos)
            
            if not predicted_centers:
                return []
            
            predicted_centers = np.array(predicted_centers)
            current_centers = np.array([r['center'] for r in current_regions])
            
            # 计算距离矩阵
            distances = cdist(predicted_centers, current_centers)
            
            # 使用匈牙利算法求解最优分配
            try:
                row_indices, col_indices = linear_sum_assignment(distances)
                matches = []
                
                for row_idx, col_idx in zip(row_indices, col_indices):
                    if distances[row_idx, col_idx] < distance_threshold:
                        matches.append((row_idx, col_idx))
                        self.logger.debug(f"卡尔曼匹配轨迹{active_regions[row_idx].id}: "
                                        f"预测距离{distances[row_idx, col_idx]:.2f}")
                
                # 如果启用重连，尝试重连未匹配的区域
                if self.enable_reconnection and len(matches) < len(active_regions):
                    reconnection_matches = self._attempt_kalman_reconnection(
                        current_regions, active_regions, matches, frame_idx
                    )
                    matches.extend(reconnection_matches)
                
                self.logger.debug(f"卡尔曼算法第{frame_idx}帧: 匹配{len(matches)}对区域")
                return matches
                
            except Exception as e:
                self.logger.warning(f"卡尔曼匈牙利分配失败: {e}")
                return self._fallback_greedy_matching(current_regions, active_regions, distance_threshold)
            
        except Exception as e:
            self.logger.error(f"卡尔曼匹配失败: {e}")
            return []
    
    def _predict_next_position(self, region) -> np.ndarray:
        """预测下一个位置"""
        try:
            trajectory = region.trajectory
            
            if len(trajectory) < 2:
                # 如果轨迹点不足，返回当前位置
                return np.array(trajectory[-1])
            
            elif len(trajectory) == 2:
                # 简单线性预测
                velocity = np.array(trajectory[-1]) - np.array(trajectory[-2])
                predicted = np.array(trajectory[-1]) + velocity * self.prediction_weight
                
            else:
                # 使用多点预测，考虑加速度
                current_pos = np.array(trajectory[-1])
                prev_pos = np.array(trajectory[-2])
                prev_prev_pos = np.array(trajectory[-3])
                
                # 计算速度和加速度
                velocity = current_pos - prev_pos
                prev_velocity = prev_pos - prev_prev_pos
                acceleration = velocity - prev_velocity
                
                # 预测下一个位置（考虑速度和加速度）
                predicted = (current_pos + 
                           velocity * self.prediction_weight + 
                           acceleration * (self.prediction_weight ** 2) * 0.5)
            
            return predicted
            
        except Exception as e:
            self.logger.warning(f"位置预测失败: {e}")
            return np.array(region.trajectory[-1])
    
    def _attempt_kalman_reconnection(self, current_regions: List[Dict], 
                                   active_regions: List,
                                   existing_matches: List[Tuple[int, int]], 
                                   frame_idx: int) -> List[Tuple[int, int]]:
        """卡尔曼重连尝试"""
        reconnection_matches = []
        
        try:
            # 获取未匹配的区域索引
            matched_tracked = set([m[0] for m in existing_matches])
            matched_current = set([m[1] for m in existing_matches])
            
            unmatched_tracked = [i for i in range(len(active_regions)) if i not in matched_tracked]
            unmatched_current = [i for i in range(len(current_regions)) if i not in matched_current]
            
            if not unmatched_tracked or not unmatched_current:
                return reconnection_matches
            
            # 使用更宽松的阈值进行重连
            reconnection_threshold = self.distance_threshold * 1.8
            
            # 预测未匹配区域的位置
            for tracked_idx in unmatched_tracked:
                tracked_region = active_regions[tracked_idx]
                
                # 只为非活跃帧数不太多的区域尝试重连
                if tracked_region.inactive_frames >= self.max_inactive_frames:
                    continue
                
                predicted_pos = self._predict_next_position(tracked_region)
                
                best_match = -1
                best_distance = float('inf')
                
                for current_idx in unmatched_current:
                    current_region = current_regions[current_idx]
                    current_pos = np.array(current_region['center'])
                    
                    distance = np.linalg.norm(predicted_pos - current_pos)
                    
                    if distance < reconnection_threshold and distance < best_distance:
                        best_distance = distance
                        best_match = current_idx
                
                if best_match >= 0:
                    reconnection_matches.append((tracked_idx, best_match))
                    unmatched_current.remove(best_match)
                    
                    self.logger.debug(f"卡尔曼重连轨迹{tracked_region.id}: "
                                    f"预测距离{best_distance:.2f}")
            
        except Exception as e:
            self.logger.warning(f"卡尔曼重连失败: {e}")
        
        return reconnection_matches
    
    def _fallback_greedy_matching(self, current_regions: List[Dict], 
                                active_regions: List, 
                                distance_threshold: float) -> List[Tuple[int, int]]:
        """备用贪婪匹配"""
        try:
            current_centers = np.array([r['center'] for r in current_regions])
            tracked_centers = np.array([r.trajectory[-1] for r in active_regions])
            
            distances = cdist(tracked_centers, current_centers)
            
            matches = []
            used_current = set()
            used_tracked = set()
            
            dist_indices = np.unravel_index(np.argsort(distances.ravel()), distances.shape)
            
            for tracked_idx, current_idx in zip(dist_indices[0], dist_indices[1]):
                if tracked_idx in used_tracked or current_idx in used_current:
                    continue
                
                if distances[tracked_idx, current_idx] < distance_threshold:
                    matches.append((tracked_idx, current_idx))
                    used_tracked.add(tracked_idx)
                    used_current.add(current_idx)
            
            return matches
            
        except Exception as e:
            self.logger.error(f"备用贪婪算法失败: {e}")
            return []
    
    def update_region_velocity_history(self, region, current_position: np.ndarray):
        """更新区域的速度历史"""
        try:
            if len(region.trajectory) >= 2:
                velocity = current_position - np.array(region.trajectory[-1])
                
                # 维护速度历史（最多保存10个历史速度）
                if not hasattr(region, 'velocity_history'):
                    region.velocity_history = []
                
                region.velocity_history.append(velocity)
                
                if len(region.velocity_history) > 10:
                    region.velocity_history.pop(0)
                    
        except Exception as e:
            self.logger.warning(f"速度历史更新失败: {e}")
    
    def get_algorithm_info(self) -> Dict:
        """获取算法信息"""
        info = super().get_algorithm_info()
        info.update({
            'description': self.description,
            'characteristics': [
                "运动预测",
                "考虑速度和加速度",
                "自适应阈值",
                "轨迹连续性优化"
            ],
            'advantages': [
                "对运动目标跟踪效果好",
                "能够处理短暂遮挡",
                "预测能力强",
                "轨迹平滑性好"
            ],
            'disadvantages': [
                "对非线性运动敏感",
                "需要足够的历史数据",
                "计算复杂度中等",
                "参数调优较复杂"
            ],
            'best_for': [
                "运动规律较明显的场景",
                "需要预测功能的场景",
                "轨迹连续性要求高的场景",
                "有遮挡的跟踪场景"
            ]
        })
        return info

# ========== trackers/overlap_tracker.py ==========
# 相对路径: trackers/overlap_tracker.py
# 在项目中的相对位置: ./trackers/overlap_tracker.py

import numpy as np
from scipy.spatial.distance import cdist
from typing import List, Tuple, Dict
from .base_tracker import BaseTracker

class OverlapTracker(BaseTracker):
    """重叠度匹配跟踪器"""
    
    def __init__(self, config):
        super().__init__(config)
        self.algorithm_name = "overlap"
        self.description = "重叠度匹配 - 基于区域重叠"
        
        # 获取算法特定配置
        alg_config = config.get_algorithm_config('overlap')
        self.overlap_threshold = alg_config.get('overlap_threshold', 0.3)
        self.distance_threshold = alg_config.get('distance_threshold', 35.0)
        self.enable_reconnection = alg_config.get('enable_reconnection', True)
        self.max_inactive_frames = alg_config.get('max_inactive_frames', 20)
        
        self.algorithm_params = {
            'overlap_threshold': self.overlap_threshold,
            'distance_threshold': self.distance_threshold,
            'enable_reconnection': self.enable_reconnection,
            'max_inactive_frames': self.max_inactive_frames
        }
    
    def match_regions(self, current_regions: List[Dict], 
                     distance_threshold: float = None, frame_idx: int = 0) -> List[Tuple[int, int]]:
        """重叠度匹配算法"""
        if not current_regions:
            return []
        
        # 获取活跃区域
        active_regions = [r for r in self.regions if r.active]
        if not active_regions:
            return []
        
        # 使用配置的距离阈值
        if distance_threshold is None:
            distance_threshold = self.distance_threshold
        
        try:
            matches = []
            used_current = set()
            used_tracked = set()
            
            # 为每个跟踪区域寻找最佳匹配
            for i, tracked_region in enumerate(active_regions):
                if i in used_tracked:
                    continue
                
                best_match = -1
                best_score = 0
                
                for j, current_region in enumerate(current_regions):
                    if j in used_current:
                        continue
                    
                    # 计算综合匹配分数
                    score = self._calculate_match_score(tracked_region, current_region, distance_threshold)
                    
                    if score > best_score and score > self.overlap_threshold:
                        best_score = score
                        best_match = j
                
                if best_match >= 0:
                    matches.append((i, best_match))
                    used_tracked.add(i)
                    used_current.add(best_match)
                    
                    self.logger.debug(f"重叠匹配轨迹{tracked_region.id}: 分数{best_score:.3f}")
            
            # 如果启用重连，尝试重连未匹配的区域
            if self.enable_reconnection and len(matches) < len(active_regions):
                reconnection_matches = self._attempt_overlap_reconnection(
                    current_regions, active_regions, used_current, used_tracked, frame_idx
                )
                matches.extend(reconnection_matches)
            
            self.logger.debug(f"重叠算法第{frame_idx}帧: 匹配{len(matches)}对区域")
            return matches
            
        except Exception as e:
            self.logger.error(f"重叠匹配失败: {e}")
            return []
    
    def _calculate_match_score(self, tracked_region, current_region, distance_threshold: float) -> float:
        """计算匹配分数"""
        try:
            tracked_center = np.array(tracked_region.trajectory[-1])
            current_center = np.array(current_region['center'])
            
            # 1. 距离分数
            distance = np.linalg.norm(tracked_center - current_center)
            if distance > distance_threshold:
                return 0.0
            
            distance_score = 1.0 - (distance / distance_threshold)
            
            # 2. 空间重叠分数（简化版本，基于距离和大小）
            overlap_score = self._estimate_spatial_overlap(tracked_region, current_region, distance)
            
            # 3. 强度相似性分数
            intensity_score = self._calculate_intensity_similarity(tracked_region, current_region)
            
            # 4. 面积相似性分数
            area_score = self._calculate_area_similarity(tracked_region, current_region)
            
            # 5. 形状稳定性分数
            stability_score = self._calculate_stability_score(tracked_region)
            
            # 综合分数（权重可调）
            total_score = (distance_score * 0.25 + 
                         overlap_score * 0.35 + 
                         intensity_score * 0.15 + 
                         area_score * 0.15 + 
                         stability_score * 0.1)
            
            return total_score
            
        except Exception as e:
            self.logger.warning(f"匹配分数计算失败: {e}")
            return 0.0
    
    def _estimate_spatial_overlap(self, tracked_region, current_region, distance: float) -> float:
        """估算空间重叠度"""
        try:
            # 简化的重叠估算，基于距离和区域大小
            tracked_area = getattr(tracked_region, 'area', 0)
            current_area = current_region.get('area', 0)
            
            if tracked_area == 0 or current_area == 0:
                return 0.0
            
            # 估算重叠区域：距离越近，重叠度越高
            estimated_radius_tracked = np.sqrt(tracked_area / np.pi)
            estimated_radius_current = np.sqrt(current_area / np.pi)
            
            # 如果两个圆心距离小于两个半径之和，则有重叠
            radius_sum = estimated_radius_tracked + estimated_radius_current
            
            if distance >= radius_sum:
                return 0.0
            elif distance <= abs(estimated_radius_tracked - estimated_radius_current):
                # 一个完全包含另一个
                return 1.0
            else:
                # 部分重叠，使用简化公式
                overlap_ratio = 1.0 - (distance / radius_sum)
                return max(0.0, min(1.0, overlap_ratio))
                
        except Exception as e:
            self.logger.warning(f"重叠估算失败: {e}")
            return 0.0
    
    def _calculate_intensity_similarity(self, tracked_region, current_region) -> float:
        """计算强度相似性"""
        try:
            tracked_intensity = getattr(tracked_region, 'intensity', 0)
            current_intensity = current_region.get('intensity', 0)
            
            if tracked_intensity == 0 and current_intensity == 0:
                return 1.0
            
            max_intensity = max(tracked_intensity, current_intensity, 0.1)
            intensity_diff = abs(tracked_intensity - current_intensity)
            
            similarity = 1.0 - min(1.0, intensity_diff / max_intensity)
            return similarity
            
        except Exception as e:
            self.logger.warning(f"强度相似性计算失败: {e}")
            return 0.0
    
    def _calculate_area_similarity(self, tracked_region, current_region) -> float:
        """计算面积相似性"""
        try:
            tracked_area = getattr(tracked_region, 'area', 0)
            current_area = current_region.get('area', 0)
            
            if tracked_area == 0 and current_area == 0:
                return 1.0
            
            max_area = max(tracked_area, current_area, 1.0)
            area_diff = abs(tracked_area - current_area)
            
            similarity = 1.0 - min(1.0, area_diff / max_area)
            return similarity
            
        except Exception as e:
            self.logger.warning(f"面积相似性计算失败: {e}")
            return 0.0
    
    def _calculate_stability_score(self, tracked_region) -> float:
        """计算稳定性分数"""
        try:
            # 基于轨迹长度和非活跃帧数的稳定性
            trajectory_length = len(tracked_region.trajectory)
            inactive_frames = getattr(tracked_region, 'inactive_frames', 0)
            
            # 轨迹越长越稳定
            length_score = min(1.0, trajectory_length / 20.0)
            
            # 非活跃帧数越少越稳定
            activity_score = max(0.0, 1.0 - inactive_frames / self.max_inactive_frames)
            
            stability = (length_score * 0.6 + activity_score * 0.4)
            return stability
            
        except Exception as e:
            self.logger.warning(f"稳定性分数计算失败: {e}")
            return 0.5
    
    def _attempt_overlap_reconnection(self, current_regions: List[Dict], 
                                    active_regions: List,
                                    used_current: set, used_tracked: set, 
                                    frame_idx: int) -> List[Tuple[int, int]]:
        """尝试重叠重连"""
        reconnection_matches = []
        
        try:
            # 获取未匹配的区域
            unmatched_tracked = [i for i in range(len(active_regions)) if i not in used_tracked]
            unmatched_current = [i for i in range(len(current_regions)) if i not in used_current]
            
            if not unmatched_tracked or not unmatched_current:
                return reconnection_matches
            
            # 使用更宽松的阈值进行重连
            reconnection_threshold = self.overlap_threshold * 0.7
            
            for tracked_idx in unmatched_tracked:
                tracked_region = active_regions[tracked_idx]
                
                # 只为非活跃帧数不太多的区域尝试重连
                if tracked_region.inactive_frames >= self.max_inactive_frames:
                    continue
                
                best_match = -1
                best_score = 0
                
                for current_idx in unmatched_current:
                    current_region = current_regions[current_idx]
                    
                    # 计算重连分数（更宽松的条件）
                    score = self._calculate_match_score(tracked_region, current_region, 
                                                      self.distance_threshold * 1.5)
                    
                    if score > reconnection_threshold and score > best_score:
                        best_score = score
                        best_match = current_idx
                
                if best_match >= 0:
                    reconnection_matches.append((tracked_idx, best_match))
                    unmatched_current.remove(best_match)
                    
                    self.logger.debug(f"重叠重连轨迹{tracked_region.id}: 分数{best_score:.3f}")
            
        except Exception as e:
            self.logger.warning(f"重叠重连失败: {e}")
        
        return reconnection_matches
    
    def get_algorithm_info(self) -> Dict:
        """获取算法信息"""
        info = super().get_algorithm_info()
        info.update({
            'description': self.description,
            'characteristics': [
                "空间重叠分析",
                "多特征综合评分",
                "形状感知匹配",
                "稳定性优化"
            ],
            'advantages': [
                "考虑区域形状信息",
                "对形变有一定容忍度",
                "匹配精度较高",
                "能处理部分遮挡"
            ],
            'disadvantages': [
                "计算复杂度较高",
                "依赖准确的区域检测",
                "对噪声敏感",
                "参数较多"
            ],
            'best_for': [
                "形状稳定的目标",
                "需要精确匹配的场景",
                "有重叠可能的场景",
                "区域边界清晰的场景"
            ]
        })
        return info

# ========== trackers/tracker_factory.py ==========
# 相对路径: trackers/tracker_factory.py
# 在项目中的相对位置: ./trackers/tracker_factory.py

"""
跟踪器工厂类
用于创建和管理不同类型的跟踪算法
"""

import logging
from typing import Dict, List, Optional
from .base_tracker import BaseTracker
from .greedy_tracker import GreedyTracker
from .hungarian_tracker import HungarianTracker
from .kalman_tracker import KalmanTracker
from .overlap_tracker import OverlapTracker
from .hybrid_tracker import HybridTracker

class TrackerFactory:
    """跟踪器工厂类"""
    
    # 注册的跟踪器类
    _trackers = {
        'greedy': GreedyTracker,
        'hungarian': HungarianTracker, 
        'kalman': KalmanTracker,
        'overlap': OverlapTracker,
        'hybrid': HybridTracker
    }
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    @classmethod
    def create_tracker(cls, algorithm_name: str, config) -> Optional[BaseTracker]:
        """创建指定类型的跟踪器"""
        logger = logging.getLogger(__name__)
        
        if algorithm_name not in cls._trackers:
            logger.error(f"未知的跟踪算法: {algorithm_name}")
            return None
        
        try:
            tracker_class = cls._trackers[algorithm_name]
            tracker = tracker_class(config)
            logger.info(f"成功创建{algorithm_name}跟踪器")
            return tracker
        except Exception as e:
            logger.error(f"创建{algorithm_name}跟踪器失败: {e}")
            import traceback
            logger.debug(f"详细错误信息: {traceback.format_exc()}")
            return None
    
    @classmethod
    def get_available_algorithms(cls) -> List[str]:
        """获取可用的算法列表"""
        return list(cls._trackers.keys())
    
    @classmethod
    def get_algorithm_info(cls, algorithm_name: str) -> Dict:
        """获取算法信息"""
        if algorithm_name not in cls._trackers:
            return {'error': f'未知算法: {algorithm_name}'}
        
        try:
            # 创建临时实例获取信息
            from config import Config
            temp_tracker = cls._trackers[algorithm_name](Config)
            return temp_tracker.get_algorithm_info()
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.warning(f"获取{algorithm_name}算法信息失败: {e}")
            return {
                'name': algorithm_name,
                'description': cls._trackers[algorithm_name].__doc__ or f'{algorithm_name} 跟踪算法',
                'error': f'获取算法信息失败: {e}'
            }
    
    @classmethod
    def compare_algorithms(cls, config) -> Dict:
        """比较所有可用算法"""
        comparison = {
            'available_algorithms': cls.get_available_algorithms(),
            'algorithm_details': {}
        }
        
        for algorithm in cls.get_available_algorithms():
            info = cls.get_algorithm_info(algorithm)
            comparison['algorithm_details'][algorithm] = info
        
        return comparison
    
    @classmethod
    def register_tracker(cls, algorithm_name: str, tracker_class):
        """注册新的跟踪器类"""
        if not issubclass(tracker_class, BaseTracker):
            raise ValueError("跟踪器类必须继承自BaseTracker")
        
        cls._trackers[algorithm_name] = tracker_class
        logging.getLogger(__name__).info(f"注册新跟踪器: {algorithm_name}")
    
    @classmethod
    def create_all_trackers(cls, config, algorithms: Optional[List[str]] = None) -> Dict[str, BaseTracker]:
        """创建多个跟踪器"""
        if algorithms is None:
            algorithms = config.COMPARISON_ALGORITHMS
        
        trackers = {}
        
        for algorithm in algorithms:
            tracker = cls.create_tracker(algorithm, config)
            if tracker is not None:
                trackers[algorithm] = tracker
            else:
                logging.getLogger(__name__).warning(f"跳过创建失败的跟踪器: {algorithm}")
        
        return trackers
    
    @classmethod
    def validate_algorithm_config(cls, config) -> Dict[str, bool]:
        """验证算法配置"""
        validation_results = {}
        
        for algorithm in config.COMPARISON_ALGORITHMS:
            try:
                if algorithm in cls._trackers:
                    # 检查配置是否存在
                    alg_config = config.get_algorithm_config(algorithm)
                    validation_results[algorithm] = bool(alg_config)
                else:
                    validation_results[algorithm] = False
            except Exception as e:
                logging.getLogger(__name__).error(f"验证{algorithm}配置失败: {e}")
                validation_results[algorithm] = False
        
        return validation_results

